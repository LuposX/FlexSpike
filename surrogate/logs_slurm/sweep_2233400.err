/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
wandb: Agent Starting Run: 6896yzg4 with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.00018642436829732932
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.8
wandb: Currently logged in as: lupos to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: setting up run 6896yzg4
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_113418-6896yzg4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/6896yzg4
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 4.7 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
4.8 K     Trainable params
0         Non-trainable params
4.8 K     Total params
0.019     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: uploading console lines 42-43
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ‚ñÖ‚ñà‚ñà
wandb:   grad_mean/lif_layers.1 ‚ñà‚ñÑ‚ñÇ‚ñÅ
wandb:   grad_mean/output_layer ‚ñà‚ñÑ‚ñÇ‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:               train_loss ‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 39
wandb:   grad_mean/lif_layers.0 0.00785
wandb:   grad_mean/lif_layers.1 0.00172
wandb:   grad_mean/output_layer 0.16297
wandb:                       lr 0
wandb: spikes/train_avg_layer_0 0.02827
wandb: spikes/train_avg_layer_1 0.01006
wandb:               train_loss 0.1857
wandb:      trainer/global_step 279
wandb:                 val_loss 0.18395
wandb: 
wandb: üöÄ View run copper-sweep-1 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/6896yzg4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_113418-6896yzg4/logs
wandb: Agent Starting Run: 7f7xsvc4 with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 5.148795801676285e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.9
wandb: setting up run 7f7xsvc4
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_114106-7f7xsvc4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lilac-sweep-2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/7f7xsvc4
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 332    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
351       Trainable params
0         Non-trainable params
351       Total params
0.001     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: uploading history steps 82-83, summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                   epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:  grad_mean/lif_layers.0 ‚ñÅ‚ñÅ‚ñÜ‚ñà
wandb:  grad_mean/lif_layers.1 ‚ñá‚ñÅ‚ñà‚ñÖ
wandb: grad_mean/lif_layers.10 ‚ñÑ‚ñÇ‚ñà‚ñÅ
wandb: grad_mean/lif_layers.11 ‚ñÑ‚ñÇ‚ñà‚ñÅ
wandb: grad_mean/lif_layers.12 ‚ñÖ‚ñÉ‚ñà‚ñÅ
wandb: grad_mean/lif_layers.13 ‚ñÖ‚ñÉ‚ñà‚ñÅ
wandb: grad_mean/lif_layers.14 ‚ñÑ‚ñÑ‚ñà‚ñÅ
wandb: grad_mean/lif_layers.15 ‚ñÉ‚ñÉ‚ñà‚ñÅ
wandb:  grad_mean/lif_layers.2 ‚ñÖ‚ñÅ‚ñà‚ñÑ
wandb:                     +28 ...
wandb: 
wandb: Run summary:
wandb:                   epoch 39
wandb:  grad_mean/lif_layers.0 0.00014
wandb:  grad_mean/lif_layers.1 8e-05
wandb: grad_mean/lif_layers.10 0.00126
wandb: grad_mean/lif_layers.11 0.00105
wandb: grad_mean/lif_layers.12 0.00245
wandb: grad_mean/lif_layers.13 0.00345
wandb: grad_mean/lif_layers.14 0.00605
wandb: grad_mean/lif_layers.15 0.0041
wandb:  grad_mean/lif_layers.2 0.00014
wandb:                     +28 ...
wandb: 
wandb: üöÄ View run lilac-sweep-2 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/7f7xsvc4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_114106-7f7xsvc4/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: uuxij427 with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 3.5334968712479883e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.8
wandb: setting up run uuxij427
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_114600-uuxij427
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-sweep-3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/uuxij427
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 13.0 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
13.1 K    Trainable params
0         Non-trainable params
13.1 K    Total params
0.052     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñÅ‚ñÑ‚ñá
wandb: spikes/train_avg_layer_1 ‚ñà‚ñá‚ñá‚ñÅ
wandb: spikes/train_avg_layer_2 ‚ñà‚ñÅ‚ñÉ‚ñÇ
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               train_loss ‚ñà‚ñÜ‚ñÉ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñÜ‚ñÉ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 3
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.0191
wandb: spikes/train_avg_layer_1 0.00088
wandb: spikes/train_avg_layer_2 0.0
wandb: spikes/train_avg_layer_3 0
wandb:               train_loss 0.20695
wandb:      trainer/global_step 27
wandb:                 val_loss 0.20504
wandb: 
wandb: üöÄ View run earnest-sweep-3 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/uuxij427
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_114600-uuxij427/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 153, in run
    self.on_advance_end(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 398, in on_advance_end
    self.val_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 145, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 437, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 412, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 620, in validation_step
    outputs = self(X_batch)
              ^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    lif_out, _states = lif(input_seq)  # lif_out: (T, B, F_hidden)
                       ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 185, in forward
    h_candidate = torch.tanh(preact)
                  ^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: qsc5tsxn with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 7.548890660327252e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.9
wandb: setting up run qsc5tsxn
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_114809-qsc5tsxn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-sweep-4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/qsc5tsxn
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 29.6 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
29.7 K    Trainable params
0         Non-trainable params
29.7 K    Total params
0.119     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception in thread QueueFeederThread:
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1012, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 291, in _feed
    queue_sem.release()
ValueError: semaphore or lock released too many times
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
      Exception ignored in:  ^<function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>^
^Traceback (most recent call last):
^  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    self._shutdown_workers()
    assert self._parent_pid == os.getpid(), 'can only test a child process'
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
           ^^^^^^^^^^^^^^^^^^^^^    ^if w.is_alive():^
^^^ ^ ^ ^ ^ ^ 
 AssertionError^: ^can only test a child process^
^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    Exception ignored in: self._shutdown_workers()
<function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^    ^self._shutdown_workers()^
^^^^  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
^^^^^^^^^^^^^^^    ^^if w.is_alive():^
^
AssertionError :      can only test a child process if w.is_alive():
 
      ^ ^ ^ ^ ^^^^^^^^^^^^^^^^
^  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'^
^^^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^
^AssertionError^: ^can only test a child processException ignored in: ^
^<function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>^
^Traceback (most recent call last):
^  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
^^^^^^^^^^^^^^
AssertionError: can only test a child process
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
    Exception ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620> 
 Traceback (most recent call last):
 ^  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
wandb: updating run metadata
wandb: uploading summary, console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÖ‚ñà‚ñÉ‚ñÅ
wandb: spikes/train_avg_layer_1 ‚ñà‚ñÇ‚ñÅ‚ñÇ
wandb: spikes/train_avg_layer_2 ‚ñá‚ñà‚ñÜ‚ñÅ
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 3
wandb:                       lr 1e-05
wandb: spikes/train_avg_layer_0 0.02057
wandb: spikes/train_avg_layer_1 0.00102
wandb: spikes/train_avg_layer_2 3e-05
wandb: spikes/train_avg_layer_3 0
wandb: spikes/train_avg_layer_4 0
wandb: spikes/train_avg_layer_5 0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run playful-sweep-4 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/qsc5tsxn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_114809-qsc5tsxn/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: 5ekf0127 with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.4170634879496257e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 1
wandb: setting up run 5ekf0127
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_115308-5ekf0127
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/5ekf0127
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 4.7 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
4.8 K     Trainable params
0         Non-trainable params
4.8 K     Total params
0.019     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñá‚ñÉ‚ñÅ‚ñá
wandb: spikes/train_avg_layer_1 ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñà
wandb:               train_loss ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñá‚ñÖ‚ñÇ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 4
wandb:                       lr 1e-05
wandb: spikes/train_avg_layer_0 0.01994
wandb: spikes/train_avg_layer_1 0.00159
wandb:               train_loss 0.30529
wandb:      trainer/global_step 34
wandb:                 val_loss 0.30241
wandb: 
wandb: üöÄ View run kind-sweep-5 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/5ekf0127
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_115308-5ekf0127/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
    outputs = self(X_batch)
              ^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    lif_out, _states = lif(input_seq)  # lif_out: (T, B, F_hidden)
                       ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 167, in forward
    x = self.rho * torch.tanh(i / self.rho)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: nua9eqmj with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 6.382233993479792e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 3
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 1
wandb: setting up run nua9eqmj
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_115411-nua9eqmj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-6
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/nua9eqmj
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 172    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
191       Trainable params
0         Non-trainable params
191       Total params
0.001     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                  epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: grad_mean/lif_layers.0 ‚ñÅ‚ñÜ‚ñà‚ñà
wandb: grad_mean/lif_layers.1 ‚ñà‚ñÅ‚ñÅ‚ñÇ
wandb: grad_mean/lif_layers.2 ‚ñà‚ñÅ‚ñÅ‚ñÇ
wandb: grad_mean/lif_layers.3 ‚ñà‚ñÅ‚ñÅ‚ñÇ
wandb: grad_mean/lif_layers.4 ‚ñà‚ñÇ‚ñÅ‚ñÇ
wandb: grad_mean/lif_layers.5 ‚ñà‚ñÇ‚ñÅ‚ñÇ
wandb: grad_mean/lif_layers.6 ‚ñà‚ñÇ‚ñÅ‚ñÇ
wandb: grad_mean/lif_layers.7 ‚ñà‚ñÇ‚ñÅ‚ñÇ
wandb: grad_mean/output_layer ‚ñà‚ñÇ‚ñÅ‚ñÉ
wandb:                    +12 ...
wandb: 
wandb: Run summary:
wandb:                  epoch 39
wandb: grad_mean/lif_layers.0 0.00237
wandb: grad_mean/lif_layers.1 0.00059
wandb: grad_mean/lif_layers.2 0.00044
wandb: grad_mean/lif_layers.3 0.00063
wandb: grad_mean/lif_layers.4 0.00039
wandb: grad_mean/lif_layers.5 0.00106
wandb: grad_mean/lif_layers.6 0.001
wandb: grad_mean/lif_layers.7 0.00085
wandb: grad_mean/output_layer 0.02616
wandb:                    +12 ...
wandb: 
wandb: üöÄ View run stellar-sweep-6 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/nua9eqmj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_115411-nua9eqmj/logs
wandb: Agent Starting Run: 7ae1lxgc with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.253680762118859e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_115646-7ae1lxgc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-7
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/7ae1lxgc
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 52     | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
71        Trainable params
0         Non-trainable params
71        Total params
0.000     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: uploading console lines 42-43
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ‚ñà‚ñÉ‚ñÅ
wandb:   grad_mean/lif_layers.1 ‚ñÜ‚ñà‚ñÖ‚ñÅ
wandb:   grad_mean/output_layer ‚ñà‚ñà‚ñÉ‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:               train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 39
wandb:   grad_mean/lif_layers.0 0.03858
wandb:   grad_mean/lif_layers.1 0.02738
wandb:   grad_mean/output_layer 0.76337
wandb:                       lr 0
wandb: spikes/train_avg_layer_0 0.0059
wandb: spikes/train_avg_layer_1 9e-05
wandb:               train_loss 0.75394
wandb:      trainer/global_step 279
wandb:                 val_loss 0.74933
wandb: 
wandb: üöÄ View run clear-sweep-7 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/7ae1lxgc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_115646-7ae1lxgc/logs
wandb: Agent Starting Run: afjwmzsy with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 4.463874992693854e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 1
wandb: setting up run afjwmzsy
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_115737-afjwmzsy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-8
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/afjwmzsy
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 4.7 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
4.8 K     Trainable params
0         Non-trainable params
4.8 K     Total params
0.019     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading history steps 18-19, summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:                       lr ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñà
wandb:               train_loss ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 9
wandb:                       lr 4e-05
wandb: spikes/train_avg_layer_0 0.01789
wandb: spikes/train_avg_layer_1 0.0008
wandb:               train_loss 0.21987
wandb:      trainer/global_step 69
wandb:                 val_loss 0.21767
wandb: 
wandb: üöÄ View run flowing-sweep-8 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/afjwmzsy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_115737-afjwmzsy/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: ysmgdt1g with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.984605607322757e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_115911-ysmgdt1g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-9
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/ysmgdt1g
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 944    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
975       Trainable params
0         Non-trainable params
975       Total params
0.004     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                       lr ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ
wandb: spikes/train_avg_layer_1 ‚ñÖ‚ñÑ‚ñá‚ñÜ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÇ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_2 ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà
wandb:               train_loss ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 10
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.02348
wandb: spikes/train_avg_layer_1 0.00189
wandb: spikes/train_avg_layer_2 0.00023
wandb: spikes/train_avg_layer_3 1e-05
wandb:               train_loss 0.42853
wandb:      trainer/global_step 76
wandb:                 val_loss 0.42514
wandb: 
wandb: üöÄ View run chocolate-sweep-9 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/ysmgdt1g
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_115911-ysmgdt1g/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
    outputs = self(X_batch)
              ^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    lif_out, _states = lif(input_seq)  # lif_out: (T, B, F_hidden)
                       ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 171, in forward
    h_prev = h.detach()
             ^^^^^^^^^^
Exception

wandb: Agent Starting Run: r15w2nhx with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.411683053959495e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 3
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.9
wandb: setting up run r15w2nhx
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_120008-r15w2nhx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-10
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/r15w2nhx
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 52     | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
71        Trainable params
0         Non-trainable params
71        Total params
0.000     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: uploading history steps 76-83, summary, console lines 42-45
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ‚ñÅ‚ñÑ‚ñà
wandb:   grad_mean/lif_layers.1 ‚ñÉ‚ñà‚ñÖ‚ñÅ
wandb:   grad_mean/output_layer ‚ñÅ‚ñà‚ñÑ‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:               train_loss ‚ñà‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:                 val_loss ‚ñà‚ñá‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 39
wandb:   grad_mean/lif_layers.0 0.00499
wandb:   grad_mean/lif_layers.1 0.023
wandb:   grad_mean/output_layer 0.54563
wandb:                       lr 0
wandb: spikes/train_avg_layer_0 0.02189
wandb: spikes/train_avg_layer_1 0.01023
wandb:               train_loss 0.45103
wandb:      trainer/global_step 279
wandb:                 val_loss 0.44756
wandb: 
wandb: üöÄ View run lucky-sweep-10 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/r15w2nhx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_120008-r15w2nhx/logs
wandb: Agent Starting Run: ausud55z with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 9.074280975665308e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 1
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.9
wandb: setting up run ausud55z
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_120100-ausud55z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-11
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/ausud55z
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 944    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
975       Trainable params
0         Non-trainable params
975       Total params
0.004     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: uploading history steps 20-25, console lines 40-40; updating run metadata
wandb: uploading summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                       lr ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ
wandb: spikes/train_avg_layer_1 ‚ñÉ‚ñÅ‚ñÉ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñá
wandb: spikes/train_avg_layer_2 ‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñà
wandb: spikes/train_avg_layer_3 ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:               train_loss ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 12
wandb:                       lr 1e-05
wandb: spikes/train_avg_layer_0 0.03814
wandb: spikes/train_avg_layer_1 0.00681
wandb: spikes/train_avg_layer_2 0.001
wandb: spikes/train_avg_layer_3 0.0
wandb:               train_loss 0.37674
wandb:      trainer/global_step 90
wandb:                 val_loss 0.37358
wandb: 
wandb: üöÄ View run dutiful-sweep-11 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/ausud55z
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_120100-ausud55z/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
    outputs = self(X_batch)
              ^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    lif_out, _states = lif(input_seq)  # lif_out: (T, B, F_hidden)
                       ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 167, in forward
    x = self.rho * torch.tanh(i / self.rho)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: 7cm3hrkn with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.6029453903934532e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_120207-7cm3hrkn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-12
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/7cm3hrkn
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 29.6 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
29.7 K    Trainable params
0         Non-trainable params
29.7 K    Total params
0.119     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñà‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_1 ‚ñà‚ñÑ‚ñÜ‚ñÅ
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÅ‚ñà‚ñá
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 3
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.02006
wandb: spikes/train_avg_layer_1 0.00139
wandb: spikes/train_avg_layer_2 4e-05
wandb: spikes/train_avg_layer_3 0
wandb: spikes/train_avg_layer_4 0
wandb: spikes/train_avg_layer_5 0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run laced-sweep-12 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/7cm3hrkn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_120207-7cm3hrkn/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: pun80zd6 with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 6.7931200572818405e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.8
wandb: setting up run pun80zd6
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_120609-pun80zd6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-13
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/pun80zd6
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 248 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
248 K     Trainable params
0         Non-trainable params
248 K     Total params
0.995     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading summary
wandb: 
wandb: Run history:
wandb:                     epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                        lr ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ
wandb:  spikes/train_avg_layer_0 ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñà
wandb:  spikes/train_avg_layer_1 ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà
wandb: spikes/train_avg_layer_10 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_11 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_12 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_13 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_14 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_15 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +11 ...
wandb: 
wandb: Run summary:
wandb:                     epoch 12
wandb:                        lr 1e-05
wandb:  spikes/train_avg_layer_0 0.02069
wandb:  spikes/train_avg_layer_1 0.00116
wandb: spikes/train_avg_layer_10 0
wandb: spikes/train_avg_layer_11 0
wandb: spikes/train_avg_layer_12 0
wandb: spikes/train_avg_layer_13 0
wandb: spikes/train_avg_layer_14 0
wandb: spikes/train_avg_layer_15 0
wandb:                       +11 ...
wandb: 
wandb: üöÄ View run revived-sweep-13 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/pun80zd6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_120609-pun80zd6/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: v9p3u7od with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.7244834381203388e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 1
wandb: setting up run v9p3u7od
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_125908-v9p3u7od
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-14
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/v9p3u7od
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 944    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
975       Trainable params
0         Non-trainable params
975       Total params
0.004     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÉ‚ñÅ‚ñà‚ñÖ
wandb:   grad_mean/lif_layers.1 ‚ñÖ‚ñÅ‚ñà‚ñÑ
wandb:   grad_mean/lif_layers.2 ‚ñÖ‚ñÅ‚ñà‚ñÑ
wandb:   grad_mean/lif_layers.3 ‚ñÖ‚ñÅ‚ñà‚ñÉ
wandb:   grad_mean/output_layer ‚ñÑ‚ñÅ‚ñà‚ñÑ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: spikes/train_avg_layer_1 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: spikes/train_avg_layer_2 ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +4 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 39
wandb:   grad_mean/lif_layers.0 0.00571
wandb:   grad_mean/lif_layers.1 0.00274
wandb:   grad_mean/lif_layers.2 0.00251
wandb:   grad_mean/lif_layers.3 0.00246
wandb:   grad_mean/output_layer 0.15046
wandb:                       lr 0
wandb: spikes/train_avg_layer_0 0.02464
wandb: spikes/train_avg_layer_1 0.00302
wandb: spikes/train_avg_layer_2 0.0003
wandb:                       +4 ...
wandb: 
wandb: üöÄ View run bright-sweep-14 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/v9p3u7od
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_125908-v9p3u7od/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: m665lmnt with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.00022113613859836567
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_130234-m665lmnt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-15
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/m665lmnt
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 2.0 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
2.1 K     Trainable params
0         Non-trainable params
2.1 K     Total params
0.008     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading history steps 16-17, summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:                       lr ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñá‚ñà‚ñÖ‚ñÑ‚ñÑ
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 8
wandb:                       lr 0.00019
wandb: spikes/train_avg_layer_0 0.02415
wandb: spikes/train_avg_layer_1 0.00217
wandb: spikes/train_avg_layer_2 0.00018
wandb: spikes/train_avg_layer_3 0
wandb: spikes/train_avg_layer_4 0
wandb: spikes/train_avg_layer_5 0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run pleasant-sweep-15 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/m665lmnt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_130234-m665lmnt/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 153, in run
    self.on_advance_end(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 398, in on_advance_end
    self.val_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 145, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 437, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 412, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 620, in validation_step
    outputs = self(X_batch)
              ^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    lif_out, _states = lif(input_seq)  # lif_out: (T, B, F_hidden)
                       ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 189, in forward
    hs = zs * hs_prev + (1.0 - zs) * h_prev
                         ~~~~^~~~
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 38, in wrapped
    @functools.wraps(f)
    
Exception

wandb: Agent Starting Run: h7lyntqr with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 3.787085466885639e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.9
wandb: setting up run h7lyntqr
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_130407-h7lyntqr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-16
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/h7lyntqr
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 172    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
191       Trainable params
0         Non-trainable params
191       Total params
0.001     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
<function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
    self._shutdown_workers()  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers

  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    self._shutdown_workers()
    if w.is_alive():  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers

       ^^^^^^    ^^if w.is_alive():^
^^^ 
   File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
     ^^^^^^^^^^^^    
if w.is_alive():  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive

       ^^^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^
^^ ^ ^ ^ ^ 
   File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
     ^^^    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'^
^^^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'^^
^^^^ ^^ ^^ ^^ ^^ 
^ AssertionError^ : ^ can only test a child process^ 
^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^
^AssertionError^: ^can only test a child process^
^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception in thread QueueFeederThreadTraceback (most recent call last):
:
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^    ^self.run()^
^^^^  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1012, in run
^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
    self._target(*self._args, **self._kwargs)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 291, in _feed
    queue_sem.release()
ValueError: semaphore or lock released too many times
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
        if w.is_alive():if w.is_alive():

              ^^^^^^^^^^^^^^^^^^^^    ^^self._shutdown_workers()^^


  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           if w.is_alive():     
 assert self._parent_pid == os.getpid(), 'can only test a child process'  
  ^  ^  ^  ^  ^  ^ ^^ ^^ ^^ ^^ ^^ ^^^^^^^^^^^^^^^^^^^^^
^^  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
^^^^^^^^^^^^^^^^^^^^^^^^Exception ignored in: 
^AssertionError<function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>^: 
^can only test a child processTraceback (most recent call last):
^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
^^^^^^^
AssertionError: can only test a child process
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^    ^self._shutdown_workers()^
^^^^  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
^^^^^^^^
AssertionError: can only test a child process
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
OSError: [Errno 9] Bad file descriptor
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Traceback (most recent call last):
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()

  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
OSError: [Errno 9] Bad file descriptor
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                  epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: grad_mean/lif_layers.0 ‚ñÅ
wandb: grad_mean/lif_layers.1 ‚ñÅ
wandb: grad_mean/lif_layers.2 ‚ñÅ
wandb: grad_mean/lif_layers.3 ‚ñÅ
wandb: grad_mean/lif_layers.4 ‚ñÅ
wandb: grad_mean/lif_layers.5 ‚ñÅ
wandb: grad_mean/lif_layers.6 ‚ñÅ
wandb: grad_mean/lif_layers.7 ‚ñÅ
wandb: grad_mean/output_layer ‚ñÅ
wandb:                    +12 ...
wandb: 
wandb: Run summary:
wandb:                  epoch 18
wandb: grad_mean/lif_layers.0 0.00203
wandb: grad_mean/lif_layers.1 0.0027
wandb: grad_mean/lif_layers.2 0.00317
wandb: grad_mean/lif_layers.3 0.0046
wandb: grad_mean/lif_layers.4 0.00623
wandb: grad_mean/lif_layers.5 0.01138
wandb: grad_mean/lif_layers.6 0.01149
wandb: grad_mean/lif_layers.7 0.00836
wandb: grad_mean/output_layer 0.23066
wandb:                    +12 ...
wandb: 
wandb: üöÄ View run polished-sweep-16 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/h7lyntqr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_130407-h7lyntqr/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 153, in run
    self.on_advance_end(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 398, in on_advance_end
    self.val_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 145, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 437, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 412, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 620, in validation_step
    outputs = self(X_batch)
              ^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    lif_out, _states = lif(input_seq)  # lif_out: (T, B, F_hidden)
                       ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 167, in forward
    x = self.rho * torch.tanh(i / self.rho)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: z4ov41aw with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 3.10385970233246e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.9
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_130611-z4ov41aw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-17
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/z4ov41aw
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 116 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
116 K     Trainable params
0         Non-trainable params
116 K     Total params
0.467     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception in thread QueueFeederThread:
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1012, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 291, in _feed
    queue_sem.release()
ValueError: semaphore or lock released too many times
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÉ‚ñÜ‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÑ‚ñÅ‚ñÑ‚ñà
wandb: spikes/train_avg_layer_2 ‚ñá‚ñà‚ñÜ‚ñÅ
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 3
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.02263
wandb: spikes/train_avg_layer_1 0.00188
wandb: spikes/train_avg_layer_2 5e-05
wandb: spikes/train_avg_layer_3 0
wandb: spikes/train_avg_layer_4 0
wandb: spikes/train_avg_layer_5 0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run desert-sweep-17 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/z4ov41aw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_130611-z4ov41aw/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: 29z6t2wt with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.531818437354374e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.9
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_131410-29z6t2wt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-18
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/29z6t2wt
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 17.5 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
17.7 K    Trainable params
0         Non-trainable params
17.7 K    Total params
0.071     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
<function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>Traceback (most recent call last):

  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^Exception ignored in: ^^^^<function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>^
^^Traceback (most recent call last):
^  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
^^^^^^^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^
^^^ ^ ^ ^ ^ ^ ^ ^ ^ ^ 
 AssertionError^: ^can only test a child process^
^^^^^    ^self._shutdown_workers()^
^^^  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
 Exception ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620> 
 Traceback (most recent call last):
   File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
   ^^^^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^
^^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^    ^^
self._shutdown_workers()^AssertionError
^: ^can only test a child process^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
^^^^^^^^^^^^^^^
AssertionError: can only test a child process
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
wandb: updating run metadata
wandb: uploading console lines 52-52
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ
wandb:   grad_mean/lif_layers.1 ‚ñÅ
wandb:   grad_mean/output_layer ‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñà‚ñà
wandb:               train_loss ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 14
wandb:   grad_mean/lif_layers.0 0.0038
wandb:   grad_mean/lif_layers.1 0.00178
wandb:   grad_mean/output_layer 0.20423
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.02017
wandb: spikes/train_avg_layer_1 0.00137
wandb:               train_loss 0.201
wandb:      trainer/global_step 99
wandb:                 val_loss 0.19913
wandb: 
wandb: üöÄ View run frosty-sweep-18 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/29z6t2wt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_131410-29z6t2wt/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
    outputs = self(X_batch)
              ^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    lif_out, _states = lif(input_seq)  # lif_out: (T, B, F_hidden)
                       ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 171, in forward
    h_prev = h.detach()
             ^^^^^^^^^^
Exception

wandb: Agent Starting Run: 14c0rjzz with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 5.309096352338182e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 3
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_132011-14c0rjzz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-sweep-19
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/14c0rjzz
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 29.6 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
29.7 K    Trainable params
0         Non-trainable params
29.7 K    Total params
0.119     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñÑ‚ñÅ‚ñÜ‚ñÖ
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÇ‚ñÅ‚ñà‚ñá
wandb: spikes/train_avg_layer_2 ‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñà
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 4
wandb:                       lr 5e-05
wandb: spikes/train_avg_layer_0 0.01914
wandb: spikes/train_avg_layer_1 0.00119
wandb: spikes/train_avg_layer_2 1e-05
wandb: spikes/train_avg_layer_3 0
wandb: spikes/train_avg_layer_4 0
wandb: spikes/train_avg_layer_5 0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run charmed-sweep-19 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/14c0rjzz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_132011-14c0rjzz/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: d2go79t1 with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 2.1063948574057957e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.8
wandb: setting up run d2go79t1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_132408-d2go79t1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-20
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/d2go79t1
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 332    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
351       Trainable params
0         Non-trainable params
351       Total params
0.001     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: uploading history steps 82-83, summary, console lines 43-45
wandb: 
wandb: Run history:
wandb:                   epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:  grad_mean/lif_layers.0 ‚ñà‚ñÅ‚ñÑ‚ñÉ
wandb:  grad_mean/lif_layers.1 ‚ñÅ‚ñÖ‚ñÜ‚ñà
wandb: grad_mean/lif_layers.10 ‚ñÅ‚ñá‚ñÜ‚ñà
wandb: grad_mean/lif_layers.11 ‚ñÅ‚ñá‚ñÜ‚ñà
wandb: grad_mean/lif_layers.12 ‚ñÅ‚ñá‚ñÜ‚ñà
wandb: grad_mean/lif_layers.13 ‚ñÅ‚ñá‚ñÜ‚ñà
wandb: grad_mean/lif_layers.14 ‚ñÅ‚ñá‚ñÜ‚ñà
wandb: grad_mean/lif_layers.15 ‚ñÅ‚ñà‚ñÜ‚ñà
wandb:  grad_mean/lif_layers.2 ‚ñÅ‚ñÖ‚ñÜ‚ñà
wandb:                     +28 ...
wandb: 
wandb: Run summary:
wandb:                   epoch 39
wandb:  grad_mean/lif_layers.0 2e-05
wandb:  grad_mean/lif_layers.1 1e-05
wandb: grad_mean/lif_layers.10 0.00154
wandb: grad_mean/lif_layers.11 0.00248
wandb: grad_mean/lif_layers.12 0.00371
wandb: grad_mean/lif_layers.13 0.00291
wandb: grad_mean/lif_layers.14 0.00311
wandb: grad_mean/lif_layers.15 0.00311
wandb:  grad_mean/lif_layers.2 1e-05
wandb:                     +28 ...
wandb: 
wandb: üöÄ View run drawn-sweep-20 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/d2go79t1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_132408-d2go79t1/logs
wandb: Agent Starting Run: 51k9gtkp with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 2.856973614391325e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 1
wandb: setting up run 51k9gtkp
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_132903-51k9gtkp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-21
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/51k9gtkp
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 52     | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
71        Trainable params
0         Non-trainable params
71        Total params
0.000     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: uploading history steps 82-83, summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñá‚ñÜ‚ñÅ‚ñà
wandb:   grad_mean/lif_layers.1 ‚ñà‚ñÜ‚ñÅ‚ñÑ
wandb:   grad_mean/output_layer ‚ñà‚ñÅ‚ñá‚ñÉ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÜ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: spikes/train_avg_layer_1 ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:               train_loss ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 39
wandb:   grad_mean/lif_layers.0 0.0217
wandb:   grad_mean/lif_layers.1 0.01868
wandb:   grad_mean/output_layer 0.74235
wandb:                       lr 0
wandb: spikes/train_avg_layer_0 0.00824
wandb: spikes/train_avg_layer_1 0.00388
wandb:               train_loss 0.71132
wandb:      trainer/global_step 279
wandb:                 val_loss 0.70686
wandb: 
wandb: üöÄ View run still-sweep-21 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/51k9gtkp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_132903-51k9gtkp/logs
wandb: Agent Starting Run: 8makozzh with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.1207619391436483e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_132954-8makozzh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-22
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/8makozzh
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 29.6 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
29.7 K    Trainable params
0         Non-trainable params
29.7 K    Total params
0.119     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                       lr ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñá‚ñà‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñá‚ñà‚ñá‚ñÇ‚ñÅ‚ñÇ
wandb: spikes/train_avg_layer_1 ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñá‚ñà‚ñà‚ñÜ‚ñá‚ñà‚ñà
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 12
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.01791
wandb: spikes/train_avg_layer_1 0.00151
wandb: spikes/train_avg_layer_2 4e-05
wandb: spikes/train_avg_layer_3 0
wandb: spikes/train_avg_layer_4 0
wandb: spikes/train_avg_layer_5 0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run glorious-sweep-22 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/8makozzh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_132954-8makozzh/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: jjk63jeh with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 8.504383935848153e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 3
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_133911-jjk63jeh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-23
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/jjk63jeh
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 4.7 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
4.8 K     Trainable params
0         Non-trainable params
4.8 K     Total params
0.019     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÅ
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñà
wandb:               train_loss ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 4
wandb:                       lr 1e-05
wandb: spikes/train_avg_layer_0 0.01982
wandb: spikes/train_avg_layer_1 0.00096
wandb:               train_loss 0.3007
wandb:      trainer/global_step 34
wandb:                 val_loss 0.29794
wandb: 
wandb: üöÄ View run summer-sweep-23 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/jjk63jeh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_133911-jjk63jeh/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 315, in apply
    return user_fn(self, *args)
           ^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 61, in backward
    grad_input = grad_output.clone()
                 ^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: vjnrziuh with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.7223290429565332e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_134008-vjnrziuh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-24
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/vjnrziuh
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 13.0 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
13.1 K    Trainable params
0         Non-trainable params
13.1 K    Total params
0.052     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading history steps 8-9, summary, console lines 43-44
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÜ‚ñá‚ñà‚ñà
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               train_loss ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 4
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.0211
wandb: spikes/train_avg_layer_1 0.00153
wandb: spikes/train_avg_layer_2 4e-05
wandb: spikes/train_avg_layer_3 0
wandb:               train_loss 0.30324
wandb:      trainer/global_step 34
wandb:                 val_loss 0.30053
wandb: 
wandb: üöÄ View run worldly-sweep-24 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/vjnrziuh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_134008-vjnrziuh/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
    outputs = self(X_batch)
              ^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    lif_out, _states = lif(input_seq)  # lif_out: (T, B, F_hidden)
                       ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 192, in forward
    sout_t = self._relu(h)
             ^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 565, in apply
    @classmethod
    
Exception

wandb: Agent Starting Run: ghkzu6ht with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 5.965415708716437e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 3
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_134207-ghkzu6ht
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-25
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/ghkzu6ht
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 116 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
116 K     Trainable params
0         Non-trainable params
116 K     Total params
0.467     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÑ‚ñÅ‚ñÇ‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÉ‚ñÜ‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÇ‚ñÑ‚ñà
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 3
wandb:                       lr 1e-05
wandb: spikes/train_avg_layer_0 0.0194
wandb: spikes/train_avg_layer_1 0.00176
wandb: spikes/train_avg_layer_2 6e-05
wandb: spikes/train_avg_layer_3 0
wandb: spikes/train_avg_layer_4 0
wandb: spikes/train_avg_layer_5 0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run sleek-sweep-25 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/ghkzu6ht
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_134207-ghkzu6ht/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
    outputs = self(X_batch)
              ^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    lif_out, _states = lif(input_seq)  # lif_out: (T, B, F_hidden)
                       ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 163, in forward
    delta = torch.matmul(sin_t, self.Ws.t())  # (batch, hidden)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: ed1r6v04 with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.0001139428731626579
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 1
wandb: setting up run ed1r6v04
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_135012-ed1r6v04
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-26
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/ed1r6v04
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 92     | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
111       Trainable params
0         Non-trainable params
111       Total params
0.000     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-44
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ
wandb:   grad_mean/lif_layers.1 ‚ñÅ
wandb:   grad_mean/lif_layers.2 ‚ñÅ
wandb:   grad_mean/lif_layers.3 ‚ñÅ
wandb:   grad_mean/output_layer ‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +4 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 18
wandb:   grad_mean/lif_layers.0 0.00971
wandb:   grad_mean/lif_layers.1 0.00941
wandb:   grad_mean/lif_layers.2 0.00808
wandb:   grad_mean/lif_layers.3 0.00981
wandb:   grad_mean/output_layer 0.19686
wandb:                       lr 6e-05
wandb: spikes/train_avg_layer_0 0.01526
wandb: spikes/train_avg_layer_1 0.0051
wandb: spikes/train_avg_layer_2 0
wandb:                       +4 ...
wandb: 
wandb: üöÄ View run sweepy-sweep-26 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/ed1r6v04
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_135012-ed1r6v04/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
    outputs = self(X_batch)
              ^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    lif_out, _states = lif(input_seq)  # lif_out: (T, B, F_hidden)
                       ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 189, in forward
    hs = zs * hs_prev + (1.0 - zs) * h_prev
                         ~~~~^~~~
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 45, in wrapped
    return f(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 1075, in __rsub__
    return _C._VariableFunctions.rsub(self, other)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: gw05rx5y with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 2.2612752707444608e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 3
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.9
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_135110-gw05rx5y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-sweep-27
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/gw05rx5y
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 400    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
431       Trainable params
0         Non-trainable params
431       Total params
0.002     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1618, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/popen_fork.py", line 40, in wait
    if not wait([self.sentinel], timeout):
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 1136, in wait
    ready = selector.select(timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Exception: 
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: uploading console lines 42-62
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÖ‚ñÅ‚ñà‚ñÇ
wandb:   grad_mean/lif_layers.1 ‚ñÜ‚ñÑ‚ñà‚ñÅ
wandb:   grad_mean/output_layer ‚ñÜ‚ñÖ‚ñà‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: spikes/train_avg_layer_1 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 39
wandb:   grad_mean/lif_layers.0 0.02021
wandb:   grad_mean/lif_layers.1 0.00775
wandb:   grad_mean/output_layer 0.35237
wandb:                       lr 0
wandb: spikes/train_avg_layer_0 0.01756
wandb: spikes/train_avg_layer_1 0.0009
wandb:               train_loss 0.29137
wandb:      trainer/global_step 279
wandb:                 val_loss 0.28875
wandb: 
wandb: üöÄ View run wise-sweep-27 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/gw05rx5y
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_135110-gw05rx5y/logs
wandb: Agent Starting Run: db3bhatm with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.675936357322927e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.8
wandb: setting up run db3bhatm
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_135251-db3bhatm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-28
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/db3bhatm
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 400    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
431       Trainable params
0         Non-trainable params
431       Total params
0.002     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading history steps 52-62, summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ‚ñà‚ñá
wandb:   grad_mean/lif_layers.1 ‚ñÅ‚ñÜ‚ñà
wandb:   grad_mean/output_layer ‚ñÅ‚ñÖ‚ñà
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb: spikes/train_avg_layer_1 ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ
wandb:               train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 29
wandb:   grad_mean/lif_layers.0 0.01089
wandb:   grad_mean/lif_layers.1 0.0099
wandb:   grad_mean/output_layer 0.35366
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.02822
wandb: spikes/train_avg_layer_1 0.00248
wandb:               train_loss 0.28358
wandb:      trainer/global_step 209
wandb:                 val_loss 0.28099
wandb: 
wandb: üöÄ View run pleasant-sweep-28 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/db3bhatm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_135251-db3bhatm/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 315, in apply
    return user_fn(self, *args)
           ^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 61, in backward
    grad_input = grad_output.clone()
                 ^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: hjsthmre with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 2.6981889194336622e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_135411-hjsthmre
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-29
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/hjsthmre
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 52     | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
71        Trainable params
0         Non-trainable params
71        Total params
0.000     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: uploading history steps 76-83, summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÑ‚ñà‚ñÅ‚ñà
wandb:   grad_mean/lif_layers.1 ‚ñÅ‚ñÉ‚ñÑ‚ñà
wandb:   grad_mean/output_layer ‚ñÇ‚ñÅ‚ñÖ‚ñà
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: spikes/train_avg_layer_1 ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ
wandb:               train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 39
wandb:   grad_mean/lif_layers.0 0.02904
wandb:   grad_mean/lif_layers.1 0.02924
wandb:   grad_mean/output_layer 0.75682
wandb:                       lr 0
wandb: spikes/train_avg_layer_0 0.03
wandb: spikes/train_avg_layer_1 0.00288
wandb:               train_loss 0.7295
wandb:      trainer/global_step 279
wandb:                 val_loss 0.72496
wandb: 
wandb: üöÄ View run lucky-sweep-29 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/hjsthmre
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_135411-hjsthmre/logs
wandb: Agent Starting Run: bjq2xjnh with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.939277197184247e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 3
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_135508-bjq2xjnh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run driven-sweep-30
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/bjq2xjnh
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 248 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
248 K     Trainable params
0         Non-trainable params
248 K     Total params
0.995     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                     epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                        lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb:  spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÖ‚ñà
wandb:  spikes/train_avg_layer_1 ‚ñÜ‚ñá‚ñà‚ñÅ
wandb: spikes/train_avg_layer_10 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_11 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_12 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_13 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_14 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_15 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +11 ...
wandb: 
wandb: Run summary:
wandb:                     epoch 3
wandb:                        lr 0.0
wandb:  spikes/train_avg_layer_0 0.01999
wandb:  spikes/train_avg_layer_1 0.00162
wandb: spikes/train_avg_layer_10 0
wandb: spikes/train_avg_layer_11 0
wandb: spikes/train_avg_layer_12 0
wandb: spikes/train_avg_layer_13 0
wandb: spikes/train_avg_layer_14 0
wandb: spikes/train_avg_layer_15 0
wandb:                       +11 ...
wandb: 
wandb: üöÄ View run driven-sweep-30 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/bjq2xjnh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_135508-bjq2xjnh/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: qrbdcj35 with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 4.474401741012071e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 3
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.8
wandb: setting up run qrbdcj35
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_141209-qrbdcj35
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-31
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/qrbdcj35
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 944    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
975       Trainable params
0         Non-trainable params
975       Total params
0.004     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÇ‚ñÅ‚ñà‚ñà
wandb:   grad_mean/lif_layers.1 ‚ñÅ‚ñÉ‚ñà‚ñÜ
wandb:   grad_mean/lif_layers.2 ‚ñÅ‚ñÉ‚ñà‚ñÖ
wandb:   grad_mean/lif_layers.3 ‚ñÅ‚ñÇ‚ñà‚ñÖ
wandb:   grad_mean/output_layer ‚ñÅ‚ñÉ‚ñà‚ñÖ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÇ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà
wandb: spikes/train_avg_layer_1 ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_2 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +4 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 39
wandb:   grad_mean/lif_layers.0 0.00503
wandb:   grad_mean/lif_layers.1 0.00122
wandb:   grad_mean/lif_layers.2 0.00072
wandb:   grad_mean/lif_layers.3 0.0012
wandb:   grad_mean/output_layer 0.05421
wandb:                       lr 0
wandb: spikes/train_avg_layer_0 0.02035
wandb: spikes/train_avg_layer_1 0.00056
wandb: spikes/train_avg_layer_2 0.0
wandb:                       +4 ...
wandb: 
wandb: üöÄ View run upbeat-sweep-31 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/qrbdcj35
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_141209-qrbdcj35/logs
wandb: Agent Starting Run: qe85q1pm with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.00022769145095116795
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.8
wandb: setting up run qe85q1pm
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_141530-qe85q1pm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-32
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/qe85q1pm
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 400    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
431       Trainable params
0         Non-trainable params
431       Total params
0.002     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ
wandb:   grad_mean/lif_layers.1 ‚ñÅ
wandb:   grad_mean/output_layer ‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb:               train_loss ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 14
wandb:   grad_mean/lif_layers.0 0.0221
wandb:   grad_mean/lif_layers.1 0.00949
wandb:   grad_mean/output_layer 0.37295
wandb:                       lr 0.00017
wandb: spikes/train_avg_layer_0 0.02196
wandb: spikes/train_avg_layer_1 0.00189
wandb:               train_loss 0.30108
wandb:      trainer/global_step 99
wandb:                 val_loss 0.29753
wandb: 
wandb: üöÄ View run stilted-sweep-32 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/qe85q1pm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_141530-qe85q1pm/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 153, in run
    self.on_advance_end(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 398, in on_advance_end
    self.val_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 145, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 437, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 412, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 620, in validation_step
    outputs = self(X_batch)
              ^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    lif_out, _states = lif(input_seq)  # lif_out: (T, B, F_hidden)
                       ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 163, in forward
    delta = torch.matmul(sin_t, self.Ws.t())  # (batch, hidden)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: rzwhw5w2 with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 5.641032030208905e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.9
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_141611-rzwhw5w2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-sweep-33
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/rzwhw5w2
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 332    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
351       Trainable params
0         Non-trainable params
351       Total params
0.001     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
Exception ignored in:         <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>self._shutdown_workers()if w.is_alive():


Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
     ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
          assert self._parent_pid == os.getpid(), 'can only test a child process' 
^^ ^ ^ ^ ^ ^ ^ ^     ^if w.is_alive(): ^
 ^  
^   File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^
^  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
^^^^^^^^^^^
AssertionError:     can only test a child processassert self._parent_pid == os.getpid(), 'can only test a child process'

             assert self._parent_pid == os.getpid(), 'can only test a child process' 
 ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^AssertionError^: ^can only test a child process^
^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
Exception in thread QueueFeederThread:
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
Traceback (most recent call last):
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1012, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 291, in _feed
    Traceback (most recent call last):
queue_sem.release()
ValueError: semaphore or lock released too many times
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
Exception ignored in:   File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
<function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>    
self._shutdown_workers()Traceback (most recent call last):

  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^    ^^self._shutdown_workers()^Exception ignored in: 
^<function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>^
    ^Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
if w.is_alive():^  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__

^^ 
   File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
     ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    if w.is_alive():
       ^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^
^^ ^     ^assert self._parent_pid == os.getpid(), 'can only test a child process' ^    
 ^self._shutdown_workers() ^ 
 ^  ^  
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
     ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    ^^    assert self._parent_pid == os.getpid(), 'can only test a child process'^^if w.is_alive():
^^
^^ ^ ^ ^ ^ ^ ^ ^ 
 ^ AssertionError ^ :  ^ can only test a child process ^^
 
^ AssertionError^ : ^^can only test a child process^^
^^^^^^^^^^^^^^
^  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
OSError: [Errno 9] Bad file descriptor
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^
^^^ ^ ^ ^ 
 AssertionError :  can only test a child process 
   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: uploading console lines 52-52
wandb: 
wandb: Run history:
wandb:                   epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:  grad_mean/lif_layers.0 ‚ñà‚ñÜ‚ñÅ‚ñÉ
wandb:  grad_mean/lif_layers.1 ‚ñà‚ñÜ‚ñÅ‚ñÖ
wandb: grad_mean/lif_layers.10 ‚ñÅ‚ñÅ‚ñÖ‚ñà
wandb: grad_mean/lif_layers.11 ‚ñÇ‚ñÅ‚ñÜ‚ñà
wandb: grad_mean/lif_layers.12 ‚ñÉ‚ñÅ‚ñÜ‚ñà
wandb: grad_mean/lif_layers.13 ‚ñÑ‚ñÅ‚ñá‚ñà
wandb: grad_mean/lif_layers.14 ‚ñÑ‚ñÅ‚ñá‚ñà
wandb: grad_mean/lif_layers.15 ‚ñÑ‚ñÅ‚ñá‚ñà
wandb:  grad_mean/lif_layers.2 ‚ñà‚ñÑ‚ñÅ‚ñà
wandb:                     +28 ...
wandb: 
wandb: Run summary:
wandb:                   epoch 39
wandb:  grad_mean/lif_layers.0 0.0004
wandb:  grad_mean/lif_layers.1 0.00012
wandb: grad_mean/lif_layers.10 0.00157
wandb: grad_mean/lif_layers.11 0.00111
wandb: grad_mean/lif_layers.12 0.0027
wandb: grad_mean/lif_layers.13 0.0027
wandb: grad_mean/lif_layers.14 0.00211
wandb: grad_mean/lif_layers.15 0.00275
wandb:  grad_mean/lif_layers.2 0.00014
wandb:                     +28 ...
wandb: 
wandb: üöÄ View run worthy-sweep-33 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/rzwhw5w2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_141611-rzwhw5w2/logs
wandb: Agent Starting Run: psa6tyfb with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 3.218982456974211e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 3
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.8
wandb: setting up run psa6tyfb
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_142136-psa6tyfb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-34
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/psa6tyfb
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 29.6 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
29.7 K    Trainable params
0         Non-trainable params
29.7 K    Total params
0.119     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñà‚ñÑ‚ñÉ
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÑ‚ñÜ‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÅ‚ñà‚ñá
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 3
wandb:                       lr 3e-05
wandb: spikes/train_avg_layer_0 0.01954
wandb: spikes/train_avg_layer_1 0.0013
wandb: spikes/train_avg_layer_2 1e-05
wandb: spikes/train_avg_layer_3 0
wandb: spikes/train_avg_layer_4 0
wandb: spikes/train_avg_layer_5 0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run icy-sweep-34 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/psa6tyfb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_142136-psa6tyfb/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: jfy5z4r8 with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.0007430485916480315
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 1
wandb: setting up run jfy5z4r8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_142508-jfy5z4r8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-35
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/jfy5z4r8
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 116 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
116 K     Trainable params
0         Non-trainable params
116 K     Total params
0.467     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                  epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: grad_mean/lif_layers.0 ‚ñÅ‚ñÉ‚ñá‚ñà
wandb: grad_mean/lif_layers.1 ‚ñÅ‚ñÉ‚ñÜ‚ñà
wandb: grad_mean/lif_layers.2 ‚ñÅ‚ñÉ‚ñá‚ñà
wandb: grad_mean/lif_layers.3 ‚ñÅ‚ñÉ‚ñá‚ñà
wandb: grad_mean/lif_layers.4 ‚ñÅ‚ñÑ‚ñá‚ñà
wandb: grad_mean/lif_layers.5 ‚ñÅ‚ñÖ‚ñà‚ñà
wandb: grad_mean/lif_layers.6 ‚ñÅ‚ñÜ‚ñà‚ñà
wandb: grad_mean/lif_layers.7 ‚ñà‚ñÇ‚ñÅ‚ñÅ
wandb: grad_mean/output_layer ‚ñà‚ñÑ‚ñÇ‚ñÅ
wandb:                    +12 ...
wandb: 
wandb: Run summary:
wandb:                  epoch 39
wandb: grad_mean/lif_layers.0 2342.53638
wandb: grad_mean/lif_layers.1 216.85454
wandb: grad_mean/lif_layers.2 18.97678
wandb: grad_mean/lif_layers.3 1.29413
wandb: grad_mean/lif_layers.4 0.09267
wandb: grad_mean/lif_layers.5 0.00802
wandb: grad_mean/lif_layers.6 0.00073
wandb: grad_mean/lif_layers.7 6e-05
wandb: grad_mean/output_layer 0.10988
wandb:                    +12 ...
wandb: 
wandb: üöÄ View run dry-sweep-35 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/jfy5z4r8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_142508-jfy5z4r8/logs
wandb: Agent Starting Run: 1qx79j7y with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 6.246187068903071e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.9
wandb: setting up run 1qx79j7y
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_154118-1qx79j7y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-36
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/1qx79j7y
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 248 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
248 K     Trainable params
0         Non-trainable params
248 K     Total params
0.995     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading summary
wandb: 
wandb: Run history:
wandb:                     epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                        lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb:  spikes/train_avg_layer_0 ‚ñÅ‚ñà‚ñà‚ñá
wandb:  spikes/train_avg_layer_1 ‚ñÜ‚ñÅ‚ñÉ‚ñà
wandb: spikes/train_avg_layer_10 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_11 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_12 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_13 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_14 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_15 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +11 ...
wandb: 
wandb: Run summary:
wandb:                     epoch 3
wandb:                        lr 1e-05
wandb:  spikes/train_avg_layer_0 0.01954
wandb:  spikes/train_avg_layer_1 0.00118
wandb: spikes/train_avg_layer_10 0
wandb: spikes/train_avg_layer_11 0
wandb: spikes/train_avg_layer_12 0
wandb: spikes/train_avg_layer_13 0
wandb: spikes/train_avg_layer_14 0
wandb: spikes/train_avg_layer_15 0
wandb:                       +11 ...
wandb: 
wandb: üöÄ View run vital-sweep-36 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/1qx79j7y
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_154118-1qx79j7y/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: njxggvsk with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.427664791208415e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.8
wandb: setting up run njxggvsk
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_155712-njxggvsk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-37
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/njxggvsk
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 13.0 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
13.1 K    Trainable params
0         Non-trainable params
13.1 K    Total params
0.052     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÜ‚ñà‚ñÅ‚ñÇ‚ñá
wandb: spikes/train_avg_layer_1 ‚ñà‚ñà‚ñÉ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_2 ‚ñà‚ñà‚ñÜ‚ñÉ‚ñÅ
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               train_loss ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 4
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.01472
wandb: spikes/train_avg_layer_1 0.00061
wandb: spikes/train_avg_layer_2 0.0
wandb: spikes/train_avg_layer_3 0
wandb:               train_loss 0.26636
wandb:      trainer/global_step 34
wandb:                 val_loss 0.26391
wandb: 
wandb: üöÄ View run deep-sweep-37 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/njxggvsk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_155712-njxggvsk/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 153, in run
    self.on_advance_end(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 398, in on_advance_end
    self.val_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 145, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 437, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 412, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 620, in validation_step
    layer_outputs.append(x_seq)
      ^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 185, in forward
    h_candidate = torch.tanh(preact)
                  ^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: hyz56lfm with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.00019915408462652185
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.8
wandb: setting up run hyz56lfm
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_155911-hyz56lfm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-38
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/hyz56lfm
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 50.6 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
50.7 K    Trainable params
0         Non-trainable params
50.7 K    Total params
0.203     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception in thread QueueFeederThread:
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1012, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 291, in _feed
    queue_sem.release()
ValueError: semaphore or lock released too many times
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÇ‚ñÑ‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÅ‚ñÑ‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÅ‚ñÉ‚ñà
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñà
wandb:               train_loss ‚ñà‚ñÜ‚ñÉ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñÜ‚ñÉ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 3
wandb:                       lr 0.00019
wandb: spikes/train_avg_layer_0 0.01867
wandb: spikes/train_avg_layer_1 0.00186
wandb: spikes/train_avg_layer_2 0.00037
wandb: spikes/train_avg_layer_3 0.0
wandb:               train_loss 0.29381
wandb:      trainer/global_step 27
wandb:                 val_loss 0.29052
wandb: 
wandb: üöÄ View run dry-sweep-38 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/hyz56lfm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_155911-hyz56lfm/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: 4x6vojir with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 6.6418157154575e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 3
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_160308-4x6vojir
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-39
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/4x6vojir
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 944    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
975       Trainable params
0         Non-trainable params
975       Total params
0.004     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñà‚ñÉ‚ñÅ‚ñÜ
wandb:   grad_mean/lif_layers.1 ‚ñÜ‚ñÇ‚ñÅ‚ñà
wandb:   grad_mean/lif_layers.2 ‚ñÇ‚ñÅ‚ñÉ‚ñà
wandb:   grad_mean/lif_layers.3 ‚ñÇ‚ñÅ‚ñÑ‚ñà
wandb:   grad_mean/output_layer ‚ñÅ‚ñÅ‚ñÑ‚ñà
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: spikes/train_avg_layer_1 ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: spikes/train_avg_layer_2 ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +4 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 39
wandb:   grad_mean/lif_layers.0 0.00206
wandb:   grad_mean/lif_layers.1 0.00059
wandb:   grad_mean/lif_layers.2 0.00053
wandb:   grad_mean/lif_layers.3 0.00095
wandb:   grad_mean/output_layer 0.04213
wandb:                       lr 0
wandb: spikes/train_avg_layer_0 0.0204
wandb: spikes/train_avg_layer_1 0.00156
wandb: spikes/train_avg_layer_2 0.00015
wandb:                       +4 ...
wandb: 
wandb: üöÄ View run laced-sweep-39 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/4x6vojir
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_160308-4x6vojir/logs
wandb: Agent Starting Run: rt007w1q with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.957346557016472e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_160625-rt007w1q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-40
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/rt007w1q
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 400    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
431       Trainable params
0         Non-trainable params
431       Total params
0.002     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: uploading history steps 12-25, console lines 40-40; updating run metadata
wandb: uploading history steps 26-30, summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ
wandb:   grad_mean/lif_layers.1 ‚ñÅ
wandb:   grad_mean/output_layer ‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_1 ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ
wandb:               train_loss ‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 14
wandb:   grad_mean/lif_layers.0 0.01754
wandb:   grad_mean/lif_layers.1 0.00946
wandb:   grad_mean/output_layer 0.33459
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.0254
wandb: spikes/train_avg_layer_1 0.00295
wandb:               train_loss 0.27456
wandb:      trainer/global_step 104
wandb:                 val_loss 0.27191
wandb: 
wandb: üöÄ View run jumping-sweep-40 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/rt007w1q
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_160625-rt007w1q/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 180, in forward
    H = (h_prev > 0.5).float()
        ^^^^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: cuhbpx4g with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.0007075520541630464
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.9
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_160707-cuhbpx4g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-41
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/cuhbpx4g
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 332    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
351       Trainable params
0         Non-trainable params
351       Total params
0.001     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                   epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:  grad_mean/lif_layers.0 ‚ñÜ‚ñà‚ñÑ‚ñÅ
wandb:  grad_mean/lif_layers.1 ‚ñà‚ñÑ‚ñÅ‚ñÅ
wandb: grad_mean/lif_layers.10 ‚ñà‚ñÉ‚ñÅ‚ñÅ
wandb: grad_mean/lif_layers.11 ‚ñà‚ñÉ‚ñÅ‚ñÅ
wandb: grad_mean/lif_layers.12 ‚ñà‚ñÉ‚ñÅ‚ñÅ
wandb: grad_mean/lif_layers.13 ‚ñà‚ñÉ‚ñÅ‚ñÅ
wandb: grad_mean/lif_layers.14 ‚ñà‚ñÉ‚ñÅ‚ñÅ
wandb: grad_mean/lif_layers.15 ‚ñà‚ñÉ‚ñÅ‚ñÅ
wandb:  grad_mean/lif_layers.2 ‚ñà‚ñÑ‚ñÅ‚ñÇ
wandb:                     +28 ...
wandb: 
wandb: Run summary:
wandb:                   epoch 39
wandb:  grad_mean/lif_layers.0 0.0
wandb:  grad_mean/lif_layers.1 0.0
wandb: grad_mean/lif_layers.10 0.00031
wandb: grad_mean/lif_layers.11 0.00068
wandb: grad_mean/lif_layers.12 0.00059
wandb: grad_mean/lif_layers.13 0.00088
wandb: grad_mean/lif_layers.14 0.00075
wandb: grad_mean/lif_layers.15 0.00088
wandb:  grad_mean/lif_layers.2 1e-05
wandb:                     +28 ...
wandb: 
wandb: üöÄ View run usual-sweep-41 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/cuhbpx4g
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_160707-cuhbpx4g/logs
wandb: Agent Starting Run: 8zbe3mps with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 8.302234594685292e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.9
wandb: setting up run 8zbe3mps
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_161151-8zbe3mps
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-42
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/8zbe3mps
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 172    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
191       Trainable params
0         Non-trainable params
191       Total params
0.001     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                  epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: grad_mean/lif_layers.0 ‚ñÅ
wandb: grad_mean/lif_layers.1 ‚ñÅ
wandb: grad_mean/lif_layers.2 ‚ñÅ
wandb: grad_mean/lif_layers.3 ‚ñÅ
wandb: grad_mean/lif_layers.4 ‚ñÅ
wandb: grad_mean/lif_layers.5 ‚ñÅ
wandb: grad_mean/lif_layers.6 ‚ñÅ
wandb: grad_mean/lif_layers.7 ‚ñÅ
wandb: grad_mean/output_layer ‚ñÅ
wandb:                    +12 ...
wandb: 
wandb: Run summary:
wandb:                  epoch 18
wandb: grad_mean/lif_layers.0 0.00294
wandb: grad_mean/lif_layers.1 0.00158
wandb: grad_mean/lif_layers.2 0.00181
wandb: grad_mean/lif_layers.3 0.00204
wandb: grad_mean/lif_layers.4 0.00365
wandb: grad_mean/lif_layers.5 0.00488
wandb: grad_mean/lif_layers.6 0.00563
wandb: grad_mean/lif_layers.7 0.01251
wandb: grad_mean/output_layer 0.30386
wandb:                    +12 ...
wandb: 
wandb: üöÄ View run amber-sweep-42 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/8zbe3mps
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_161151-8zbe3mps/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: go0fxqby with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 2.333562491616714e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_161308-go0fxqby
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-43
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/go0fxqby
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 172    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
191       Trainable params
0         Non-trainable params
191       Total params
0.001     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: uploading history steps 76-83, summary, console lines 42-44
wandb: 
wandb: Run history:
wandb:                  epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: grad_mean/lif_layers.0 ‚ñà‚ñÅ‚ñÉ‚ñà
wandb: grad_mean/lif_layers.1 ‚ñÖ‚ñà‚ñà‚ñÅ
wandb: grad_mean/lif_layers.2 ‚ñÖ‚ñá‚ñà‚ñÅ
wandb: grad_mean/lif_layers.3 ‚ñÜ‚ñá‚ñà‚ñÅ
wandb: grad_mean/lif_layers.4 ‚ñÜ‚ñá‚ñà‚ñÅ
wandb: grad_mean/lif_layers.5 ‚ñÜ‚ñá‚ñà‚ñÅ
wandb: grad_mean/lif_layers.6 ‚ñÜ‚ñá‚ñà‚ñÅ
wandb: grad_mean/lif_layers.7 ‚ñá‚ñá‚ñà‚ñÅ
wandb: grad_mean/output_layer ‚ñÜ‚ñÜ‚ñà‚ñÅ
wandb:                    +12 ...
wandb: 
wandb: Run summary:
wandb:                  epoch 39
wandb: grad_mean/lif_layers.0 0.00413
wandb: grad_mean/lif_layers.1 0.00041
wandb: grad_mean/lif_layers.2 0.00075
wandb: grad_mean/lif_layers.3 0.00088
wandb: grad_mean/lif_layers.4 0.00079
wandb: grad_mean/lif_layers.5 0.0011
wandb: grad_mean/lif_layers.6 0.0008
wandb: grad_mean/lif_layers.7 0.00069
wandb: grad_mean/output_layer 0.02531
wandb:                    +12 ...
wandb: 
wandb: üöÄ View run efficient-sweep-43 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/go0fxqby
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_161308-go0fxqby/logs
wandb: Agent Starting Run: 68s2mf18 with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.00026347012578315025
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_161543-68s2mf18
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-44
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/68s2mf18
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 172    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
191       Trainable params
0         Non-trainable params
191       Total params
0.001     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: uploading console lines 42-43
wandb: 
wandb: Run history:
wandb:                  epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: grad_mean/lif_layers.0 ‚ñà‚ñá‚ñÖ‚ñÅ
wandb: grad_mean/lif_layers.1 ‚ñà‚ñÖ‚ñÖ‚ñÅ
wandb: grad_mean/lif_layers.2 ‚ñà‚ñÑ‚ñÑ‚ñÅ
wandb: grad_mean/lif_layers.3 ‚ñà‚ñÑ‚ñÑ‚ñÅ
wandb: grad_mean/lif_layers.4 ‚ñà‚ñÑ‚ñÑ‚ñÅ
wandb: grad_mean/lif_layers.5 ‚ñà‚ñÖ‚ñÖ‚ñÅ
wandb: grad_mean/lif_layers.6 ‚ñà‚ñÑ‚ñÖ‚ñÅ
wandb: grad_mean/lif_layers.7 ‚ñà‚ñÑ‚ñÖ‚ñÅ
wandb: grad_mean/output_layer ‚ñà‚ñÑ‚ñÖ‚ñÅ
wandb:                    +12 ...
wandb: 
wandb: Run summary:
wandb:                  epoch 39
wandb: grad_mean/lif_layers.0 0.00021
wandb: grad_mean/lif_layers.1 0.00022
wandb: grad_mean/lif_layers.2 0.00023
wandb: grad_mean/lif_layers.3 0.00045
wandb: grad_mean/lif_layers.4 0.00045
wandb: grad_mean/lif_layers.5 0.0006
wandb: grad_mean/lif_layers.6 0.00062
wandb: grad_mean/lif_layers.7 0.00132
wandb: grad_mean/output_layer 0.03542
wandb:                    +12 ...
wandb: 
wandb: üöÄ View run frosty-sweep-44 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/68s2mf18
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_161543-68s2mf18/logs
wandb: Agent Starting Run: t6fq64wn with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 8.560258251122763e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 3
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.9
wandb: setting up run t6fq64wn
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_161813-t6fq64wn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-45
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/t6fq64wn
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 944    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
975       Trainable params
0         Non-trainable params
975       Total params
0.004     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: uploading history steps 78-83, summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñà‚ñÅ‚ñÅ‚ñÜ
wandb:   grad_mean/lif_layers.1 ‚ñÑ‚ñÖ‚ñÅ‚ñà
wandb:   grad_mean/lif_layers.2 ‚ñà‚ñá‚ñÅ‚ñá
wandb:   grad_mean/lif_layers.3 ‚ñà‚ñÜ‚ñÅ‚ñÜ
wandb:   grad_mean/output_layer ‚ñà‚ñÜ‚ñÅ‚ñÜ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +4 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 39
wandb:   grad_mean/lif_layers.0 0.00272
wandb:   grad_mean/lif_layers.1 0.001
wandb:   grad_mean/lif_layers.2 0.00101
wandb:   grad_mean/lif_layers.3 0.0014
wandb:   grad_mean/output_layer 0.07824
wandb:                       lr 0
wandb: spikes/train_avg_layer_0 0.01263
wandb: spikes/train_avg_layer_1 0.00164
wandb: spikes/train_avg_layer_2 0.0
wandb:                       +4 ...
wandb: 
wandb: üöÄ View run dazzling-sweep-45 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/t6fq64wn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_161813-t6fq64wn/logs
wandb: Agent Starting Run: cipy4m21 with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.0003851382149966893
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.9
wandb: setting up run cipy4m21
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_162114-cipy4m21
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-46
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/cipy4m21
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 400    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
431       Trainable params
0         Non-trainable params
431       Total params
0.002     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: uploading history steps 69-81, console lines 40-40; updating run metadata
wandb: uploading console lines 42-43
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñà‚ñÑ‚ñÇ‚ñÅ
wandb:   grad_mean/lif_layers.1 ‚ñà‚ñÉ‚ñÇ‚ñÅ
wandb:   grad_mean/output_layer ‚ñà‚ñÇ‚ñÉ‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:               train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:                 val_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 39
wandb:   grad_mean/lif_layers.0 0.00362
wandb:   grad_mean/lif_layers.1 0.00156
wandb:   grad_mean/output_layer 0.04058
wandb:                       lr 0
wandb: spikes/train_avg_layer_0 0.03885
wandb: spikes/train_avg_layer_1 0.0139
wandb:               train_loss 0.15688
wandb:      trainer/global_step 279
wandb:                 val_loss 0.15556
wandb: 
wandb: üöÄ View run unique-sweep-46 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/cipy4m21
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_162114-cipy4m21/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: i4ehzps9 with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 6.848539928182084e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 1
wandb: setting up run i4ehzps9
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_162257-i4ehzps9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-47
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/i4ehzps9
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 13.0 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
13.1 K    Trainable params
0         Non-trainable params
13.1 K    Total params
0.052     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñà
wandb:               train_loss ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÇ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 5
wandb:                       lr 1e-05
wandb: spikes/train_avg_layer_0 0.02383
wandb: spikes/train_avg_layer_1 0.00266
wandb: spikes/train_avg_layer_2 0.00035
wandb: spikes/train_avg_layer_3 0.0
wandb:               train_loss 0.23965
wandb:      trainer/global_step 41
wandb:                 val_loss 0.23741
wandb: 
wandb: üöÄ View run hardy-sweep-47 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/i4ehzps9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_162257-i4ehzps9/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: sssoexnx with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 3.1791881187667465e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 1
wandb: setting up run sssoexnx
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_162507-sssoexnx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-48
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/sssoexnx
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 52     | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
71        Trainable params
0         Non-trainable params
71        Total params
0.000     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: uploading history steps 71-83, summary, console lines 42-44
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÉ‚ñÅ‚ñÅ‚ñà
wandb:   grad_mean/lif_layers.1 ‚ñà‚ñÅ‚ñÇ‚ñÑ
wandb:   grad_mean/output_layer ‚ñà‚ñÅ‚ñÅ‚ñÖ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:               train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:                 val_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 39
wandb:   grad_mean/lif_layers.0 0.00308
wandb:   grad_mean/lif_layers.1 0.00359
wandb:   grad_mean/output_layer 0.06779
wandb:                       lr 0
wandb: spikes/train_avg_layer_0 0.03452
wandb: spikes/train_avg_layer_1 0.0018
wandb:               train_loss 0.16584
wandb:      trainer/global_step 279
wandb:                 val_loss 0.16465
wandb: 
wandb: üöÄ View run upbeat-sweep-48 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/sssoexnx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_162507-sssoexnx/logs
wandb: Agent Starting Run: 2h5ccmnj with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.000131488256781281
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_162604-2h5ccmnj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-49
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/2h5ccmnj
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 400    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
431       Trainable params
0         Non-trainable params
431       Total params
0.002     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñà‚ñÅ
wandb:   grad_mean/lif_layers.1 ‚ñà‚ñÅ
wandb:   grad_mean/output_layer ‚ñà‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:               train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 24
wandb:   grad_mean/lif_layers.0 0.02056
wandb:   grad_mean/lif_layers.1 0.01065
wandb:   grad_mean/output_layer 0.40182
wandb:                       lr 4e-05
wandb: spikes/train_avg_layer_0 0.02892
wandb: spikes/train_avg_layer_1 0.00262
wandb:               train_loss 0.32365
wandb:      trainer/global_step 174
wandb:                 val_loss 0.32074
wandb: 
wandb: üöÄ View run silvery-sweep-49 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/2h5ccmnj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_162604-2h5ccmnj/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 153, in run
    self.on_advance_end(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 398, in on_advance_end
    self.val_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 145, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 437, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 412, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 620, in validation_step
    layer_outputs.append(x_seq)
      ^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 167, in forward
    x = self.rho * torch.tanh(i / self.rho)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: 3oxoz1wc with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.0004818618875422161
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 1
wandb: setting up run 3oxoz1wc
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_162711-3oxoz1wc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-50
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/3oxoz1wc
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 29.6 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
29.7 K    Trainable params
0         Non-trainable params
29.7 K    Total params
0.119     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Traceback (most recent call last):
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
      File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
OSError: [Errno 9] Bad file descriptor
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
Exception in thread QueueFeederThread:
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1012, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 291, in _feed
    queue_sem.release()
ValueError: semaphore or lock released too many times
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    if w.is_alive():
   Exception ignored in:   <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620> 
 Traceback (most recent call last):
^  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
^^^^^^^^^^    ^self._shutdown_workers()

  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
        self._shutdown_workers()assert self._parent_pid == os.getpid(), 'can only test a child process'

   File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
         if w.is_alive(): 
       ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^    ^^if w.is_alive():^^

^   File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^
^AssertionError^: ^can only test a child process^
^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^
^^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^
^AssertionError^: ^can only test a child process^
^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^Traceback (most recent call last):
^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
Traceback (most recent call last):
    assert self._parent_pid == os.getpid(), 'can only test a child process'
            File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
 ^  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
^^  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
^^^OSError: [Errno 9] Bad file descriptor
^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: uploading history steps 82-83, summary, console lines 42-42
wandb: uploading console lines 52-52
wandb: 
wandb: Run history:
wandb:                  epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: grad_mean/lif_layers.0 ‚ñÅ‚ñÇ‚ñÜ‚ñà
wandb: grad_mean/lif_layers.1 ‚ñÅ‚ñÉ‚ñÜ‚ñà
wandb: grad_mean/lif_layers.2 ‚ñÅ‚ñÉ‚ñÜ‚ñà
wandb: grad_mean/lif_layers.3 ‚ñÅ‚ñÑ‚ñÜ‚ñà
wandb: grad_mean/lif_layers.4 ‚ñÅ‚ñÑ‚ñÜ‚ñà
wandb: grad_mean/lif_layers.5 ‚ñÅ‚ñÑ‚ñÜ‚ñà
wandb: grad_mean/lif_layers.6 ‚ñÇ‚ñÅ‚ñÖ‚ñà
wandb: grad_mean/lif_layers.7 ‚ñà‚ñÉ‚ñÇ‚ñÅ
wandb: grad_mean/output_layer ‚ñà‚ñÖ‚ñÖ‚ñÅ
wandb:                    +12 ...
wandb: 
wandb: Run summary:
wandb:                  epoch 39
wandb: grad_mean/lif_layers.0 7.88142
wandb: grad_mean/lif_layers.1 1.27179
wandb: grad_mean/lif_layers.2 0.24448
wandb: grad_mean/lif_layers.3 0.05533
wandb: grad_mean/lif_layers.4 0.01453
wandb: grad_mean/lif_layers.5 0.00305
wandb: grad_mean/lif_layers.6 0.00059
wandb: grad_mean/lif_layers.7 0.00017
wandb: grad_mean/output_layer 0.08236
wandb:                    +12 ...
wandb: 
wandb: üöÄ View run morning-sweep-50 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/3oxoz1wc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_162711-3oxoz1wc/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: rt7nx20g with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.0008953435974484793
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 3
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_165409-rt7nx20g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-51
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/rt7nx20g
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 62.9 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
63.0 K    Trainable params
0         Non-trainable params
63.0 K    Total params
0.252     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                     epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                        lr ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ
wandb:  spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÖ
wandb:  spikes/train_avg_layer_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: spikes/train_avg_layer_10 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà
wandb: spikes/train_avg_layer_11 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñà
wandb: spikes/train_avg_layer_12 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñà
wandb: spikes/train_avg_layer_13 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñà
wandb: spikes/train_avg_layer_14 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà
wandb: spikes/train_avg_layer_15 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñá‚ñà
wandb:                       +11 ...
wandb: 
wandb: Run summary:
wandb:                     epoch 12
wandb:                        lr 0.00068
wandb:  spikes/train_avg_layer_0 0.02845
wandb:  spikes/train_avg_layer_1 0.03332
wandb: spikes/train_avg_layer_10 0.03333
wandb: spikes/train_avg_layer_11 0.0271
wandb: spikes/train_avg_layer_12 0.02824
wandb: spikes/train_avg_layer_13 0.0225
wandb: spikes/train_avg_layer_14 0.02168
wandb: spikes/train_avg_layer_15 0.00651
wandb:                       +11 ...
wandb: 
wandb: üöÄ View run efficient-sweep-51 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/rt7nx20g
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_165409-rt7nx20g/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 511, in forward
    spk_states = []
                    
Exception

wandb: Agent Starting Run: 1l7fu88d with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.951562831132189e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.9
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_171812-1l7fu88d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-52
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/1l7fu88d
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 944    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
975       Trainable params
0         Non-trainable params
975       Total params
0.004     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading history steps 18-19, summary, console lines 42-43
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:                       lr ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà
wandb: spikes/train_avg_layer_3 ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñá‚ñà
wandb:               train_loss ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 9
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.0205
wandb: spikes/train_avg_layer_1 0.00329
wandb: spikes/train_avg_layer_2 0.0005
wandb: spikes/train_avg_layer_3 0.0
wandb:               train_loss 0.34319
wandb:      trainer/global_step 69
wandb:                 val_loss 0.34024
wandb: 
wandb: üöÄ View run gallant-sweep-52 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/1l7fu88d
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_171812-1l7fu88d/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 180, in forward
    H = (h_prev > 0.5).float()
        ^^^^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: zl7aosv6 with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.0001220595672721351
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.9
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_171909-zl7aosv6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-53
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/zl7aosv6
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 50.6 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
50.7 K    Trainable params
0         Non-trainable params
50.7 K    Total params
0.203     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÇ‚ñÑ‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÉ‚ñÖ‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÉ‚ñÑ‚ñà
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               train_loss ‚ñà‚ñÜ‚ñÉ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñÜ‚ñÉ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 3
wandb:                       lr 0.00012
wandb: spikes/train_avg_layer_0 0.01675
wandb: spikes/train_avg_layer_1 0.00145
wandb: spikes/train_avg_layer_2 0.0001
wandb: spikes/train_avg_layer_3 0
wandb:               train_loss 0.21981
wandb:      trainer/global_step 27
wandb:                 val_loss 0.21752
wandb: 
wandb: üöÄ View run twilight-sweep-53 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/zl7aosv6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_171909-zl7aosv6/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: t7t2ss3k with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.00030790034057888124
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_172311-t7t2ss3k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-sweep-54
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/t7t2ss3k
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 172    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
191       Trainable params
0         Non-trainable params
191       Total params
0.001     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                  epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: grad_mean/lif_layers.0 ‚ñà‚ñÅ‚ñÑ
wandb: grad_mean/lif_layers.1 ‚ñà‚ñÇ‚ñÅ
wandb: grad_mean/lif_layers.2 ‚ñà‚ñÉ‚ñÅ
wandb: grad_mean/lif_layers.3 ‚ñà‚ñÉ‚ñÅ
wandb: grad_mean/lif_layers.4 ‚ñà‚ñÉ‚ñÅ
wandb: grad_mean/lif_layers.5 ‚ñà‚ñÉ‚ñÅ
wandb: grad_mean/lif_layers.6 ‚ñà‚ñÉ‚ñÅ
wandb: grad_mean/lif_layers.7 ‚ñà‚ñÉ‚ñÅ
wandb: grad_mean/output_layer ‚ñà‚ñÉ‚ñÅ
wandb:                    +12 ...
wandb: 
wandb: Run summary:
wandb:                  epoch 28
wandb: grad_mean/lif_layers.0 0.00177
wandb: grad_mean/lif_layers.1 0.00221
wandb: grad_mean/lif_layers.2 0.00227
wandb: grad_mean/lif_layers.3 0.00362
wandb: grad_mean/lif_layers.4 0.00425
wandb: grad_mean/lif_layers.5 0.00429
wandb: grad_mean/lif_layers.6 0.00564
wandb: grad_mean/lif_layers.7 0.00479
wandb: grad_mean/output_layer 0.12035
wandb:                    +12 ...
wandb: 
wandb: üöÄ View run graceful-sweep-54 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/t7t2ss3k
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_172311-t7t2ss3k/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 167, in forward
    x = self.rho * torch.tanh(i / self.rho)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: tjgx3vp6 with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.0001403921238583028
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 3
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.8
wandb: setting up run tjgx3vp6
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_172510-tjgx3vp6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-55
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/tjgx3vp6
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 29.6 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
29.7 K    Trainable params
0         Non-trainable params
29.7 K    Total params
0.119     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÉ‚ñà‚ñá
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÑ‚ñÜ‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÉ‚ñÑ‚ñà
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñà
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 3
wandb:                       lr 0.00014
wandb: spikes/train_avg_layer_0 0.0203
wandb: spikes/train_avg_layer_1 0.00184
wandb: spikes/train_avg_layer_2 0.0004
wandb: spikes/train_avg_layer_3 0.0
wandb: spikes/train_avg_layer_4 0
wandb: spikes/train_avg_layer_5 0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run dauntless-sweep-55 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/tjgx3vp6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_172510-tjgx3vp6/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: p4avtzll with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.07709654253433e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 3
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_172811-p4avtzll
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-56
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/p4avtzll
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 50.6 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
50.7 K    Trainable params
0         Non-trainable params
50.7 K    Total params
0.203     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading summary, console lines 42-43
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñÜ‚ñÅ‚ñÇ
wandb: spikes/train_avg_layer_1 ‚ñà‚ñà‚ñÅ‚ñÜ
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÖ‚ñá‚ñà
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               train_loss ‚ñà‚ñÜ‚ñÉ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñÜ‚ñÉ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 3
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.02061
wandb: spikes/train_avg_layer_1 0.00204
wandb: spikes/train_avg_layer_2 6e-05
wandb: spikes/train_avg_layer_3 0
wandb:               train_loss 0.2158
wandb:      trainer/global_step 27
wandb:                 val_loss 0.2138
wandb: 
wandb: üöÄ View run morning-sweep-56 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/p4avtzll
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_172811-p4avtzll/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: wasqvxah with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 5.571203147155003e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.8
wandb: setting up run wasqvxah
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_173208-wasqvxah
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-57
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/wasqvxah
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 400    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
431       Trainable params
0         Non-trainable params
431       Total params
0.002     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ
wandb:   grad_mean/lif_layers.1 ‚ñÅ
wandb:   grad_mean/output_layer ‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_1 ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÜ
wandb:               train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 19
wandb:   grad_mean/lif_layers.0 0.01609
wandb:   grad_mean/lif_layers.1 0.00821
wandb:   grad_mean/output_layer 0.45663
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.01844
wandb: spikes/train_avg_layer_1 0.00052
wandb:               train_loss 0.37428
wandb:      trainer/global_step 139
wandb:                 val_loss 0.37119
wandb: 
wandb: üöÄ View run different-sweep-57 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/wasqvxah
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_173208-wasqvxah/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 315, in apply
    return user_fn(self, *args)
           ^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 61, in backward
    grad_input = grad_output.clone()
                 ^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: bq0bkzv8 with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.0005237499312766653
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_173311-bq0bkzv8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-sweep-58
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/bq0bkzv8
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 332    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
351       Trainable params
0         Non-trainable params
351       Total params
0.001     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                   epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:  grad_mean/lif_layers.0 ‚ñÅ‚ñá‚ñÜ‚ñà
wandb:  grad_mean/lif_layers.1 ‚ñÅ‚ñÑ‚ñÜ‚ñà
wandb: grad_mean/lif_layers.10 ‚ñÇ‚ñà‚ñÅ‚ñÅ
wandb: grad_mean/lif_layers.11 ‚ñÑ‚ñà‚ñÅ‚ñÉ
wandb: grad_mean/lif_layers.12 ‚ñÜ‚ñà‚ñÅ‚ñÜ
wandb: grad_mean/lif_layers.13 ‚ñà‚ñà‚ñÅ‚ñà
wandb: grad_mean/lif_layers.14 ‚ñÉ‚ñà‚ñÅ‚ñÉ
wandb: grad_mean/lif_layers.15 ‚ñÅ‚ñà‚ñÑ‚ñÅ
wandb:  grad_mean/lif_layers.2 ‚ñÅ‚ñÑ‚ñÖ‚ñà
wandb:                     +28 ...
wandb: 
wandb: Run summary:
wandb:                   epoch 39
wandb:  grad_mean/lif_layers.0 0.0002
wandb:  grad_mean/lif_layers.1 0.00031
wandb: grad_mean/lif_layers.10 2e-05
wandb: grad_mean/lif_layers.11 5e-05
wandb: grad_mean/lif_layers.12 6e-05
wandb: grad_mean/lif_layers.13 6e-05
wandb: grad_mean/lif_layers.14 4e-05
wandb: grad_mean/lif_layers.15 0.00011
wandb:  grad_mean/lif_layers.2 0.00015
wandb:                     +28 ...
wandb: 
wandb: üöÄ View run young-sweep-58 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/bq0bkzv8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_173311-bq0bkzv8/logs
wandb: Agent Starting Run: 63mrs7yr with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 4.019403569569251e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.9
wandb: setting up run 63mrs7yr
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_173754-63mrs7yr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-59
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/63mrs7yr
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 4.2 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
4.2 K     Trainable params
0         Non-trainable params
4.2 K     Total params
0.017     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                     epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:                        lr ‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÅ
wandb:  spikes/train_avg_layer_0 ‚ñÅ‚ñÑ‚ñÜ‚ñà‚ñÖ‚ñÑ‚ñÉ
wandb:  spikes/train_avg_layer_1 ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà
wandb: spikes/train_avg_layer_10 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_11 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_12 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_13 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_14 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_15 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +11 ...
wandb: 
wandb: Run summary:
wandb:                     epoch 6
wandb:                        lr 0.0
wandb:  spikes/train_avg_layer_0 0.01977
wandb:  spikes/train_avg_layer_1 0.00058
wandb: spikes/train_avg_layer_10 0
wandb: spikes/train_avg_layer_11 0
wandb: spikes/train_avg_layer_12 0
wandb: spikes/train_avg_layer_13 0
wandb: spikes/train_avg_layer_14 0
wandb: spikes/train_avg_layer_15 0
wandb:                       +11 ...
wandb: 
wandb: üöÄ View run fast-sweep-59 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/63mrs7yr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_173754-63mrs7yr/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: c04b6j2b with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.136112292889247e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 3
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.8
wandb: setting up run c04b6j2b
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_174009-c04b6j2b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-60
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/c04b6j2b
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 944    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
975       Trainable params
0         Non-trainable params
975       Total params
0.004     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading history steps 18-21, summary, console lines 42-43
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                       lr ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_1 ‚ñà‚ñà‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñà‚ñà‚ñà‚ñÉ‚ñÉ‚ñÉ
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               train_loss ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 10
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.01482
wandb: spikes/train_avg_layer_1 0.0017
wandb: spikes/train_avg_layer_2 0.0
wandb: spikes/train_avg_layer_3 0
wandb:               train_loss 0.24983
wandb:      trainer/global_step 76
wandb:                 val_loss 0.24751
wandb: 
wandb: üöÄ View run smart-sweep-60 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/c04b6j2b
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_174009-c04b6j2b/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 153, in run
    self.on_advance_end(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 398, in on_advance_end
    self.val_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 145, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 437, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 412, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 620, in validation_step
    layer_outputs.append(x_seq)
      ^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: 5pdiol1n with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 5.240452657137913e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_174111-5pdiol1n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-61
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/5pdiol1n
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 332    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
351       Trainable params
0         Non-trainable params
351       Total params
0.001     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading history steps 37-38, summary, console lines 42-43
wandb: 
wandb: Run history:
wandb:                   epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:  grad_mean/lif_layers.0 ‚ñÅ
wandb:  grad_mean/lif_layers.1 ‚ñÅ
wandb: grad_mean/lif_layers.10 ‚ñÅ
wandb: grad_mean/lif_layers.11 ‚ñÅ
wandb: grad_mean/lif_layers.12 ‚ñÅ
wandb: grad_mean/lif_layers.13 ‚ñÅ
wandb: grad_mean/lif_layers.14 ‚ñÅ
wandb: grad_mean/lif_layers.15 ‚ñÅ
wandb:  grad_mean/lif_layers.2 ‚ñÅ
wandb:                     +28 ...
wandb: 
wandb: Run summary:
wandb:                   epoch 18
wandb:  grad_mean/lif_layers.0 0.00027
wandb:  grad_mean/lif_layers.1 0.00011
wandb: grad_mean/lif_layers.10 0.00108
wandb: grad_mean/lif_layers.11 0.00135
wandb: grad_mean/lif_layers.12 0.0017
wandb: grad_mean/lif_layers.13 0.00217
wandb: grad_mean/lif_layers.14 0.00498
wandb: grad_mean/lif_layers.15 0.00511
wandb:  grad_mean/lif_layers.2 0.00012
wandb:                     +28 ...
wandb: 
wandb: üöÄ View run sparkling-sweep-61 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/5pdiol1n
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_174111-5pdiol1n/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 153, in run
    self.on_advance_end(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 398, in on_advance_end
    self.val_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 145, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 437, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 412, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 620, in validation_step
    layer_outputs.append(x_seq)
      ^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 185, in forward
    h_candidate = torch.tanh(preact)
                  ^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: spettxzb with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.0007697506928918769
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.8
wandb: setting up run spettxzb
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_174412-spettxzb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-62
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/spettxzb
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 29.6 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
29.7 K    Trainable params
0         Non-trainable params
29.7 K    Total params
0.119     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception in thread QueueFeederThread:
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
         self._close() 
     File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1012, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 291, in _feed
    queue_sem.release()
Traceback (most recent call last):
ValueError: semaphore or lock released too many times
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>Exception ignored in: 
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
<function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^
^^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^
^AssertionError^: ^can only test a child process^
^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
OSError: [Errno 9] Bad file descriptor
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
          if w.is_alive(): 
^^ ^ ^ ^ ^ ^ ^ ^^^^^^^^
^  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
            assert self._parent_pid == os.getpid(), 'can only test a child process' 
   ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^AssertionError^: ^can only test a child process^
^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
       Exception ignored in:    <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620> 
^Traceback (most recent call last):
^  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^Traceback (most recent call last):
^^^^^^
AssertionError: can only test a child process  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()

  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
wandb: updating run metadata
wandb: uploading summary, console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                       lr ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÉ
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 12
wandb:                       lr 0.00059
wandb: spikes/train_avg_layer_0 0.02262
wandb: spikes/train_avg_layer_1 0.02206
wandb: spikes/train_avg_layer_2 0.02306
wandb: spikes/train_avg_layer_3 0.0247
wandb: spikes/train_avg_layer_4 0.02284
wandb: spikes/train_avg_layer_5 0.02307
wandb: spikes/train_avg_layer_6 0.02026
wandb: spikes/train_avg_layer_7 0.01436
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run solar-sweep-62 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/spettxzb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_174412-spettxzb/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: hd6u3irl with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 6.615137807084451e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 1
wandb: setting up run hd6u3irl
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_175710-hd6u3irl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-63
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/hd6u3irl
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 29.6 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
29.7 K    Trainable params
0         Non-trainable params
29.7 K    Total params
0.119     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÑ‚ñá‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÜ‚ñÇ‚ñÅ‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÑ‚ñÜ‚ñà
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 3
wandb:                       lr 6e-05
wandb: spikes/train_avg_layer_0 0.02237
wandb: spikes/train_avg_layer_1 0.00155
wandb: spikes/train_avg_layer_2 0.00012
wandb: spikes/train_avg_layer_3 0
wandb: spikes/train_avg_layer_4 0
wandb: spikes/train_avg_layer_5 0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run quiet-sweep-63 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/hd6u3irl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_175710-hd6u3irl/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: 4mvrvjvp with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 3.6003621847870324e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.9
wandb: setting up run 4mvrvjvp
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_180107-4mvrvjvp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-64
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/4mvrvjvp
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 944    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
975       Trainable params
0         Non-trainable params
975       Total params
0.004     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ‚ñà
wandb:   grad_mean/lif_layers.1 ‚ñà‚ñÅ
wandb:   grad_mean/lif_layers.2 ‚ñÅ‚ñà
wandb:   grad_mean/lif_layers.3 ‚ñà‚ñÅ
wandb:   grad_mean/output_layer ‚ñà‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ
wandb: spikes/train_avg_layer_1 ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                       +4 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 21
wandb:   grad_mean/lif_layers.0 0.00549
wandb:   grad_mean/lif_layers.1 0.00218
wandb:   grad_mean/lif_layers.2 0.00218
wandb:   grad_mean/lif_layers.3 0.00283
wandb:   grad_mean/output_layer 0.1367
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.01317
wandb: spikes/train_avg_layer_1 0.00075
wandb: spikes/train_avg_layer_2 8e-05
wandb:                       +4 ...
wandb: 
wandb: üöÄ View run daily-sweep-64 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/4mvrvjvp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_180107-4mvrvjvp/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 315, in apply
    return user_fn(self, *args)
           ^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 61, in backward
    grad_input = grad_output.clone()
                 ^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: 5dt710yd with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 2.155309629974547e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 3
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_180312-5dt710yd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-sweep-65
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/5dt710yd
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 92     | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
111       Trainable params
0         Non-trainable params
111       Total params
0.000     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ‚ñà
wandb:   grad_mean/lif_layers.1 ‚ñÅ‚ñà
wandb:   grad_mean/lif_layers.2 ‚ñÅ‚ñà
wandb:   grad_mean/lif_layers.3 ‚ñÅ‚ñà
wandb:   grad_mean/output_layer ‚ñÅ‚ñà
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_1 ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +4 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 21
wandb:   grad_mean/lif_layers.0 0.01038
wandb:   grad_mean/lif_layers.1 0.00879
wandb:   grad_mean/lif_layers.2 0.00459
wandb:   grad_mean/lif_layers.3 0.00568
wandb:   grad_mean/output_layer 0.13044
wandb:                       lr 1e-05
wandb: spikes/train_avg_layer_0 0.01374
wandb: spikes/train_avg_layer_1 4e-05
wandb: spikes/train_avg_layer_2 0
wandb:                       +4 ...
wandb: 
wandb: üöÄ View run blooming-sweep-65 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/5dt710yd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_180312-5dt710yd/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: mb5ck3dy with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 3.3075794275488065e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.9
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_180408-mb5ck3dy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-66
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/mb5ck3dy
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 116 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
116 K     Trainable params
0         Non-trainable params
116 K     Total params
0.467     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading summary, console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñÖ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÇ‚ñÜ‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÅ‚ñá‚ñà
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 3
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.01988
wandb: spikes/train_avg_layer_1 0.00121
wandb: spikes/train_avg_layer_2 1e-05
wandb: spikes/train_avg_layer_3 0
wandb: spikes/train_avg_layer_4 0
wandb: spikes/train_avg_layer_5 0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run dashing-sweep-66 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/mb5ck3dy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_180408-mb5ck3dy/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: w59doyk2 with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.7559217983251724e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.8
wandb: setting up run w59doyk2
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_181208-w59doyk2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-67
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/w59doyk2
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 172    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
191       Trainable params
0         Non-trainable params
191       Total params
0.001     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading history steps 20-25, summary, console lines 43-44
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                       lr ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÇ‚ñÅ‚ñÉ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 12
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.00898
wandb: spikes/train_avg_layer_1 4e-05
wandb: spikes/train_avg_layer_2 0
wandb: spikes/train_avg_layer_3 0
wandb: spikes/train_avg_layer_4 0
wandb: spikes/train_avg_layer_5 0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run fragrant-sweep-67 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/w59doyk2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_181208-w59doyk2/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 247, in step
    adam(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 150, in maybe_fallback
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 953, in adam
    func(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 411, in _single_tensor_adam
    param.mul_(1 - lr * weight_decay)
Exception

wandb: Agent Starting Run: bei6517c with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.00035655503666106605
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.8
wandb: setting up run bei6517c
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_181311-bei6517c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-68
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/bei6517c
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 52     | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
71        Trainable params
0         Non-trainable params
71        Total params
0.000     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: uploading console lines 42-43
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñà‚ñÉ‚ñÅ‚ñÇ
wandb:   grad_mean/lif_layers.1 ‚ñà‚ñÑ‚ñÅ‚ñÉ
wandb:   grad_mean/output_layer ‚ñà‚ñÜ‚ñÅ‚ñÇ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:               train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:                 val_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 39
wandb:   grad_mean/lif_layers.0 0.00379
wandb:   grad_mean/lif_layers.1 0.00227
wandb:   grad_mean/output_layer 0.01351
wandb:                       lr 0
wandb: spikes/train_avg_layer_0 0.01297
wandb: spikes/train_avg_layer_1 0.0057
wandb:               train_loss 0.1593
wandb:      trainer/global_step 279
wandb:                 val_loss 0.15837
wandb: 
wandb: üöÄ View run eternal-sweep-68 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/bei6517c
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_181311-bei6517c/logs
wandb: Agent Starting Run: bv9lrgxx with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 2.2402721073530917e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_181407-bv9lrgxx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-69
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/bv9lrgxx
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 172    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
191       Trainable params
0         Non-trainable params
191       Total params
0.001     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                  epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: grad_mean/lif_layers.0 ‚ñÅ
wandb: grad_mean/lif_layers.1 ‚ñÅ
wandb: grad_mean/lif_layers.2 ‚ñÅ
wandb: grad_mean/lif_layers.3 ‚ñÅ
wandb: grad_mean/lif_layers.4 ‚ñÅ
wandb: grad_mean/lif_layers.5 ‚ñÅ
wandb: grad_mean/lif_layers.6 ‚ñÅ
wandb: grad_mean/lif_layers.7 ‚ñÅ
wandb: grad_mean/output_layer ‚ñÅ
wandb:                    +12 ...
wandb: 
wandb: Run summary:
wandb:                  epoch 14
wandb: grad_mean/lif_layers.0 0.00025
wandb: grad_mean/lif_layers.1 0.00017
wandb: grad_mean/lif_layers.2 0.00022
wandb: grad_mean/lif_layers.3 0.00029
wandb: grad_mean/lif_layers.4 0.00048
wandb: grad_mean/lif_layers.5 0.00076
wandb: grad_mean/lif_layers.6 0.00086
wandb: grad_mean/lif_layers.7 0.0072
wandb: grad_mean/output_layer 0.27208
wandb:                    +12 ...
wandb: 
wandb: üöÄ View run sweet-sweep-69 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/bv9lrgxx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_181407-bv9lrgxx/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 315, in apply
    return user_fn(self, *args)
           ^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 61, in backward
    grad_input = grad_output.clone()
                 ^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: lo3064w0 with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.00019350641721949832
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 3
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_181510-lo3064w0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-70
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/lo3064w0
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 17.5 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
17.7 K    Trainable params
0         Non-trainable params
17.7 K    Total params
0.071     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñà‚ñÉ‚ñÅ‚ñÇ
wandb:   grad_mean/lif_layers.1 ‚ñà‚ñÉ‚ñÅ‚ñÇ
wandb:   grad_mean/output_layer ‚ñà‚ñÉ‚ñÅ‚ñÉ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:               train_loss ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 39
wandb:   grad_mean/lif_layers.0 0.00249
wandb:   grad_mean/lif_layers.1 0.00037
wandb:   grad_mean/output_layer 0.10408
wandb:                       lr 0
wandb: spikes/train_avg_layer_0 0.02902
wandb: spikes/train_avg_layer_1 0.01337
wandb:               train_loss 0.16665
wandb:      trainer/global_step 279
wandb:                 val_loss 0.1648
wandb: 
wandb: üöÄ View run resilient-sweep-70 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/lo3064w0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_181510-lo3064w0/logs
wandb: Agent Starting Run: 499fyzyw with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 2.0662714865233367e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.9
wandb: setting up run 499fyzyw
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_182825-499fyzyw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-71
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/499fyzyw
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 50.6 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
50.7 K    Trainable params
0         Non-trainable params
50.7 K    Total params
0.203     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñÅ‚ñà‚ñá
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÇ‚ñÑ‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñá‚ñá‚ñà
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               train_loss ‚ñà‚ñÜ‚ñÉ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñÜ‚ñÉ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 3
wandb:                       lr 2e-05
wandb: spikes/train_avg_layer_0 0.02193
wandb: spikes/train_avg_layer_1 0.00141
wandb: spikes/train_avg_layer_2 5e-05
wandb: spikes/train_avg_layer_3 0
wandb:               train_loss 0.25841
wandb:      trainer/global_step 27
wandb:                 val_loss 0.25597
wandb: 
wandb: üöÄ View run dandy-sweep-71 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/499fyzyw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_182825-499fyzyw/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: vy3kocqg with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.0006292048645651606
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 1
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.9
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_183207-vy3kocqg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-72
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/vy3kocqg
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 332    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
351       Trainable params
0         Non-trainable params
351       Total params
0.001     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                   epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:  grad_mean/lif_layers.0 ‚ñÖ‚ñÅ‚ñÜ‚ñà
wandb:  grad_mean/lif_layers.1 ‚ñÅ‚ñÅ‚ñà‚ñÜ
wandb: grad_mean/lif_layers.10 ‚ñà‚ñÖ‚ñÖ‚ñÅ
wandb: grad_mean/lif_layers.11 ‚ñà‚ñÖ‚ñÖ‚ñÅ
wandb: grad_mean/lif_layers.12 ‚ñà‚ñÖ‚ñÖ‚ñÅ
wandb: grad_mean/lif_layers.13 ‚ñà‚ñÖ‚ñÖ‚ñÅ
wandb: grad_mean/lif_layers.14 ‚ñà‚ñÖ‚ñÖ‚ñÅ
wandb: grad_mean/lif_layers.15 ‚ñà‚ñÖ‚ñÖ‚ñÅ
wandb:  grad_mean/lif_layers.2 ‚ñÜ‚ñÅ‚ñà‚ñÇ
wandb:                     +28 ...
wandb: 
wandb: Run summary:
wandb:                   epoch 39
wandb:  grad_mean/lif_layers.0 1e-05
wandb:  grad_mean/lif_layers.1 1e-05
wandb: grad_mean/lif_layers.10 0.00043
wandb: grad_mean/lif_layers.11 0.00098
wandb: grad_mean/lif_layers.12 0.00155
wandb: grad_mean/lif_layers.13 0.00189
wandb: grad_mean/lif_layers.14 0.0026
wandb: grad_mean/lif_layers.15 0.00219
wandb:  grad_mean/lif_layers.2 2e-05
wandb:                     +28 ...
wandb: 
wandb: üöÄ View run vital-sweep-72 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/vy3kocqg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_183207-vy3kocqg/logs
wandb: Agent Starting Run: nzyzjygp with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.00016470126842747017
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_183706-nzyzjygp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-73
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/nzyzjygp
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 62.9 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
63.0 K    Trainable params
0         Non-trainable params
63.0 K    Total params
0.252     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                     epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                        lr ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ
wandb:  spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñà
wandb:  spikes/train_avg_layer_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà
wandb: spikes/train_avg_layer_10 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_11 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_12 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_13 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_14 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_15 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +11 ...
wandb: 
wandb: Run summary:
wandb:                     epoch 12
wandb:                        lr 0.00013
wandb:  spikes/train_avg_layer_0 0.01717
wandb:  spikes/train_avg_layer_1 0.00367
wandb: spikes/train_avg_layer_10 0
wandb: spikes/train_avg_layer_11 0
wandb: spikes/train_avg_layer_12 0
wandb: spikes/train_avg_layer_13 0
wandb: spikes/train_avg_layer_14 0
wandb: spikes/train_avg_layer_15 0
wandb:                       +11 ...
wandb: 
wandb: üöÄ View run wild-sweep-73 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/nzyzjygp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_183706-nzyzjygp/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: djoh2wxm with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.0005391583843172306
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 1
wandb: setting up run djoh2wxm
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_190010-djoh2wxm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sweep-74
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/djoh2wxm
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 116 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
116 K     Trainable params
0         Non-trainable params
116 K     Total params
0.467     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                  epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: grad_mean/lif_layers.0 ‚ñÅ‚ñÉ‚ñá‚ñà
wandb: grad_mean/lif_layers.1 ‚ñÅ‚ñÉ‚ñá‚ñà
wandb: grad_mean/lif_layers.2 ‚ñÅ‚ñÉ‚ñá‚ñà
wandb: grad_mean/lif_layers.3 ‚ñÅ‚ñÉ‚ñá‚ñà
wandb: grad_mean/lif_layers.4 ‚ñÅ‚ñÑ‚ñà‚ñà
wandb: grad_mean/lif_layers.5 ‚ñÅ‚ñÑ‚ñà‚ñà
wandb: grad_mean/lif_layers.6 ‚ñÅ‚ñÉ‚ñà‚ñá
wandb: grad_mean/lif_layers.7 ‚ñà‚ñÑ‚ñÅ‚ñÅ
wandb: grad_mean/output_layer ‚ñÜ‚ñà‚ñÅ‚ñÖ
wandb:                    +12 ...
wandb: 
wandb: Run summary:
wandb:                  epoch 39
wandb: grad_mean/lif_layers.0 428.72598
wandb: grad_mean/lif_layers.1 40.57615
wandb: grad_mean/lif_layers.2 4.61541
wandb: grad_mean/lif_layers.3 0.46314
wandb: grad_mean/lif_layers.4 0.04638
wandb: grad_mean/lif_layers.5 0.00522
wandb: grad_mean/lif_layers.6 0.00052
wandb: grad_mean/lif_layers.7 5e-05
wandb: grad_mean/output_layer 0.11487
wandb:                    +12 ...
wandb: 
wandb: üöÄ View run expert-sweep-74 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/djoh2wxm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_190010-djoh2wxm/logs
wandb: Agent Starting Run: oee69xg8 with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.0004668758119227954
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 3
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_201428-oee69xg8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-sweep-75
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/oee69xg8
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 400    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
431       Trainable params
0         Non-trainable params
431       Total params
0.002     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading history steps 20-23, summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                       lr ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà
wandb:               train_loss ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 11
wandb:                       lr 0.00037
wandb: spikes/train_avg_layer_0 0.02358
wandb: spikes/train_avg_layer_1 0.00382
wandb:               train_loss 0.25317
wandb:      trainer/global_step 83
wandb:                 val_loss 0.2492
wandb: 
wandb: üöÄ View run crimson-sweep-75 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/oee69xg8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_201428-oee69xg8/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 149, in run
    self.on_run_start(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 245, in on_run_start
    iter(data_fetcher)  # creates the iterator inside the fetcher
    ^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fetchers.py", line 105, in __iter__
    super().__iter__()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fetchers.py", line 52, in __iter__
    self.iterator = iter(self.combined_loader)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py", line 351, in __iter__
    iter(iterator)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py", line 92, in __iter__
    super().__iter__()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py", line 43, in __iter__
    self.iterators = [iter(iterable) for iterable in self.iterables]
                      ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 494, in __iter__
    return self._get_iterator()
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 427, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1218, in __init__
    self._reset(loader, first_iter=True)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1260, in _reset
    self._try_put_index()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1531, in _try_put_index
    self._index_queues[worker_queue_idx].put((self._send_idx, index))  # type: ignore[possibly-undefined]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 94, in put
    self._start_thread()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 192, in _start_thread
    self._thread.start()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 999, in start
    self._started.wait()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 655, in wait
    signaled = self._cond.wait(timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 355, in wait
    waiter.acquire()
Exception

wandb: Agent Starting Run: 2vpxdmck with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 5.041170494160205e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 1
wandb: setting up run 2vpxdmck
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_201509-2vpxdmck
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-76
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/2vpxdmck
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 400    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
431       Trainable params
0         Non-trainable params
431       Total params
0.002     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ‚ñà
wandb:   grad_mean/lif_layers.1 ‚ñÅ‚ñà
wandb:   grad_mean/output_layer ‚ñÅ‚ñà
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñá‚ñá‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÖ
wandb: spikes/train_avg_layer_1 ‚ñà‚ñà‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÇ‚ñÇ‚ñÅ
wandb:               train_loss ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:                 val_loss ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 21
wandb:   grad_mean/lif_layers.0 0.01096
wandb:   grad_mean/lif_layers.1 0.00818
wandb:   grad_mean/output_layer 0.27305
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.01532
wandb: spikes/train_avg_layer_1 0.00138
wandb:               train_loss 0.23292
wandb:      trainer/global_step 153
wandb:                 val_loss 0.23078
wandb: 
wandb: üöÄ View run absurd-sweep-76 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/2vpxdmck
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_201509-2vpxdmck/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 153, in run
    self.on_advance_end(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 398, in on_advance_end
    self.val_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 145, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 437, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 412, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 620, in validation_step
    layer_outputs.append(x_seq)
      ^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 189, in forward
    hs = zs * hs_prev + (1.0 - zs) * h_prev
                         ~~~~^~~~
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 38, in wrapped
    @functools.wraps(f)
    
Exception

wandb: Agent Starting Run: 4qb6h849 with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 2.4413149893349883e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 3
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.8
wandb: setting up run 4qb6h849
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_201611-4qb6h849
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-77
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/4qb6h849
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 62.9 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
63.0 K    Trainable params
0         Non-trainable params
63.0 K    Total params
0.252     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception in thread QueueFeederThread:
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1012, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 291, in _feed
    queue_sem.release()
ValueError: semaphore or lock released too many times
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                     epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                        lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb:  spikes/train_avg_layer_0 ‚ñà‚ñà‚ñÅ‚ñÅ
wandb:  spikes/train_avg_layer_1 ‚ñÜ‚ñÑ‚ñÅ‚ñà
wandb: spikes/train_avg_layer_10 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_11 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_12 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_13 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_14 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_15 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +11 ...
wandb: 
wandb: Run summary:
wandb:                     epoch 3
wandb:                        lr 0.0
wandb:  spikes/train_avg_layer_0 0.02643
wandb:  spikes/train_avg_layer_1 0.00268
wandb: spikes/train_avg_layer_10 0
wandb: spikes/train_avg_layer_11 0
wandb: spikes/train_avg_layer_12 0
wandb: spikes/train_avg_layer_13 0
wandb: spikes/train_avg_layer_14 0
wandb: spikes/train_avg_layer_15 0
wandb:                       +11 ...
wandb: 
wandb: üöÄ View run devout-sweep-77 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/4qb6h849
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_201611-4qb6h849/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 171, in forward
    h_prev = h.detach()
             ^^^^^^^^^^
Exception

wandb: Agent Starting Run: s50fgk7s with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 9.216715164687624e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 1
wandb: setting up run s50fgk7s
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_202410-s50fgk7s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-sweep-78
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/s50fgk7s
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 332    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
351       Trainable params
0         Non-trainable params
351       Total params
0.001     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                   epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:  grad_mean/lif_layers.0 ‚ñÅ
wandb:  grad_mean/lif_layers.1 ‚ñÅ
wandb: grad_mean/lif_layers.10 ‚ñÅ
wandb: grad_mean/lif_layers.11 ‚ñÅ
wandb: grad_mean/lif_layers.12 ‚ñÅ
wandb: grad_mean/lif_layers.13 ‚ñÅ
wandb: grad_mean/lif_layers.14 ‚ñÅ
wandb: grad_mean/lif_layers.15 ‚ñÅ
wandb:  grad_mean/lif_layers.2 ‚ñÅ
wandb:                     +28 ...
wandb: 
wandb: Run summary:
wandb:                   epoch 14
wandb:  grad_mean/lif_layers.0 9e-05
wandb:  grad_mean/lif_layers.1 8e-05
wandb: grad_mean/lif_layers.10 0.00136
wandb: grad_mean/lif_layers.11 0.00197
wandb: grad_mean/lif_layers.12 0.00363
wandb: grad_mean/lif_layers.13 0.00465
wandb: grad_mean/lif_layers.14 0.00593
wandb: grad_mean/lif_layers.15 0.00607
wandb:  grad_mean/lif_layers.2 0.00022
wandb:                     +28 ...
wandb: 
wandb: üöÄ View run charmed-sweep-78 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/s50fgk7s
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_202410-s50fgk7s/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 153, in run
    self.on_advance_end(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 398, in on_advance_end
    self.val_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 123, in run
    self.reset()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 259, in reset
    iter(data_fetcher)  # creates the iterator inside the fetcher
    ^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fetchers.py", line 105, in __iter__
    super().__iter__()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fetchers.py", line 52, in __iter__
    self.iterator = iter(self.combined_loader)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py", line 351, in __iter__
    iter(iterator)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py", line 155, in __iter__
    self._load_current_iterator()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py", line 173, in _load_current_iterator
    self.iterators = [iter(self.iterables[self._iterator_idx])]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 494, in __iter__
    return self._get_iterator()
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 427, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1170, in __init__
    w.start()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 120, in start
    _cleanup()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 64, in _cleanup
    if (child_popen := p._popen) and child_popen.poll() is not None:
                                     ^^^^^^^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/popen_fork.py", line 27, in poll
    pid, sts = os.waitpid(self.pid, flag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
Exception

Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1612, in _shutdown_workers
    if self._persistent_workers or self._workers_status[worker_id]:
                                   ^^^^^^^^^^^^^^^^^^^^
AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'
wandb: Agent Starting Run: 046h7372 with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.00015218313570715384
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 3
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_202609-046h7372
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fallen-sweep-79
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/046h7372
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 52     | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
71        Trainable params
0         Non-trainable params
71        Total params
0.000     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception in thread QueueFeederThread:
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1012, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 291, in _feed
    queue_sem.release()
ValueError: semaphore or lock released too many times
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
Exception ignored in: Exception ignored in:   File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
<function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620><function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>

Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    if w.is_alive():
       ^^^    ^self._shutdown_workers()^
^^^^  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^    ^    if w.is_alive():^assert self._parent_pid == os.getpid(), 'can only test a child process'
^
^ ^  ^  ^  ^  ^  ^  ^^ 
^   File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
^ ^ ^ ^^^^^^^^^^^^^^
^  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
^^^^^^^^^^^^^^^^^^^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^
^
 AssertionError :  can only test a child process 
        assert self._parent_pid == os.getpid(), 'can only test a child process' 
   ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^AssertionError^: ^can only test a child process^
^^^^^^
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
Exception ignored in:   File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
<function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
    Traceback (most recent call last):
self._shutdown_workers()  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__

  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
     self._shutdown_workers() 
       File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
^    ^if w.is_alive():^
^^ ^ ^ ^ ^ ^     ^self._shutdown_workers() ^
^
^  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
^^  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
^^^^^^^^
      File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
if w.is_alive():
       ^^^^^^^^^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^

  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
         if w.is_alive(): 
       assert self._parent_pid == os.getpid(), 'can only test a child process'  
    ^  ^  ^  ^ ^^ ^^ ^^ ^^ ^^ ^^ ^    ^ ^assert self._parent_pid == os.getpid(), 'can only test a child process'^^^
^^^^^ ^^^ ^^^ 
^^   File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^^^^^^^^^^^^^^^^^^^^
^^AssertionError^^: ^^can only test a child process^^
^^^    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'^^
^^^ ^^ ^^ 
^ AssertionError^ : ^ can only test a child process^ 
^ ^ ^ ^ ^^^^^^^^^^
^AssertionError^: ^can only test a child process^
^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
Exception ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>if w.is_alive():

Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
        assert self._parent_pid == os.getpid(), 'can only test a child process'self._shutdown_workers()

     File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
        ^^^^^^^^^^^^^^^^^^^^^^^^    ^if w.is_alive():^
^^ ^ ^ ^ 
 AssertionError :  can only test a child process^
^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1618, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/popen_fork.py", line 40, in wait
    if not wait([self.sentinel], timeout):
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 1136, in wait
    ready = selector.select(timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Exception: 
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
Exception ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>if w.is_alive():

Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
        self._shutdown_workers()assert self._parent_pid == os.getpid(), 'can only test a child process'

    File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process    
if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
Exception ignored in:   File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
<function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Exception ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>if w.is_alive():

Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
      Exception ignored in:  ^<function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>^    
^self._shutdown_workers()Traceback (most recent call last):
^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
^^^  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
        self._shutdown_workers()if w.is_alive():

     File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    ^^^^^^^^^    ^^self._shutdown_workers()^

  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
      File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
assert self._parent_pid == os.getpid(), 'can only test a child process'
       if w.is_alive(): 
             ^ ^^^^^^^^^^    ^^    assert self._parent_pid == os.getpid(), 'can only test a child process'^^if w.is_alive():
^^
^^ ^^  ^^  ^^  ^
  ^  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
  ^  ^  ^^ ^^ ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^^  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
^
^AssertionError^: ^can only test a child process^    
^assert self._parent_pid == os.getpid(), 'can only test a child process'^
^^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^
^AssertionError^: ^can only test a child process^
^^^^    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'^
^^^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^
^AssertionError^: ^can only test a child process^
^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^Exception ignored in: ^^^<function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>^
^^Traceback (most recent call last):
^  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
^^^^^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>^
^Traceback (most recent call last):
^  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
^^^^^^^^
AssertionError: can only test a child process
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^
^^^ ^ ^ ^ ^ ^ ^ 
 AssertionError :  can only test a child process 
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>Exception ignored in: 
<function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>Traceback (most recent call last):

  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
        self._shutdown_workers()if w.is_alive():

     File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    ^^^Exception ignored in:     ^<function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>^if w.is_alive():
^
Traceback (most recent call last):
^  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
^ ^ ^ ^ ^ 
   File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
 ^^^^^^^^    ^if w.is_alive():^
^^ 
   File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
     ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
    Exception ignored in:  self._shutdown_workers() <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
 
 Traceback (most recent call last):
   File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
       File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
 assert self._parent_pid == os.getpid(), 'can only test a child process' 
    ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'^^
^^^^ ^^ ^^     ^^self._shutdown_workers() ^^
 ^^ ^    ^   File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
^if w.is_alive():^ ^
^ ^^  ^^  ^
 ^^AssertionError ^^:  ^^can only test a child process ^^
 ^^^^^^^^^^^^^^^^^^^
    ^^AssertionError^if w.is_alive():^: ^
^can only test a child process^^ 
^^ ^^ 
^   File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
^ ^ ^ ^^^^^^^^^^^^^^^^^^^^
^AssertionError^: 
can only test a child process  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive

    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^
^^^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^
^AssertionError^: ^can only test a child process^
^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: uploading console lines 70-71
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñà‚ñÑ‚ñÅ‚ñÅ
wandb:   grad_mean/lif_layers.1 ‚ñà‚ñÇ‚ñÅ‚ñÇ
wandb:   grad_mean/output_layer ‚ñà‚ñÉ‚ñÇ‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:               train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 39
wandb:   grad_mean/lif_layers.0 0.03309
wandb:   grad_mean/lif_layers.1 0.01434
wandb:   grad_mean/output_layer 0.16532
wandb:                       lr 0
wandb: spikes/train_avg_layer_0 0.02554
wandb: spikes/train_avg_layer_1 0.00405
wandb:               train_loss 0.18757
wandb:      trainer/global_step 279
wandb:                 val_loss 0.18607
wandb: 
wandb: üöÄ View run fallen-sweep-79 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/046h7372
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_202609-046h7372/logs
wandb: Agent Starting Run: aatx7n4x with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 6.8405760764677005e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_202937-aatx7n4x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-sweep-80
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/aatx7n4x
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 62.9 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
63.0 K    Trainable params
0         Non-trainable params
63.0 K    Total params
0.252     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                     epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                        lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb:  spikes/train_avg_layer_0 ‚ñÅ‚ñÑ‚ñÑ‚ñà
wandb:  spikes/train_avg_layer_1 ‚ñÅ‚ñà‚ñá‚ñá
wandb: spikes/train_avg_layer_10 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_11 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_12 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_13 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_14 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_15 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +11 ...
wandb: 
wandb: Run summary:
wandb:                     epoch 3
wandb:                        lr 1e-05
wandb:  spikes/train_avg_layer_0 0.01948
wandb:  spikes/train_avg_layer_1 0.00204
wandb: spikes/train_avg_layer_10 0
wandb: spikes/train_avg_layer_11 0
wandb: spikes/train_avg_layer_12 0
wandb: spikes/train_avg_layer_13 0
wandb: spikes/train_avg_layer_14 0
wandb: spikes/train_avg_layer_15 0
wandb:                       +11 ...
wandb: 
wandb: üöÄ View run easy-sweep-80 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/aatx7n4x
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_202937-aatx7n4x/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: 3x218r5t with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 2.6508227437863288e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 1
wandb: setting up run 3x218r5t
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_203810-3x218r5t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-81
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/3x218r5t
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 50.6 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
50.7 K    Trainable params
0         Non-trainable params
50.7 K    Total params
0.203     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñà‚ñÜ‚ñÅ
wandb: spikes/train_avg_layer_1 ‚ñà‚ñà‚ñá‚ñÅ
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÇ‚ñÇ‚ñà
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               train_loss ‚ñà‚ñÜ‚ñÉ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñÜ‚ñÉ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 3
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.01605
wandb: spikes/train_avg_layer_1 0.00092
wandb: spikes/train_avg_layer_2 2e-05
wandb: spikes/train_avg_layer_3 0
wandb:               train_loss 0.21508
wandb:      trainer/global_step 27
wandb:                 val_loss 0.21308
wandb: 
wandb: üöÄ View run eternal-sweep-81 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/3x218r5t
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_203810-3x218r5t/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: eyrw6zrp with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.00023827372387143312
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_204208-eyrw6zrp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-82
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/eyrw6zrp
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 944    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
975       Trainable params
0         Non-trainable params
975       Total params
0.004     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                       lr ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñà
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÜ‚ñÑ‚ñà
wandb:               train_loss ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 10
wandb:                       lr 0.0002
wandb: spikes/train_avg_layer_0 0.02908
wandb: spikes/train_avg_layer_1 0.00242
wandb: spikes/train_avg_layer_2 0.00058
wandb: spikes/train_avg_layer_3 2e-05
wandb:               train_loss 0.28214
wandb:      trainer/global_step 76
wandb:                 val_loss 0.27892
wandb: 
wandb: üöÄ View run revived-sweep-82 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/eyrw6zrp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_204208-eyrw6zrp/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 149, in run
    self.on_run_start(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 245, in on_run_start
    iter(data_fetcher)  # creates the iterator inside the fetcher
    ^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fetchers.py", line 105, in __iter__
    super().__iter__()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fetchers.py", line 52, in __iter__
    self.iterator = iter(self.combined_loader)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py", line 351, in __iter__
    iter(iterator)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py", line 92, in __iter__
    super().__iter__()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py", line 43, in __iter__
    self.iterators = [iter(iterable) for iterable in self.iterables]
                      ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 494, in __iter__
    return self._get_iterator()
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 427, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1170, in __init__
    w.start()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 120, in start
    _cleanup()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 64, in _cleanup
    if (child_popen := p._popen) and child_popen.poll() is not None:
                                     ^^^^^^^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/popen_fork.py", line 27, in poll
    pid, sts = os.waitpid(self.pid, flag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
Exception

Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1612, in _shutdown_workers
    if self._persistent_workers or self._workers_status[worker_id]:
                                   ^^^^^^^^^^^^^^^^^^^^
AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'
wandb: Agent Starting Run: lxpezjyx with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 2.4369089502965792e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.8
wandb: setting up run lxpezjyx
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_204310-lxpezjyx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-83
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/lxpezjyx
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 172    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
191       Trainable params
0         Non-trainable params
191       Total params
0.001     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                       lr ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_1 ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_2 ‚ñà‚ñá‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÅ
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 10
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.03379
wandb: spikes/train_avg_layer_1 0.00215
wandb: spikes/train_avg_layer_2 7e-05
wandb: spikes/train_avg_layer_3 0
wandb: spikes/train_avg_layer_4 0
wandb: spikes/train_avg_layer_5 0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run lunar-sweep-83 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/lxpezjyx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_204310-lxpezjyx/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 153, in run
    self.on_advance_end(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 398, in on_advance_end
    self.val_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 145, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 437, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 412, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 620, in validation_step
    layer_outputs.append(x_seq)
      ^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 185, in forward
    h_candidate = torch.tanh(preact)
                  ^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: puqch96f with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.0069040767679474e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 3
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.9
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_204406-puqch96f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-84
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/puqch96f
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 52     | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
71        Trainable params
0         Non-trainable params
71        Total params
0.000     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620><function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>

Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
Exception ignored in:   File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
<function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
    if w.is_alive():  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers

          self._shutdown_workers() 
^^^^  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
^^^^^^^^        
if w.is_alive():self._shutdown_workers()  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive


    File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
     ^^^^^    ^if w.is_alive():^
^^ ^ ^ ^ 
   File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
  ^^^^^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^
^^ ^ ^ 
   File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
       if w.is_alive(): 
    ^ ^ ^ ^ ^ ^     ^^^assert self._parent_pid == os.getpid(), 'can only test a child process'^^
^^^^ ^^ ^^ ^^ ^^     ^^ assert self._parent_pid == os.getpid(), 'can only test a child process'^^ 
^^ ^^  
^    File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
^  ^ ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^^^^^^
^^AssertionError^^: ^^can only test a child process^^
^^^^    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'^^
^^^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^^^
^^AssertionError^^: ^^can only test a child process^^
^^^^^^^
^AssertionError^: ^can only test a child process^
^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception in thread Traceback (most recent call last):
QueueFeederThreadTraceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
OSError: [Errno 9] Bad file descriptor
:
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1012, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 291, in _feed
    queue_sem.release()
ValueError: semaphore or lock released too many times
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^
^^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^
^AssertionError^: ^can only test a child process^
^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
    Traceback (most recent call last):
if w.is_alive():  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__

       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^    ^if w.is_alive():^
^^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^
^  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive

AssertionError: can only test a child process
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
      File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
if w.is_alive():
OSError: [Errno 9] Bad file descriptor
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Exception ignored in: Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
<function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    assert self._parent_pid == os.getpid(), 'can only test a child process'
        self._shutdown_workers() self._shutdown_workers()
 
     File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
   File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
     ^^^^^    ^self._shutdown_workers()^
^    ^if w.is_alive():  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
^
^^ ^ ^ ^ ^     ^if w.is_alive(): ^
 ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^^^^^^^    ^^^if w.is_alive():^^^
^^
^ 
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
^ Exception ignored in: AssertionError^ : ^ <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>can only test a child process^ 

^ Traceback (most recent call last):
^   File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__

^  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
              assert self._parent_pid == os.getpid(), 'can only test a child process' 
^^^ ^ ^     ^     self._shutdown_workers()^ assert self._parent_pid == os.getpid(), 'can only test a child process'
^ 
^ ^  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
  ^  ^  ^  ^ ^^ ^^ ^^ ^^ ^^ ^^ ^^^^^^^^^^^^^^^^^^^    ^^^if w.is_alive():^^^
^^^^^ ^^^ ^
^ ^AssertionError^ ^: ^ ^can only test a child process^ ^
^ ^^^^^^^^^^^^^^^^^^^^^^^^^^Traceback (most recent call last):
^
^^AssertionError^^: ^^can only test a child process^

^  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
^
AssertionError: can only test a child process  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()

  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
    assert self._parent_pid == os.getpid(), 'can only test a child process'
  OSError: [Errno 9] Bad file descriptor
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
OSError: [Errno 9] Bad file descriptor
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    self._shutdown_workers()
      File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    ^if w.is_alive():

AssertionError:  can only test a child process 
     ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
Traceback (most recent call last):
    assert self._parent_pid == os.getpid(), 'can only test a child process'
    File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
    File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
    File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
  OSError: [Errno 9] Bad file descriptor
   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
      File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^
^^^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^
^AssertionError^: ^can only test a child process^
^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 270, in _feed
    send_bytes(obj)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 427, in _send_bytes
    self._send(header + buf)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 384, in _send
    n = write(self._handle, buf)
        ^^^^^^^^^^^^^^^^^^^^^^^^
OSError: [Errno 9] Bad file descriptor
Exception in thread QueueFeederThread:
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           _close(self._handle) 
  Traceback (most recent call last):
 OSError^: ^[Errno 9] Bad file descriptor^
^
^During handling of the above exception, another exception occurred:
^
^Traceback (most recent call last):
^  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
^  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
^^  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
^^  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
^^^^^OSError: [Errno 9] Bad file descriptor
^^^^^^^^^^^^^
AssertionError: can only test a child process
    self.run()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1012, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 291, in _feed
    queue_sem.release()
ValueError: semaphore or lock released too many times
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: uploading console lines 44-44
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ‚ñà‚ñÜ‚ñÇ
wandb:   grad_mean/lif_layers.1 ‚ñÖ‚ñà‚ñÉ‚ñÅ
wandb:   grad_mean/output_layer ‚ñÖ‚ñà‚ñÑ‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: spikes/train_avg_layer_1 ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 39
wandb:   grad_mean/lif_layers.0 0.00227
wandb:   grad_mean/lif_layers.1 0.00953
wandb:   grad_mean/output_layer 0.11664
wandb:                       lr 0
wandb: spikes/train_avg_layer_0 0.01575
wandb: spikes/train_avg_layer_1 0.00084
wandb:               train_loss 0.17636
wandb:      trainer/global_step 279
wandb:                 val_loss 0.17492
wandb: 
wandb: üöÄ View run generous-sweep-84 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/puqch96f
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_204406-puqch96f/logs
wandb: Agent Starting Run: nk28r1wr with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.000729581722104135
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_204728-nk28r1wr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-85
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/nk28r1wr
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 17.5 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
17.7 K    Trainable params
0         Non-trainable params
17.7 K    Total params
0.071     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÉ‚ñÖ‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÇ‚ñÖ‚ñà
wandb:               train_loss ‚ñà‚ñÜ‚ñÉ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñÜ‚ñÉ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 3
wandb:                       lr 0.00071
wandb: spikes/train_avg_layer_0 0.02212
wandb: spikes/train_avg_layer_1 0.01067
wandb:               train_loss 0.245
wandb:      trainer/global_step 27
wandb:                 val_loss 0.23581
wandb: 
wandb: üöÄ View run icy-sweep-85 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/nk28r1wr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_204728-nk28r1wr/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: zmtjgxx9 with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 3.6062185389067183e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 3
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.9
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_204911-zmtjgxx9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-sweep-86
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/zmtjgxx9
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 172    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
191       Trainable params
0         Non-trainable params
191       Total params
0.001     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                  epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: grad_mean/lif_layers.0 ‚ñÅ‚ñà
wandb: grad_mean/lif_layers.1 ‚ñÅ‚ñà
wandb: grad_mean/lif_layers.2 ‚ñÅ‚ñà
wandb: grad_mean/lif_layers.3 ‚ñÅ‚ñà
wandb: grad_mean/lif_layers.4 ‚ñÅ‚ñà
wandb: grad_mean/lif_layers.5 ‚ñÅ‚ñà
wandb: grad_mean/lif_layers.6 ‚ñÅ‚ñà
wandb: grad_mean/lif_layers.7 ‚ñÅ‚ñà
wandb: grad_mean/output_layer ‚ñÅ‚ñà
wandb:                    +12 ...
wandb: 
wandb: Run summary:
wandb:                  epoch 27
wandb: grad_mean/lif_layers.0 0.00023
wandb: grad_mean/lif_layers.1 0.00029
wandb: grad_mean/lif_layers.2 0.00066
wandb: grad_mean/lif_layers.3 0.00093
wandb: grad_mean/lif_layers.4 0.00111
wandb: grad_mean/lif_layers.5 0.00248
wandb: grad_mean/lif_layers.6 0.00472
wandb: grad_mean/lif_layers.7 0.00668
wandb: grad_mean/output_layer 0.15785
wandb:                    +12 ...
wandb: 
wandb: üöÄ View run sage-sweep-86 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/zmtjgxx9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_204911-zmtjgxx9/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 315, in apply
    return user_fn(self, *args)
           ^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 61, in backward
    grad_input = grad_output.clone()
                 ^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: af1cvmtv with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 2.0946519444208068e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 3
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 1
wandb: setting up run af1cvmtv
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_205110-af1cvmtv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-87
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/af1cvmtv
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 400    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
431       Trainable params
0         Non-trainable params
431       Total params
0.002     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1618, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/popen_fork.py", line 40, in wait
    if not wait([self.sentinel], timeout):
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 1136, in wait
    ready = selector.select(timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Exception: 
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: uploading console lines 63-63
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÖ‚ñÅ‚ñà‚ñÅ
wandb:   grad_mean/lif_layers.1 ‚ñÑ‚ñÅ‚ñà‚ñÇ
wandb:   grad_mean/output_layer ‚ñÉ‚ñÅ‚ñà‚ñÇ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_1 ‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 39
wandb:   grad_mean/lif_layers.0 0.00473
wandb:   grad_mean/lif_layers.1 0.00376
wandb:   grad_mean/output_layer 0.15108
wandb:                       lr 0
wandb: spikes/train_avg_layer_0 0.02212
wandb: spikes/train_avg_layer_1 0.00197
wandb:               train_loss 0.18677
wandb:      trainer/global_step 279
wandb:                 val_loss 0.18512
wandb: 
wandb: üöÄ View run silver-sweep-87 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/af1cvmtv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_205110-af1cvmtv/logs
wandb: Agent Starting Run: agvhn8tp with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.00024798026159848644
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.8
wandb: setting up run agvhn8tp
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_205250-agvhn8tp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-sweep-88
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/agvhn8tp
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 332    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
351       Trainable params
0         Non-trainable params
351       Total params
0.001     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                   epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:  grad_mean/lif_layers.0 ‚ñà‚ñÅ‚ñÖ‚ñÜ
wandb:  grad_mean/lif_layers.1 ‚ñÅ‚ñÇ‚ñà‚ñÑ
wandb: grad_mean/lif_layers.10 ‚ñÉ‚ñÅ‚ñÅ‚ñà
wandb: grad_mean/lif_layers.11 ‚ñÉ‚ñÇ‚ñÅ‚ñà
wandb: grad_mean/lif_layers.12 ‚ñÅ‚ñÇ‚ñÅ‚ñà
wandb: grad_mean/lif_layers.13 ‚ñÅ‚ñÉ‚ñÇ‚ñà
wandb: grad_mean/lif_layers.14 ‚ñÉ‚ñÇ‚ñÅ‚ñà
wandb: grad_mean/lif_layers.15 ‚ñà‚ñÜ‚ñá‚ñÅ
wandb:  grad_mean/lif_layers.2 ‚ñÑ‚ñÅ‚ñá‚ñà
wandb:                     +28 ...
wandb: 
wandb: Run summary:
wandb:                   epoch 39
wandb:  grad_mean/lif_layers.0 3e-05
wandb:  grad_mean/lif_layers.1 2e-05
wandb: grad_mean/lif_layers.10 8e-05
wandb: grad_mean/lif_layers.11 0.00015
wandb: grad_mean/lif_layers.12 0.00011
wandb: grad_mean/lif_layers.13 9e-05
wandb: grad_mean/lif_layers.14 0.00026
wandb: grad_mean/lif_layers.15 3e-05
wandb:  grad_mean/lif_layers.2 1e-05
wandb:                     +28 ...
wandb: 
wandb: üöÄ View run playful-sweep-88 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/agvhn8tp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_205250-agvhn8tp/logs
wandb: Agent Starting Run: rvsssqcp with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.0002692746643810551
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 3
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_205747-rvsssqcp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-89
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/rvsssqcp
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 62.9 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
63.0 K    Trainable params
0         Non-trainable params
63.0 K    Total params
0.252     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                     epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                        lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb:  spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÑ‚ñà
wandb:  spikes/train_avg_layer_1 ‚ñÅ‚ñÇ‚ñÖ‚ñà
wandb: spikes/train_avg_layer_10 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_11 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_12 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_13 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_14 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_15 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +11 ...
wandb: 
wandb: Run summary:
wandb:                     epoch 3
wandb:                        lr 0.00026
wandb:  spikes/train_avg_layer_0 0.01937
wandb:  spikes/train_avg_layer_1 0.00142
wandb: spikes/train_avg_layer_10 0
wandb: spikes/train_avg_layer_11 0
wandb: spikes/train_avg_layer_12 0
wandb: spikes/train_avg_layer_13 0
wandb: spikes/train_avg_layer_14 0
wandb: spikes/train_avg_layer_15 0
wandb:                       +11 ...
wandb: 
wandb: üöÄ View run fancy-sweep-89 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/rvsssqcp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_205747-rvsssqcp/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: x2z0alfl with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.00019439095464657911
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.9
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_210611-x2z0alfl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-90
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/x2z0alfl
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 400    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
431       Trainable params
0         Non-trainable params
431       Total params
0.002     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ
wandb:   grad_mean/lif_layers.1 ‚ñÅ
wandb:   grad_mean/output_layer ‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:               train_loss ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 15
wandb:   grad_mean/lif_layers.0 0.02123
wandb:   grad_mean/lif_layers.1 0.00845
wandb:   grad_mean/output_layer 0.40043
wandb:                       lr 0.00013
wandb: spikes/train_avg_layer_0 0.01821
wandb: spikes/train_avg_layer_1 0.00214
wandb:               train_loss 0.31281
wandb:      trainer/global_step 111
wandb:                 val_loss 0.3094
wandb: 
wandb: üöÄ View run noble-sweep-90 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/x2z0alfl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_210611-x2z0alfl/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: 96z5g6c1 with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.5592966831316943e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.9
wandb: setting up run 96z5g6c1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_210709-96z5g6c1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-91
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/96z5g6c1
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 62.9 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
63.0 K    Trainable params
0         Non-trainable params
63.0 K    Total params
0.252     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                     epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                        lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb:  spikes/train_avg_layer_0 ‚ñÉ‚ñÅ‚ñÉ‚ñà
wandb:  spikes/train_avg_layer_1 ‚ñà‚ñÇ‚ñÅ‚ñÖ
wandb: spikes/train_avg_layer_10 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_11 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_12 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_13 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_14 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_15 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +11 ...
wandb: 
wandb: Run summary:
wandb:                     epoch 3
wandb:                        lr 0.0
wandb:  spikes/train_avg_layer_0 0.02022
wandb:  spikes/train_avg_layer_1 0.00141
wandb: spikes/train_avg_layer_10 0
wandb: spikes/train_avg_layer_11 0
wandb: spikes/train_avg_layer_12 0
wandb: spikes/train_avg_layer_13 0
wandb: spikes/train_avg_layer_14 0
wandb: spikes/train_avg_layer_15 0
wandb:                       +11 ...
wandb: 
wandb: üöÄ View run fast-sweep-91 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/96z5g6c1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_210709-96z5g6c1/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: maqnju8k with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.00024644672488851146
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 3
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_211411-maqnju8k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-92
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/maqnju8k
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 172    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
191       Trainable params
0         Non-trainable params
191       Total params
0.001     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:                       lr ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñà‚ñá
wandb: spikes/train_avg_layer_2 ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñá‚ñà
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñà
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 9
wandb:                       lr 0.00021
wandb: spikes/train_avg_layer_0 0.01773
wandb: spikes/train_avg_layer_1 0.00359
wandb: spikes/train_avg_layer_2 0.0024
wandb: spikes/train_avg_layer_3 0.0
wandb: spikes/train_avg_layer_4 0
wandb: spikes/train_avg_layer_5 0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run sweet-sweep-92 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/maqnju8k
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_211411-maqnju8k/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 192, in forward
    sout_t = self._relu(h)
             ^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 565, in apply
    @classmethod
    
Exception

wandb: Agent Starting Run: w8y15acj with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.00033738101669654485
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 3
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_211508-w8y15acj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-93
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/w8y15acj
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 332    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
351       Trainable params
0         Non-trainable params
351       Total params
0.001     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: uploading history steps 82-83, summary, console lines 43-45
wandb: 
wandb: Run history:
wandb:                   epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:  grad_mean/lif_layers.0 ‚ñÅ‚ñÑ‚ñá‚ñà
wandb:  grad_mean/lif_layers.1 ‚ñà‚ñÜ‚ñÑ‚ñÅ
wandb: grad_mean/lif_layers.10 ‚ñà‚ñÜ‚ñÑ‚ñÅ
wandb: grad_mean/lif_layers.11 ‚ñà‚ñÖ‚ñÉ‚ñÅ
wandb: grad_mean/lif_layers.12 ‚ñà‚ñÜ‚ñÉ‚ñÅ
wandb: grad_mean/lif_layers.13 ‚ñà‚ñÜ‚ñÉ‚ñÅ
wandb: grad_mean/lif_layers.14 ‚ñà‚ñÜ‚ñÉ‚ñÅ
wandb: grad_mean/lif_layers.15 ‚ñà‚ñÜ‚ñÉ‚ñÅ
wandb:  grad_mean/lif_layers.2 ‚ñà‚ñÜ‚ñÑ‚ñÅ
wandb:                     +28 ...
wandb: 
wandb: Run summary:
wandb:                   epoch 39
wandb:  grad_mean/lif_layers.0 0.00038
wandb:  grad_mean/lif_layers.1 0.00016
wandb: grad_mean/lif_layers.10 0.00063
wandb: grad_mean/lif_layers.11 0.00058
wandb: grad_mean/lif_layers.12 0.00058
wandb: grad_mean/lif_layers.13 0.0029
wandb: grad_mean/lif_layers.14 0.00364
wandb: grad_mean/lif_layers.15 0.00347
wandb:  grad_mean/lif_layers.2 0.00027
wandb:                     +28 ...
wandb: 
wandb: üöÄ View run trim-sweep-93 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/w8y15acj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_211508-w8y15acj/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: jlb3guaf with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.00018165900007045469
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 3
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.9
wandb: setting up run jlb3guaf
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_212022-jlb3guaf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-94
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/jlb3guaf
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 400    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
431       Trainable params
0         Non-trainable params
431       Total params
0.002     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ
wandb:   grad_mean/lif_layers.1 ‚ñÅ
wandb:   grad_mean/output_layer ‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà
wandb: spikes/train_avg_layer_1 ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb:               train_loss ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 14
wandb:   grad_mean/lif_layers.0 0.01667
wandb:   grad_mean/lif_layers.1 0.00664
wandb:   grad_mean/output_layer 0.30729
wandb:                       lr 0.00013
wandb: spikes/train_avg_layer_0 0.01452
wandb: spikes/train_avg_layer_1 0.00091
wandb:               train_loss 0.25722
wandb:      trainer/global_step 104
wandb:                 val_loss 0.25441
wandb: 
wandb: üöÄ View run worldly-sweep-94 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/jlb3guaf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_212022-jlb3guaf/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 171, in forward
    h_prev = h.detach()
             ^^^^^^^^^^
Exception

wandb: Agent Starting Run: 5k2odo2a with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.00020001488585014464
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 3
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.9
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_212110-5k2odo2a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-95
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/5k2odo2a
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 29.6 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
29.7 K    Trainable params
0         Non-trainable params
29.7 K    Total params
0.119     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñà
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 4
wandb:                       lr 0.00019
wandb: spikes/train_avg_layer_0 0.02161
wandb: spikes/train_avg_layer_1 0.00243
wandb: spikes/train_avg_layer_2 0.00022
wandb: spikes/train_avg_layer_3 0.0
wandb: spikes/train_avg_layer_4 0
wandb: spikes/train_avg_layer_5 0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run rose-sweep-95 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/5k2odo2a
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_212110-5k2odo2a/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 562, in forward
    # For SRC we previously validated that temporal and layer skips
    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/linear.py", line 134, in forward
    return F.linear(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: vhtbpkba with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.00017796240210109752
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 1
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.8
wandb: setting up run vhtbpkba
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_212506-vhtbpkba
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run atomic-sweep-96
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/vhtbpkba
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 4.2 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
4.2 K     Trainable params
0         Non-trainable params
4.2 K     Total params
0.017     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading history steps 10-11, summary, console lines 43-44
wandb: 
wandb: Run history:
wandb:                     epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñà
wandb:                        lr ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÅ
wandb:  spikes/train_avg_layer_0 ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñà
wandb:  spikes/train_avg_layer_1 ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñà
wandb: spikes/train_avg_layer_10 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_11 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_12 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_13 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_14 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_15 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +11 ...
wandb: 
wandb: Run summary:
wandb:                     epoch 5
wandb:                        lr 0.00017
wandb:  spikes/train_avg_layer_0 0.02749
wandb:  spikes/train_avg_layer_1 0.00242
wandb: spikes/train_avg_layer_10 0
wandb: spikes/train_avg_layer_11 0
wandb: spikes/train_avg_layer_12 0
wandb: spikes/train_avg_layer_13 0
wandb: spikes/train_avg_layer_14 0
wandb: spikes/train_avg_layer_15 0
wandb:                       +11 ...
wandb: 
wandb: üöÄ View run atomic-sweep-96 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/vhtbpkba
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_212506-vhtbpkba/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: bgievuxu with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.000916684832004827
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 3
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.9
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_212710-bgievuxu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-sweep-97
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/bgievuxu
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 332    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
351       Trainable params
0         Non-trainable params
351       Total params
0.001     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading history steps 10-11, summary, console lines 42-43
wandb: 
wandb: Run history:
wandb:                     epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñà
wandb:                        lr ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÅ
wandb:  spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñà
wandb:  spikes/train_avg_layer_1 ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñà
wandb: spikes/train_avg_layer_10 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_11 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_12 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_13 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_14 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_15 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +11 ...
wandb: 
wandb: Run summary:
wandb:                     epoch 5
wandb:                        lr 0.00087
wandb:  spikes/train_avg_layer_0 0.00451
wandb:  spikes/train_avg_layer_1 0.00137
wandb: spikes/train_avg_layer_10 0
wandb: spikes/train_avg_layer_11 0
wandb: spikes/train_avg_layer_12 0
wandb: spikes/train_avg_layer_13 0
wandb: spikes/train_avg_layer_14 0
wandb: spikes/train_avg_layer_15 0
wandb:                       +11 ...
wandb: 
wandb: üöÄ View run dark-sweep-97 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/bgievuxu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_212710-bgievuxu/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 185, in forward
    h_candidate = torch.tanh(preact)
                  ^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: lshepk6m with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.0001063705615753578
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 3
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.9
wandb: setting up run lshepk6m
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_212807-lshepk6m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-98
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/lshepk6m
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 62.9 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
63.0 K    Trainable params
0         Non-trainable params
63.0 K    Total params
0.252     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                     epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                        lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb:  spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÑ‚ñà
wandb:  spikes/train_avg_layer_1 ‚ñÅ‚ñÇ‚ñÖ‚ñà
wandb: spikes/train_avg_layer_10 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_11 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_12 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_13 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_14 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_15 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +11 ...
wandb: 
wandb: Run summary:
wandb:                     epoch 3
wandb:                        lr 0.0001
wandb:  spikes/train_avg_layer_0 0.02126
wandb:  spikes/train_avg_layer_1 0.00154
wandb: spikes/train_avg_layer_10 0
wandb: spikes/train_avg_layer_11 0
wandb: spikes/train_avg_layer_12 0
wandb: spikes/train_avg_layer_13 0
wandb: spikes/train_avg_layer_14 0
wandb: spikes/train_avg_layer_15 0
wandb:                       +11 ...
wandb: 
wandb: üöÄ View run fresh-sweep-98 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/lshepk6m
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_212807-lshepk6m/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: vn6dzjq1 with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 2.9185203103423514e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_213611-vn6dzjq1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-99
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/vn6dzjq1
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 332    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
351       Trainable params
0         Non-trainable params
351       Total params
0.001     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                   epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:  grad_mean/lif_layers.0 ‚ñÖ‚ñÑ‚ñà‚ñÅ
wandb:  grad_mean/lif_layers.1 ‚ñÖ‚ñÉ‚ñà‚ñÅ
wandb: grad_mean/lif_layers.10 ‚ñÜ‚ñÖ‚ñà‚ñÅ
wandb: grad_mean/lif_layers.11 ‚ñÜ‚ñÖ‚ñà‚ñÅ
wandb: grad_mean/lif_layers.12 ‚ñÜ‚ñÖ‚ñà‚ñÅ
wandb: grad_mean/lif_layers.13 ‚ñÜ‚ñÖ‚ñà‚ñÅ
wandb: grad_mean/lif_layers.14 ‚ñÜ‚ñÖ‚ñà‚ñÅ
wandb: grad_mean/lif_layers.15 ‚ñÜ‚ñÖ‚ñà‚ñÅ
wandb:  grad_mean/lif_layers.2 ‚ñÖ‚ñÉ‚ñà‚ñÅ
wandb:                     +28 ...
wandb: 
wandb: Run summary:
wandb:                   epoch 39
wandb:  grad_mean/lif_layers.0 1e-05
wandb:  grad_mean/lif_layers.1 2e-05
wandb: grad_mean/lif_layers.10 0.00162
wandb: grad_mean/lif_layers.11 0.00143
wandb: grad_mean/lif_layers.12 0.00182
wandb: grad_mean/lif_layers.13 0.00279
wandb: grad_mean/lif_layers.14 0.00262
wandb: grad_mean/lif_layers.15 0.00239
wandb:  grad_mean/lif_layers.2 2e-05
wandb:                     +28 ...
wandb: 
wandb: üöÄ View run cosmic-sweep-99 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/vn6dzjq1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_213611-vn6dzjq1/logs
wandb: Agent Starting Run: qo8bkyzw with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 3.2715870135531463e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.9
wandb: setting up run qo8bkyzw
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_214121-qo8bkyzw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-100
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/qo8bkyzw
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 92     | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
111       Trainable params
0         Non-trainable params
111       Total params
0.000     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ
wandb:   grad_mean/lif_layers.1 ‚ñÅ
wandb:   grad_mean/lif_layers.2 ‚ñÅ
wandb:   grad_mean/lif_layers.3 ‚ñÅ
wandb:   grad_mean/output_layer ‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:                       +4 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 17
wandb:   grad_mean/lif_layers.0 0.05047
wandb:   grad_mean/lif_layers.1 0.01373
wandb:   grad_mean/lif_layers.2 0.01301
wandb:   grad_mean/lif_layers.3 0.01904
wandb:   grad_mean/output_layer 0.61424
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.00036
wandb: spikes/train_avg_layer_1 0.00012
wandb: spikes/train_avg_layer_2 0.0
wandb:                       +4 ...
wandb: 
wandb: üöÄ View run stellar-sweep-100 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/qo8bkyzw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_214121-qo8bkyzw/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 167, in forward
    x = self.rho * torch.tanh(i / self.rho)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: 2sxlfogt with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.000993325829341105
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 3
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_214207-2sxlfogt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-sweep-101
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/2sxlfogt
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 92     | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
111       Trainable params
0         Non-trainable params
111       Total params
0.000     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ‚ñà
wandb:   grad_mean/lif_layers.1 ‚ñÅ‚ñà
wandb:   grad_mean/lif_layers.2 ‚ñÅ‚ñà
wandb:   grad_mean/lif_layers.3 ‚ñà‚ñÅ
wandb:   grad_mean/output_layer ‚ñà‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                       +4 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 23
wandb:   grad_mean/lif_layers.0 0.14712
wandb:   grad_mean/lif_layers.1 0.06249
wandb:   grad_mean/lif_layers.2 0.03385
wandb:   grad_mean/lif_layers.3 0.02613
wandb:   grad_mean/output_layer 0.64604
wandb:                       lr 0.00034
wandb: spikes/train_avg_layer_0 0.0466
wandb: spikes/train_avg_layer_1 0.00997
wandb: spikes/train_avg_layer_2 0.00541
wandb:                       +4 ...
wandb: 
wandb: üöÄ View run likely-sweep-101 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/2sxlfogt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_214207-2sxlfogt/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 153, in run
    self.on_advance_end(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 398, in on_advance_end
    self.val_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 145, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 437, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 412, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 620, in validation_step
    layer_outputs.append(x_seq)
      ^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 185, in forward
    h_candidate = torch.tanh(preact)
                  ^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: b7yg5pr4 with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.7620191450380394e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 1
wandb: setting up run b7yg5pr4
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_214309-b7yg5pr4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-102
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/b7yg5pr4
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 50.6 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
50.7 K    Trainable params
0         Non-trainable params
50.7 K    Total params
0.203     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÉ‚ñÅ‚ñÅ‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÉ‚ñÖ‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÉ‚ñá‚ñà
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               train_loss ‚ñà‚ñÜ‚ñÉ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñÜ‚ñÉ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 3
wandb:                       lr 2e-05
wandb: spikes/train_avg_layer_0 0.01714
wandb: spikes/train_avg_layer_1 0.00141
wandb: spikes/train_avg_layer_2 8e-05
wandb: spikes/train_avg_layer_3 0
wandb:               train_loss 0.22653
wandb:      trainer/global_step 27
wandb:                 val_loss 0.22438
wandb: 
wandb: üöÄ View run stoic-sweep-102 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/b7yg5pr4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_214309-b7yg5pr4/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: et5tvkzw with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.00017484176745376744
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 1
wandb: setting up run et5tvkzw
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_214707-et5tvkzw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-103
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/et5tvkzw
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 944    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
975       Trainable params
0         Non-trainable params
975       Total params
0.004     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                       lr ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb: spikes/train_avg_layer_1 ‚ñá‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñà‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñà‚ñà
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà
wandb:               train_loss ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 10
wandb:                       lr 0.00014
wandb: spikes/train_avg_layer_0 0.02533
wandb: spikes/train_avg_layer_1 0.00378
wandb: spikes/train_avg_layer_2 7e-05
wandb: spikes/train_avg_layer_3 0.0
wandb:               train_loss 0.23195
wandb:      trainer/global_step 76
wandb:                 val_loss 0.22946
wandb: 
wandb: üöÄ View run zany-sweep-103 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/et5tvkzw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_214707-et5tvkzw/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 315, in apply
    return user_fn(self, *args)
           ^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 61, in backward
    grad_input = grad_output.clone()
                 ^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: bsbqv366 with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 6.273430798450726e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.9
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_214809-bsbqv366
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-104
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/bsbqv366
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 50.6 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
50.7 K    Trainable params
0         Non-trainable params
50.7 K    Total params
0.203     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception in thread QueueFeederThread:
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1012, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 291, in _feed
    queue_sem.release()
ValueError: semaphore or lock released too many times
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÑ‚ñá‚ñà‚ñÅ
wandb: spikes/train_avg_layer_1 ‚ñá‚ñÅ‚ñà‚ñÉ
wandb: spikes/train_avg_layer_2 ‚ñà‚ñà‚ñÜ‚ñÅ
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               train_loss ‚ñà‚ñÜ‚ñÉ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñÜ‚ñÉ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 3
wandb:                       lr 1e-05
wandb: spikes/train_avg_layer_0 0.01754
wandb: spikes/train_avg_layer_1 0.0012
wandb: spikes/train_avg_layer_2 3e-05
wandb: spikes/train_avg_layer_3 0
wandb:               train_loss 0.25618
wandb:      trainer/global_step 27
wandb:                 val_loss 0.2538
wandb: 
wandb: üöÄ View run pretty-sweep-104 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/bsbqv366
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_214809-bsbqv366/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 189, in forward
    hs = zs * hs_prev + (1.0 - zs) * h_prev
                         ~~~~^~~~
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 38, in wrapped
    @functools.wraps(f)
    
Exception

wandb: Agent Starting Run: mi8cgns3 with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.00011252115206949056
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_215206-mi8cgns3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-105
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/mi8cgns3
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 92     | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
111       Trainable params
0         Non-trainable params
111       Total params
0.000     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^    ^^if w.is_alive():^
^^ ^ 
   File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'^
^^^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^
^AssertionError^: ^can only test a child process^
^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
Exception ignored in:   File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
<function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
Exception ignored in:   File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
<function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
      File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
self._shutdown_workers()
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
           ^if w.is_alive():^
^^ ^ ^ ^ ^ ^ ^ ^^^    ^
if w.is_alive():^  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive

^^ ^ ^ ^ ^ ^ ^ ^^Exception ignored in: 
^  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
<function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>^
^Traceback (most recent call last):
^  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
               assert self._parent_pid == os.getpid(), 'can only test a child process'^
^^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^    ^^    assert self._parent_pid == os.getpid(), 'can only test a child process'^^self._shutdown_workers()
^^
^^ ^^   File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^
^^AssertionError^^: ^^can only test a child process^^
^^^^^^^^    ^^if w.is_alive():^^
^^^ ^^ ^^ 
^ AssertionError^ : ^ can only test a child process^ 
^^^^^^^^^^^^^^^^^^^^^^^^^

  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
AssertionError: can only test a child process
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñà‚ñÇ‚ñÇ‚ñÅ
wandb:   grad_mean/lif_layers.1 ‚ñÅ‚ñà‚ñÑ‚ñÉ
wandb:   grad_mean/lif_layers.2 ‚ñÅ‚ñà‚ñÖ‚ñÉ
wandb:   grad_mean/lif_layers.3 ‚ñÑ‚ñà‚ñÉ‚ñÅ
wandb:   grad_mean/output_layer ‚ñÑ‚ñà‚ñÉ‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: spikes/train_avg_layer_2 ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +4 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 39
wandb:   grad_mean/lif_layers.0 0.00309
wandb:   grad_mean/lif_layers.1 0.00059
wandb:   grad_mean/lif_layers.2 0.00051
wandb:   grad_mean/lif_layers.3 0.00053
wandb:   grad_mean/output_layer 0.01084
wandb:                       lr 0
wandb: spikes/train_avg_layer_0 0.03087
wandb: spikes/train_avg_layer_1 0.00529
wandb: spikes/train_avg_layer_2 0.00305
wandb:                       +4 ...
wandb: 
wandb: üöÄ View run daily-sweep-105 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/mi8cgns3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_215206-mi8cgns3/logs
wandb: Agent Starting Run: y269j658 with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.738633715006325e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 3
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.9
wandb: setting up run y269j658
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_215431-y269j658
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-106
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/y269j658
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 29.6 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
29.7 K    Trainable params
0         Non-trainable params
29.7 K    Total params
0.119     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÉ‚ñÖ‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÉ‚ñÖ‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÇ‚ñà‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 3
wandb:                       lr 2e-05
wandb: spikes/train_avg_layer_0 0.02331
wandb: spikes/train_avg_layer_1 0.00111
wandb: spikes/train_avg_layer_2 1e-05
wandb: spikes/train_avg_layer_3 0
wandb: spikes/train_avg_layer_4 0
wandb: spikes/train_avg_layer_5 0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run cosmic-sweep-106 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/y269j658
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_215431-y269j658/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: 2k0dn679 with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 9.70191860780412e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 3
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_215807-2k0dn679
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serene-sweep-107
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/2k0dn679
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 52     | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
71        Trainable params
0         Non-trainable params
71        Total params
0.000     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-43
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ‚ñÑ‚ñá‚ñà
wandb:   grad_mean/lif_layers.1 ‚ñà‚ñÜ‚ñÖ‚ñÅ
wandb:   grad_mean/output_layer ‚ñà‚ñá‚ñÉ‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_1 ‚ñÜ‚ñá‚ñá‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:               train_loss ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 37
wandb:   grad_mean/lif_layers.0 0.01297
wandb:   grad_mean/lif_layers.1 0.00943
wandb:   grad_mean/output_layer 0.13529
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.02559
wandb: spikes/train_avg_layer_1 0.00289
wandb:               train_loss 0.18133
wandb:      trainer/global_step 265
wandb:                 val_loss 0.17978
wandb: 
wandb: üöÄ View run serene-sweep-107 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/2k0dn679
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_215807-2k0dn679/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 149, in run
    self.on_run_start(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 245, in on_run_start
    iter(data_fetcher)  # creates the iterator inside the fetcher
    ^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fetchers.py", line 105, in __iter__
    super().__iter__()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fetchers.py", line 52, in __iter__
    self.iterator = iter(self.combined_loader)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py", line 351, in __iter__
    iter(iterator)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py", line 92, in __iter__
    super().__iter__()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py", line 43, in __iter__
    self.iterators = [iter(iterable) for iterable in self.iterables]
                      ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 494, in __iter__
    return self._get_iterator()
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 427, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1170, in __init__
    w.start()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 120, in start
    _cleanup()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 64, in _cleanup
    if (child_popen := p._popen) and child_popen.poll() is not None:
                                     ^^^^^^^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/popen_fork.py", line 27, in poll
    pid, sts = os.waitpid(self.pid, flag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
Exception

Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1612, in _shutdown_workers
    if self._persistent_workers or self._workers_status[worker_id]:
                                   ^^^^^^^^^^^^^^^^^^^^
AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'
wandb: Agent Starting Run: z59wm6h8 with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.0002803729682765262
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 3
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_215909-z59wm6h8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-sweep-108
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/z59wm6h8
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 116 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
116 K     Trainable params
0         Non-trainable params
116 K     Total params
0.467     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÑ‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÇ‚ñÖ‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÅ‚ñÉ‚ñà
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñà
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñà
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñà
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 3
wandb:                       lr 0.00027
wandb: spikes/train_avg_layer_0 0.02063
wandb: spikes/train_avg_layer_1 0.00329
wandb: spikes/train_avg_layer_2 0.00137
wandb: spikes/train_avg_layer_3 0.00037
wandb: spikes/train_avg_layer_4 3e-05
wandb: spikes/train_avg_layer_5 0.0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run fluent-sweep-108 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/z59wm6h8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_215909-z59wm6h8/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: 9yud3clc with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 2.8688697768650467e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 1
wandb: setting up run 9yud3clc
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_220810-9yud3clc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-109
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/9yud3clc
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 2.0 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
2.1 K     Trainable params
0         Non-trainable params
2.1 K     Total params
0.008     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñÉ‚ñÅ‚ñÑ‚ñÖ
wandb: spikes/train_avg_layer_1 ‚ñà‚ñá‚ñá‚ñÉ‚ñÅ
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÖ‚ñá‚ñà‚ñá
wandb: spikes/train_avg_layer_3 ‚ñà‚ñÅ‚ñÇ‚ñÑ‚ñÑ
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 4
wandb:                       lr 3e-05
wandb: spikes/train_avg_layer_0 0.03029
wandb: spikes/train_avg_layer_1 0.00365
wandb: spikes/train_avg_layer_2 0.00098
wandb: spikes/train_avg_layer_3 0.0
wandb: spikes/train_avg_layer_4 0
wandb: spikes/train_avg_layer_5 0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run desert-sweep-109 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/9yud3clc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_220810-9yud3clc/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: 0zi01giq with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.00037641338348362114
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.8
wandb: setting up run 0zi01giq
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_220907-0zi01giq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-110
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/0zi01giq
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 248 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
248 K     Trainable params
0         Non-trainable params
248 K     Total params
0.995     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                     epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                        lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb:  spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÑ‚ñà
wandb:  spikes/train_avg_layer_1 ‚ñÅ‚ñÇ‚ñÑ‚ñà
wandb: spikes/train_avg_layer_10 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_11 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_12 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_13 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_14 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_15 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +11 ...
wandb: 
wandb: Run summary:
wandb:                     epoch 3
wandb:                        lr 0.00037
wandb:  spikes/train_avg_layer_0 0.02134
wandb:  spikes/train_avg_layer_1 0.00355
wandb: spikes/train_avg_layer_10 0
wandb: spikes/train_avg_layer_11 0
wandb: spikes/train_avg_layer_12 0
wandb: spikes/train_avg_layer_13 0
wandb: spikes/train_avg_layer_14 0
wandb: spikes/train_avg_layer_15 0
wandb:                       +11 ...
wandb: 
wandb: üöÄ View run fresh-sweep-110 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/0zi01giq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_220907-0zi01giq/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: fya8s69r with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.5109183457348248e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 1
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.9
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_222607-fya8s69r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-sweep-111
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/fya8s69r
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 400    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
431       Trainable params
0         Non-trainable params
431       Total params
0.002     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ
wandb:   grad_mean/lif_layers.1 ‚ñÅ
wandb:   grad_mean/output_layer ‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:               train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 17
wandb:   grad_mean/lif_layers.0 0.00907
wandb:   grad_mean/lif_layers.1 0.00456
wandb:   grad_mean/output_layer 0.14518
wandb:                       lr 1e-05
wandb: spikes/train_avg_layer_0 0.01626
wandb: spikes/train_avg_layer_1 0.00287
wandb:               train_loss 0.181
wandb:      trainer/global_step 125
wandb:                 val_loss 0.17949
wandb: 
wandb: üöÄ View run visionary-sweep-111 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/fya8s69r
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_222607-fya8s69r/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 171, in forward
    h_prev = h.detach()
             ^^^^^^^^^^
Exception

wandb: Agent Starting Run: v5oo68j2 with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.2348155808495122e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.9
wandb: setting up run v5oo68j2
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_222710-v5oo68j2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-sweep-112
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/v5oo68j2
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 13.0 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
13.1 K    Trainable params
0         Non-trainable params
13.1 K    Total params
0.052     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñá‚ñà‚ñá‚ñÉ‚ñÅ
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñà‚ñÖ‚ñÑ‚ñÑ
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñà
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               train_loss ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 4
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.02245
wandb: spikes/train_avg_layer_1 0.00169
wandb: spikes/train_avg_layer_2 3e-05
wandb: spikes/train_avg_layer_3 0
wandb:               train_loss 0.2415
wandb:      trainer/global_step 34
wandb:                 val_loss 0.23925
wandb: 
wandb: üöÄ View run mild-sweep-112 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/v5oo68j2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_222710-v5oo68j2/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: 7vwi97xe with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 3.2999874640761275e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 3
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.9
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_222908-7vwi97xe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-113
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/7vwi97xe
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 944    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
975       Trainable params
0         Non-trainable params
975       Total params
0.004     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñá‚ñÉ‚ñà‚ñÅ
wandb:   grad_mean/lif_layers.1 ‚ñá‚ñÜ‚ñà‚ñÅ
wandb:   grad_mean/lif_layers.2 ‚ñà‚ñá‚ñà‚ñÅ
wandb:   grad_mean/lif_layers.3 ‚ñà‚ñá‚ñá‚ñÅ
wandb:   grad_mean/output_layer ‚ñà‚ñà‚ñà‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb: spikes/train_avg_layer_2 ‚ñà‚ñá‚ñà‚ñà‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ
wandb:                       +4 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 39
wandb:   grad_mean/lif_layers.0 0.00231
wandb:   grad_mean/lif_layers.1 0.00135
wandb:   grad_mean/lif_layers.2 0.00067
wandb:   grad_mean/lif_layers.3 0.0009
wandb:   grad_mean/output_layer 0.05074
wandb:                       lr 0
wandb: spikes/train_avg_layer_0 0.01876
wandb: spikes/train_avg_layer_1 0.00084
wandb: spikes/train_avg_layer_2 0.0
wandb:                       +4 ...
wandb: 
wandb: üöÄ View run flowing-sweep-113 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/7vwi97xe
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_222908-7vwi97xe/logs
wandb: Agent Starting Run: s53bx5lr with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 3.3700300851925476e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 3
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.9
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_223240-s53bx5lr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-114
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/s53bx5lr
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 4.2 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
4.2 K     Trainable params
0         Non-trainable params
4.2 K     Total params
0.017     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                     epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                        lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb:  spikes/train_avg_layer_0 ‚ñà‚ñÖ‚ñÅ‚ñÅ
wandb:  spikes/train_avg_layer_1 ‚ñà‚ñÖ‚ñÉ‚ñÅ
wandb: spikes/train_avg_layer_10 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_11 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_12 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_13 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_14 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_15 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +11 ...
wandb: 
wandb: Run summary:
wandb:                     epoch 3
wandb:                        lr 0.0
wandb:  spikes/train_avg_layer_0 0.01384
wandb:  spikes/train_avg_layer_1 0.00017
wandb: spikes/train_avg_layer_10 0
wandb: spikes/train_avg_layer_11 0
wandb: spikes/train_avg_layer_12 0
wandb: spikes/train_avg_layer_13 0
wandb: spikes/train_avg_layer_14 0
wandb: spikes/train_avg_layer_15 0
wandb:                       +11 ...
wandb: 
wandb: üöÄ View run azure-sweep-114 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/s53bx5lr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_223240-s53bx5lr/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 167, in forward
    x = self.rho * torch.tanh(i / self.rho)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: iy8xfsyn with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.0006830218113379545
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 1
wandb: setting up run iy8xfsyn
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_223408-iy8xfsyn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sweep-115
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/iy8xfsyn
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 332    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
351       Trainable params
0         Non-trainable params
351       Total params
0.001     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                   epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:  grad_mean/lif_layers.0 ‚ñÅ‚ñÇ‚ñá‚ñà
wandb:  grad_mean/lif_layers.1 ‚ñÅ‚ñÇ‚ñá‚ñà
wandb: grad_mean/lif_layers.10 ‚ñà‚ñÇ‚ñÇ‚ñÅ
wandb: grad_mean/lif_layers.11 ‚ñà‚ñÉ‚ñÇ‚ñÅ
wandb: grad_mean/lif_layers.12 ‚ñà‚ñÉ‚ñÇ‚ñÅ
wandb: grad_mean/lif_layers.13 ‚ñà‚ñÉ‚ñÇ‚ñÅ
wandb: grad_mean/lif_layers.14 ‚ñà‚ñÉ‚ñÇ‚ñÅ
wandb: grad_mean/lif_layers.15 ‚ñà‚ñÉ‚ñÅ‚ñÅ
wandb:  grad_mean/lif_layers.2 ‚ñÅ‚ñÇ‚ñá‚ñà
wandb:                     +28 ...
wandb: 
wandb: Run summary:
wandb:                   epoch 39
wandb:  grad_mean/lif_layers.0 0.00224
wandb:  grad_mean/lif_layers.1 0.00276
wandb: grad_mean/lif_layers.10 0.00199
wandb: grad_mean/lif_layers.11 0.0028
wandb: grad_mean/lif_layers.12 0.00536
wandb: grad_mean/lif_layers.13 0.00494
wandb: grad_mean/lif_layers.14 0.00286
wandb: grad_mean/lif_layers.15 0.00351
wandb:  grad_mean/lif_layers.2 0.00175
wandb:                     +28 ...
wandb: 
wandb: üöÄ View run light-sweep-115 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/iy8xfsyn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_223408-iy8xfsyn/logs
wandb: Agent Starting Run: d51e5c21 with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.0970627384418832e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_223902-d51e5c21
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-116
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/d51e5c21
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 17.5 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
17.7 K    Trainable params
0         Non-trainable params
17.7 K    Total params
0.071     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñà
wandb:               train_loss ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 4
wandb:                       lr 1e-05
wandb: spikes/train_avg_layer_0 0.0236
wandb: spikes/train_avg_layer_1 0.00233
wandb:               train_loss 0.24397
wandb:      trainer/global_step 34
wandb:                 val_loss 0.24153
wandb: 
wandb: üöÄ View run eager-sweep-116 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/d51e5c21
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_223902-d51e5c21/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: be5oqdpk with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 2.1419973125069073e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 3
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.9
wandb: setting up run be5oqdpk
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_224111-be5oqdpk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-sweep-117
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/be5oqdpk
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 172    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
191       Trainable params
0         Non-trainable params
191       Total params
0.001     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                  epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: grad_mean/lif_layers.0 ‚ñÉ‚ñÅ‚ñÖ‚ñà
wandb: grad_mean/lif_layers.1 ‚ñÅ‚ñÑ‚ñà‚ñÖ
wandb: grad_mean/lif_layers.2 ‚ñÅ‚ñÑ‚ñà‚ñÖ
wandb: grad_mean/lif_layers.3 ‚ñÅ‚ñÑ‚ñà‚ñÜ
wandb: grad_mean/lif_layers.4 ‚ñÅ‚ñÑ‚ñà‚ñÜ
wandb: grad_mean/lif_layers.5 ‚ñÅ‚ñÑ‚ñà‚ñÜ
wandb: grad_mean/lif_layers.6 ‚ñÅ‚ñÉ‚ñà‚ñÖ
wandb: grad_mean/lif_layers.7 ‚ñÅ‚ñÉ‚ñà‚ñÖ
wandb: grad_mean/output_layer ‚ñÅ‚ñÇ‚ñà‚ñÖ
wandb:                    +12 ...
wandb: 
wandb: Run summary:
wandb:                  epoch 39
wandb: grad_mean/lif_layers.0 0.00107
wandb: grad_mean/lif_layers.1 0.00105
wandb: grad_mean/lif_layers.2 0.00091
wandb: grad_mean/lif_layers.3 0.00116
wandb: grad_mean/lif_layers.4 0.00096
wandb: grad_mean/lif_layers.5 0.00086
wandb: grad_mean/lif_layers.6 0.0009
wandb: grad_mean/lif_layers.7 0.00077
wandb: grad_mean/output_layer 0.04629
wandb:                    +12 ...
wandb: 
wandb: üöÄ View run vocal-sweep-117 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/be5oqdpk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_224111-be5oqdpk/logs
wandb: Agent Starting Run: 2nvjt8en with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 3.0024858143586274e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_224357-2nvjt8en
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-118
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/2nvjt8en
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 13.0 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
13.1 K    Trainable params
0         Non-trainable params
13.1 K    Total params
0.052     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ
wandb:   grad_mean/lif_layers.1 ‚ñÅ
wandb:   grad_mean/lif_layers.2 ‚ñÅ
wandb:   grad_mean/lif_layers.3 ‚ñÅ
wandb:   grad_mean/output_layer ‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ
wandb: spikes/train_avg_layer_1 ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb:                       +4 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 14
wandb:   grad_mean/lif_layers.0 0.00292
wandb:   grad_mean/lif_layers.1 0.00171
wandb:   grad_mean/lif_layers.2 0.00155
wandb:   grad_mean/lif_layers.3 0.00178
wandb:   grad_mean/output_layer 0.18475
wandb:                       lr 2e-05
wandb: spikes/train_avg_layer_0 0.01712
wandb: spikes/train_avg_layer_1 0.0014
wandb: spikes/train_avg_layer_2 3e-05
wandb:                       +4 ...
wandb: 
wandb: üöÄ View run denim-sweep-118 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/2nvjt8en
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_224357-2nvjt8en/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: 4dhdh4eg with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.8586172503957324e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_224911-4dhdh4eg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-119
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/4dhdh4eg
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 332    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
351       Trainable params
0         Non-trainable params
351       Total params
0.001     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                   epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:  grad_mean/lif_layers.0 ‚ñÅ‚ñà‚ñÖ‚ñÖ
wandb:  grad_mean/lif_layers.1 ‚ñÖ‚ñà‚ñÖ‚ñÅ
wandb: grad_mean/lif_layers.10 ‚ñà‚ñá‚ñá‚ñÅ
wandb: grad_mean/lif_layers.11 ‚ñà‚ñá‚ñÜ‚ñÅ
wandb: grad_mean/lif_layers.12 ‚ñà‚ñá‚ñÜ‚ñÅ
wandb: grad_mean/lif_layers.13 ‚ñà‚ñá‚ñÜ‚ñÅ
wandb: grad_mean/lif_layers.14 ‚ñà‚ñá‚ñÜ‚ñÅ
wandb: grad_mean/lif_layers.15 ‚ñà‚ñÜ‚ñá‚ñÅ
wandb:  grad_mean/lif_layers.2 ‚ñá‚ñÜ‚ñà‚ñÅ
wandb:                     +28 ...
wandb: 
wandb: Run summary:
wandb:                   epoch 39
wandb:  grad_mean/lif_layers.0 0.00027
wandb:  grad_mean/lif_layers.1 0.00026
wandb: grad_mean/lif_layers.10 0.00092
wandb: grad_mean/lif_layers.11 0.00135
wandb: grad_mean/lif_layers.12 0.00097
wandb: grad_mean/lif_layers.13 0.00107
wandb: grad_mean/lif_layers.14 0.00231
wandb: grad_mean/lif_layers.15 0.00357
wandb:  grad_mean/lif_layers.2 0.00019
wandb:                     +28 ...
wandb: 
wandb: üöÄ View run absurd-sweep-119 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/4dhdh4eg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_224911-4dhdh4eg/logs
wandb: Agent Starting Run: bjp4s7xz with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 9.384090537094184e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_225415-bjp4s7xz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-120
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/bjp4s7xz
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 172    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
191       Trainable params
0         Non-trainable params
191       Total params
0.001     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: uploading console lines 42-43
wandb: 
wandb: Run history:
wandb:                  epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: grad_mean/lif_layers.0 ‚ñÅ‚ñÖ‚ñà‚ñá
wandb: grad_mean/lif_layers.1 ‚ñÅ‚ñÑ‚ñá‚ñà
wandb: grad_mean/lif_layers.2 ‚ñÅ‚ñá‚ñà‚ñÉ
wandb: grad_mean/lif_layers.3 ‚ñÇ‚ñà‚ñà‚ñÅ
wandb: grad_mean/lif_layers.4 ‚ñÇ‚ñà‚ñà‚ñÅ
wandb: grad_mean/lif_layers.5 ‚ñÇ‚ñà‚ñà‚ñÅ
wandb: grad_mean/lif_layers.6 ‚ñÉ‚ñà‚ñà‚ñÅ
wandb: grad_mean/lif_layers.7 ‚ñÉ‚ñà‚ñà‚ñÅ
wandb: grad_mean/output_layer ‚ñÉ‚ñà‚ñà‚ñÅ
wandb:                    +12 ...
wandb: 
wandb: Run summary:
wandb:                  epoch 39
wandb: grad_mean/lif_layers.0 0.00144
wandb: grad_mean/lif_layers.1 0.00095
wandb: grad_mean/lif_layers.2 0.00099
wandb: grad_mean/lif_layers.3 0.00051
wandb: grad_mean/lif_layers.4 0.00048
wandb: grad_mean/lif_layers.5 0.00049
wandb: grad_mean/lif_layers.6 0.0006
wandb: grad_mean/lif_layers.7 0.00083
wandb: grad_mean/output_layer 0.02254
wandb:                    +12 ...
wandb: 
wandb: üöÄ View run rosy-sweep-120 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/bjp4s7xz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_225415-bjp4s7xz/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: qotzniu8 with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 2.7849181857173072e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 1
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_225705-qotzniu8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-121
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/qotzniu8
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 13.0 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
13.1 K    Trainable params
0         Non-trainable params
13.1 K    Total params
0.052     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñà
wandb: spikes/train_avg_layer_1 ‚ñà‚ñÑ‚ñÅ‚ñÇ‚ñÖ
wandb: spikes/train_avg_layer_2 ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               train_loss ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 4
wandb:                       lr 3e-05
wandb: spikes/train_avg_layer_0 0.02197
wandb: spikes/train_avg_layer_1 0.00211
wandb: spikes/train_avg_layer_2 0.00019
wandb: spikes/train_avg_layer_3 0
wandb:               train_loss 0.21421
wandb:      trainer/global_step 34
wandb:                 val_loss 0.21218
wandb: 
wandb: üöÄ View run prime-sweep-121 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/qotzniu8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_225705-qotzniu8/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: jk6jbx8m with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 2.7927532163476868e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 1
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.9
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_225910-jk6jbx8m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-122
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/jk6jbx8m
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 52     | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
71        Trainable params
0         Non-trainable params
71        Total params
0.000     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñà‚ñÖ‚ñÅ‚ñà
wandb:   grad_mean/lif_layers.1 ‚ñÖ‚ñÅ‚ñÉ‚ñà
wandb:   grad_mean/output_layer ‚ñá‚ñÑ‚ñà‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:               train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 39
wandb:   grad_mean/lif_layers.0 0.01344
wandb:   grad_mean/lif_layers.1 0.00254
wandb:   grad_mean/output_layer 0.04175
wandb:                       lr 0
wandb: spikes/train_avg_layer_0 0.02412
wandb: spikes/train_avg_layer_1 0.00298
wandb:               train_loss 0.1631
wandb:      trainer/global_step 279
wandb:                 val_loss 0.16245
wandb: 
wandb: üöÄ View run robust-sweep-122 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/jk6jbx8m
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_225910-jk6jbx8m/logs
wandb: Agent Starting Run: kose34xi with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 2.9625234068567497e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_230007-kose34xi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-123
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/kose34xi
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 29.6 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
29.7 K    Trainable params
0         Non-trainable params
29.7 K    Total params
0.119     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                  epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: grad_mean/lif_layers.0 ‚ñÅ
wandb: grad_mean/lif_layers.1 ‚ñÅ
wandb: grad_mean/lif_layers.2 ‚ñÅ
wandb: grad_mean/lif_layers.3 ‚ñÅ
wandb: grad_mean/lif_layers.4 ‚ñÅ
wandb: grad_mean/lif_layers.5 ‚ñÅ
wandb: grad_mean/lif_layers.6 ‚ñÅ
wandb: grad_mean/lif_layers.7 ‚ñÅ
wandb: grad_mean/output_layer ‚ñÅ
wandb:                    +12 ...
wandb: 
wandb: Run summary:
wandb:                  epoch 14
wandb: grad_mean/lif_layers.0 0.00145
wandb: grad_mean/lif_layers.1 0.00064
wandb: grad_mean/lif_layers.2 0.00061
wandb: grad_mean/lif_layers.3 0.00079
wandb: grad_mean/lif_layers.4 0.001
wandb: grad_mean/lif_layers.5 0.0012
wandb: grad_mean/lif_layers.6 0.00136
wandb: grad_mean/lif_layers.7 0.00158
wandb: grad_mean/output_layer 0.18285
wandb:                    +12 ...
wandb: 
wandb: üöÄ View run colorful-sweep-123 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/kose34xi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_230007-kose34xi/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 167, in forward
    x = self.rho * torch.tanh(i / self.rho)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: l22p7exw with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.0006951034723930782
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 1
wandb: setting up run l22p7exw
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_231010-l22p7exw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-124
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/l22p7exw
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 944    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
975       Trainable params
0         Non-trainable params
975       Total params
0.004     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading history steps 16-17, summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:                       lr ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñà
wandb: spikes/train_avg_layer_3 ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñà
wandb:               train_loss ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 8
wandb:                       lr 0.00061
wandb: spikes/train_avg_layer_0 0.02516
wandb: spikes/train_avg_layer_1 0.00797
wandb: spikes/train_avg_layer_2 0.00123
wandb: spikes/train_avg_layer_3 0.00036
wandb:               train_loss 0.3527
wandb:      trainer/global_step 62
wandb:                 val_loss 0.34658
wandb: 
wandb: üöÄ View run silvery-sweep-124 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/l22p7exw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_231010-l22p7exw/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 185, in forward
    h_candidate = torch.tanh(preact)
                  ^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: pxgz6wmq with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.00013535441641764046
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.9
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_231107-pxgz6wmq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-sweep-125
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/pxgz6wmq
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 944    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
975       Trainable params
0         Non-trainable params
975       Total params
0.004     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ‚ñÖ‚ñà‚ñà
wandb:   grad_mean/lif_layers.1 ‚ñÅ‚ñÖ‚ñà‚ñÖ
wandb:   grad_mean/lif_layers.2 ‚ñÉ‚ñÖ‚ñà‚ñÅ
wandb:   grad_mean/lif_layers.3 ‚ñà‚ñÑ‚ñÑ‚ñÅ
wandb:   grad_mean/output_layer ‚ñà‚ñÑ‚ñÉ‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                       +4 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 39
wandb:   grad_mean/lif_layers.0 0.00849
wandb:   grad_mean/lif_layers.1 0.00439
wandb:   grad_mean/lif_layers.2 0.00222
wandb:   grad_mean/lif_layers.3 0.00227
wandb:   grad_mean/output_layer 0.10611
wandb:                       lr 0
wandb: spikes/train_avg_layer_0 0.02565
wandb: spikes/train_avg_layer_1 0.00605
wandb: spikes/train_avg_layer_2 0.0037
wandb:                       +4 ...
wandb: 
wandb: üöÄ View run youthful-sweep-125 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/pxgz6wmq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_231107-pxgz6wmq/logs
wandb: Agent Starting Run: 26quqdvn with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 2.945465929856528e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 3
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 1
wandb: setting up run 26quqdvn
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_231434-26quqdvn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-sweep-126
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/26quqdvn
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 50.6 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
50.7 K    Trainable params
0         Non-trainable params
50.7 K    Total params
0.203     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÖ‚ñÅ‚ñÖ‚ñÜ‚ñà
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               train_loss ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 4
wandb:                       lr 3e-05
wandb: spikes/train_avg_layer_0 0.02282
wandb: spikes/train_avg_layer_1 0.00211
wandb: spikes/train_avg_layer_2 0.00013
wandb: spikes/train_avg_layer_3 0
wandb:               train_loss 0.26045
wandb:      trainer/global_step 34
wandb:                 val_loss 0.25798
wandb: 
wandb: üöÄ View run sage-sweep-126 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/26quqdvn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_231434-26quqdvn/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 192, in forward
    sout_t = self._relu(h)
             ^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 565, in apply
    @classmethod
    
Exception

wandb: Agent Starting Run: 62y83y3v with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 2.9701908327758497e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 1
wandb: setting up run 62y83y3v
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_231907-62y83y3v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-127
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/62y83y3v
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 400    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
431       Trainable params
0         Non-trainable params
431       Total params
0.002     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ
wandb:   grad_mean/lif_layers.1 ‚ñÅ
wandb:   grad_mean/output_layer ‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà
wandb:               train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 17
wandb:   grad_mean/lif_layers.0 0.01238
wandb:   grad_mean/lif_layers.1 0.00807
wandb:   grad_mean/output_layer 0.32965
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.01884
wandb: spikes/train_avg_layer_1 0.00118
wandb:               train_loss 0.272
wandb:      trainer/global_step 125
wandb:                 val_loss 0.26952
wandb: 
wandb: üöÄ View run magic-sweep-127 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/62y83y3v
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_231907-62y83y3v/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 153, in run
    self.on_advance_end(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 398, in on_advance_end
    self.val_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 123, in run
    self.reset()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 259, in reset
    iter(data_fetcher)  # creates the iterator inside the fetcher
    ^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fetchers.py", line 105, in __iter__
    super().__iter__()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fetchers.py", line 52, in __iter__
    self.iterator = iter(self.combined_loader)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py", line 351, in __iter__
    iter(iterator)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py", line 155, in __iter__
    self._load_current_iterator()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py", line 173, in _load_current_iterator
    self.iterators = [iter(self.iterables[self._iterator_idx])]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 494, in __iter__
    return self._get_iterator()
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 427, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1170, in __init__
    w.start()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 120, in start
    _cleanup()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 64, in _cleanup
    if (child_popen := p._popen) and child_popen.poll() is not None:
                                     ^^^^^^^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/popen_fork.py", line 27, in poll
    pid, sts = os.waitpid(self.pid, flag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
Exception

Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1612, in _shutdown_workers
    if self._persistent_workers or self._workers_status[worker_id]:
                                   ^^^^^^^^^^^^^^^^^^^^
AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'
wandb: Agent Starting Run: agrdbguu with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.6904277177128091e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 1
wandb: setting up run agrdbguu
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_232009-agrdbguu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-128
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/agrdbguu
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 116 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
116 K     Trainable params
0         Non-trainable params
116 K     Total params
0.467     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñá‚ñÉ‚ñÅ
wandb: spikes/train_avg_layer_1 ‚ñà‚ñá‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_2 ‚ñà‚ñà‚ñá‚ñÅ
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 3
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.01724
wandb: spikes/train_avg_layer_1 0.00112
wandb: spikes/train_avg_layer_2 1e-05
wandb: spikes/train_avg_layer_3 0
wandb: spikes/train_avg_layer_4 0
wandb: spikes/train_avg_layer_5 0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run elated-sweep-128 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/agrdbguu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_232009-agrdbguu/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: va8v6rc4 with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.00023368395807276575
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.9
wandb: setting up run va8v6rc4
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_232910-va8v6rc4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-129
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/va8v6rc4
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 116 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
116 K     Trainable params
0         Non-trainable params
116 K     Total params
0.467     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception in thread QueueFeederThread:
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1012, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 291, in _feed
    queue_sem.release()
ValueError: semaphore or lock released too many times
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
<function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>Traceback (most recent call last):

  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^
^^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^
^AssertionError^: ^can only test a child process^
^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^    ^^self._shutdown_workers()^
^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    assert self._parent_pid == os.getpid(), 'can only test a child process'
             if w.is_alive(): 
 ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^
^  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
^^^^^^^^^^
AssertionError: can only test a child process
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÇ‚ñÑ‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÇ‚ñÖ‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÇ‚ñÑ‚ñà
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñà
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 3
wandb:                       lr 0.00023
wandb: spikes/train_avg_layer_0 0.02312
wandb: spikes/train_avg_layer_1 0.0029
wandb: spikes/train_avg_layer_2 0.00052
wandb: spikes/train_avg_layer_3 2e-05
wandb: spikes/train_avg_layer_4 0
wandb: spikes/train_avg_layer_5 0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run dandy-sweep-129 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/va8v6rc4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_232910-va8v6rc4/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: ztyzxiwn with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.0006872474506272794
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.9
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_233755-ztyzxiwn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-sweep-130
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/ztyzxiwn
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 29.6 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
29.7 K    Trainable params
0         Non-trainable params
29.7 K    Total params
0.119     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÇ‚ñÖ‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÇ‚ñÑ‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÅ‚ñÇ‚ñà
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñà
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñà
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 3
wandb:                       lr 0.00067
wandb: spikes/train_avg_layer_0 0.01464
wandb: spikes/train_avg_layer_1 0.00224
wandb: spikes/train_avg_layer_2 0.00083
wandb: spikes/train_avg_layer_3 0.00019
wandb: spikes/train_avg_layer_4 0.0
wandb: spikes/train_avg_layer_5 0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run vocal-sweep-130 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/ztyzxiwn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_233755-ztyzxiwn/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: h62ubfs6 with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.5208891388959411e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_234209-h62ubfs6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-sweep-131
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/h62ubfs6
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 13.0 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
13.1 K    Trainable params
0         Non-trainable params
13.1 K    Total params
0.052     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÇ‚ñÅ‚ñÖ‚ñÇ‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÑ‚ñÑ‚ñà‚ñÖ
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÉ‚ñÇ‚ñà‚ñÉ
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               train_loss ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 4
wandb:                       lr 1e-05
wandb: spikes/train_avg_layer_0 0.01683
wandb: spikes/train_avg_layer_1 0.00088
wandb: spikes/train_avg_layer_2 0.0
wandb: spikes/train_avg_layer_3 0
wandb:               train_loss 0.24282
wandb:      trainer/global_step 34
wandb:                 val_loss 0.24053
wandb: 
wandb: üöÄ View run fanciful-sweep-131 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/h62ubfs6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_234209-h62ubfs6/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 153, in run
    self.on_advance_end(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 398, in on_advance_end
    self.val_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 145, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 437, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 412, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 620, in validation_step
    layer_outputs.append(x_seq)
      ^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 189, in forward
    hs = zs * hs_prev + (1.0 - zs) * h_prev
                         ~~~~^~~~
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 38, in wrapped
    @functools.wraps(f)
    
Exception

wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 420zxea0 with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.2832722855036668e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 3
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.8
wandb: setting up run 420zxea0
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_234414-420zxea0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-132
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/420zxea0
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 248 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
248 K     Trainable params
0         Non-trainable params
248 K     Total params
0.995     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Exception in thread QueueFeederThread:
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1012, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 291, in _feed
    queue_sem.release()
ValueError: semaphore or lock released too many times
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                     epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                        lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb:  spikes/train_avg_layer_0 ‚ñÅ‚ñà‚ñÖ‚ñá
wandb:  spikes/train_avg_layer_1 ‚ñà‚ñá‚ñÅ‚ñÜ
wandb: spikes/train_avg_layer_10 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_11 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_12 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_13 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_14 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_15 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +11 ...
wandb: 
wandb: Run summary:
wandb:                     epoch 3
wandb:                        lr 1e-05
wandb:  spikes/train_avg_layer_0 0.01836
wandb:  spikes/train_avg_layer_1 0.0012
wandb: spikes/train_avg_layer_10 0
wandb: spikes/train_avg_layer_11 0
wandb: spikes/train_avg_layer_12 0
wandb: spikes/train_avg_layer_13 0
wandb: spikes/train_avg_layer_14 0
wandb: spikes/train_avg_layer_15 0
wandb:                       +11 ...
wandb: 
wandb: üöÄ View run stoic-sweep-132 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/420zxea0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_234414-420zxea0/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: az275n1i with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.00024336859437923137
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.8
wandb: setting up run az275n1i
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_000110-az275n1i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run distinctive-sweep-133
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/az275n1i
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 4.2 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
4.2 K     Trainable params
0         Non-trainable params
4.2 K     Total params
0.017     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading history steps 10-11, summary, console lines 42-43
wandb: 
wandb: Run history:
wandb:                     epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñà
wandb:                        lr ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÅ
wandb:  spikes/train_avg_layer_0 ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà
wandb:  spikes/train_avg_layer_1 ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñà
wandb: spikes/train_avg_layer_10 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_11 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_12 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_13 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_14 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_15 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +11 ...
wandb: 
wandb: Run summary:
wandb:                     epoch 5
wandb:                        lr 0.00023
wandb:  spikes/train_avg_layer_0 0.02509
wandb:  spikes/train_avg_layer_1 0.00171
wandb: spikes/train_avg_layer_10 0
wandb: spikes/train_avg_layer_11 0
wandb: spikes/train_avg_layer_12 0
wandb: spikes/train_avg_layer_13 0
wandb: spikes/train_avg_layer_14 0
wandb: spikes/train_avg_layer_15 0
wandb:                       +11 ...
wandb: 
wandb: üöÄ View run distinctive-sweep-133 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/az275n1i
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_000110-az275n1i/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 315, in apply
    return user_fn(self, *args)
           ^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 61, in backward
    grad_input = grad_output.clone()
                 ^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: q3sc5573 with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 6.913250874552493e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_000309-q3sc5573
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-134
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/q3sc5573
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 2.0 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
2.1 K     Trainable params
0         Non-trainable params
2.1 K     Total params
0.008     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_1 ‚ñà‚ñÖ‚ñÖ‚ñÉ‚ñÅ
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 4
wandb:                       lr 7e-05
wandb: spikes/train_avg_layer_0 0.01544
wandb: spikes/train_avg_layer_1 0.00029
wandb: spikes/train_avg_layer_2 0
wandb: spikes/train_avg_layer_3 0
wandb: spikes/train_avg_layer_4 0
wandb: spikes/train_avg_layer_5 0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run kind-sweep-134 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/q3sc5573
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_000309-q3sc5573/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 315, in apply
    return user_fn(self, *args)
           ^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 61, in backward
    grad_input = grad_output.clone()
                 ^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: tiru0pom with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.00026408734752764136
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 1
wandb: setting up run tiru0pom
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_000412-tiru0pom
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-135
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/tiru0pom
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 2.0 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
2.1 K     Trainable params
0         Non-trainable params
2.1 K     Total params
0.008     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                  epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: grad_mean/lif_layers.0 ‚ñÅ‚ñÉ‚ñà‚ñà
wandb: grad_mean/lif_layers.1 ‚ñÅ‚ñÉ‚ñà‚ñá
wandb: grad_mean/lif_layers.2 ‚ñá‚ñÅ‚ñà‚ñÖ
wandb: grad_mean/lif_layers.3 ‚ñà‚ñÇ‚ñÖ‚ñÅ
wandb: grad_mean/lif_layers.4 ‚ñà‚ñÇ‚ñÖ‚ñÅ
wandb: grad_mean/lif_layers.5 ‚ñà‚ñÇ‚ñÖ‚ñÅ
wandb: grad_mean/lif_layers.6 ‚ñà‚ñÇ‚ñÑ‚ñÅ
wandb: grad_mean/lif_layers.7 ‚ñà‚ñÇ‚ñÖ‚ñÅ
wandb: grad_mean/output_layer ‚ñà‚ñÉ‚ñÖ‚ñÅ
wandb:                    +12 ...
wandb: 
wandb: Run summary:
wandb:                  epoch 39
wandb: grad_mean/lif_layers.0 0.00993
wandb: grad_mean/lif_layers.1 0.00222
wandb: grad_mean/lif_layers.2 0.00117
wandb: grad_mean/lif_layers.3 0.00106
wandb: grad_mean/lif_layers.4 0.00101
wandb: grad_mean/lif_layers.5 0.00111
wandb: grad_mean/lif_layers.6 0.0012
wandb: grad_mean/lif_layers.7 0.00175
wandb: grad_mean/output_layer 0.09301
wandb:                    +12 ...
wandb: 
wandb: üöÄ View run frosty-sweep-135 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/tiru0pom
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_000412-tiru0pom/logs
wandb: Agent Starting Run: 0xev2lol with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.0003991250854873523
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 3
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.9
wandb: setting up run 0xev2lol
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_001013-0xev2lol
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-136
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/0xev2lol
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 52     | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
71        Trainable params
0         Non-trainable params
71        Total params
0.000     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñà‚ñÉ‚ñÅ‚ñÅ
wandb:   grad_mean/lif_layers.1 ‚ñà‚ñÖ‚ñÇ‚ñÅ
wandb:   grad_mean/output_layer ‚ñà‚ñÖ‚ñÇ‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: spikes/train_avg_layer_1 ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 37
wandb:   grad_mean/lif_layers.0 0.01495
wandb:   grad_mean/lif_layers.1 0.0098
wandb:   grad_mean/output_layer 0.19587
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.01434
wandb: spikes/train_avg_layer_1 0
wandb:               train_loss 0.20349
wandb:      trainer/global_step 265
wandb:                 val_loss 0.20162
wandb: 
wandb: üöÄ View run kind-sweep-136 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/0xev2lol
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_001013-0xev2lol/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 185, in forward
    h_candidate = torch.tanh(preact)
                  ^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: i42oxfr8 with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 2.4459830409088695e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 3
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.8
wandb: setting up run i42oxfr8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_001110-i42oxfr8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-137
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/i42oxfr8
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 172    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
191       Trainable params
0         Non-trainable params
191       Total params
0.001     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                  epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: grad_mean/lif_layers.0 ‚ñà‚ñÅ‚ñÉ
wandb: grad_mean/lif_layers.1 ‚ñà‚ñÅ‚ñÜ
wandb: grad_mean/lif_layers.2 ‚ñà‚ñÅ‚ñÖ
wandb: grad_mean/lif_layers.3 ‚ñà‚ñÅ‚ñÖ
wandb: grad_mean/lif_layers.4 ‚ñà‚ñÅ‚ñÖ
wandb: grad_mean/lif_layers.5 ‚ñà‚ñÅ‚ñÖ
wandb: grad_mean/lif_layers.6 ‚ñà‚ñÅ‚ñÖ
wandb: grad_mean/lif_layers.7 ‚ñà‚ñÅ‚ñÖ
wandb: grad_mean/output_layer ‚ñà‚ñÅ‚ñÑ
wandb:                    +12 ...
wandb: 
wandb: Run summary:
wandb:                  epoch 28
wandb: grad_mean/lif_layers.0 0.00803
wandb: grad_mean/lif_layers.1 0.00293
wandb: grad_mean/lif_layers.2 0.00483
wandb: grad_mean/lif_layers.3 0.00666
wandb: grad_mean/lif_layers.4 0.00824
wandb: grad_mean/lif_layers.5 0.00749
wandb: grad_mean/lif_layers.6 0.00506
wandb: grad_mean/lif_layers.7 0.00664
wandb: grad_mean/output_layer 0.17003
wandb:                    +12 ...
wandb: 
wandb: üöÄ View run rare-sweep-137 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/i42oxfr8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_001110-i42oxfr8/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: 46kjayil with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.00018864202222007725
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 3
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.9
wandb: setting up run 46kjayil
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_001308-46kjayil
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-138
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/46kjayil
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 92     | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
111       Trainable params
0         Non-trainable params
111       Total params
0.000     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ‚ñà
wandb:   grad_mean/lif_layers.1 ‚ñÅ‚ñà
wandb:   grad_mean/lif_layers.2 ‚ñÅ‚ñà
wandb:   grad_mean/lif_layers.3 ‚ñÅ‚ñà
wandb:   grad_mean/output_layer ‚ñà‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñÜ
wandb:                       +4 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 24
wandb:   grad_mean/lif_layers.0 0.07079
wandb:   grad_mean/lif_layers.1 0.03651
wandb:   grad_mean/lif_layers.2 0.04312
wandb:   grad_mean/lif_layers.3 0.02756
wandb:   grad_mean/output_layer 0.67697
wandb:                       lr 6e-05
wandb: spikes/train_avg_layer_0 0.01858
wandb: spikes/train_avg_layer_1 0.00228
wandb: spikes/train_avg_layer_2 0.00063
wandb:                       +4 ...
wandb: 
wandb: üöÄ View run fearless-sweep-138 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/46kjayil
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_001308-46kjayil/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 189, in forward
    hs = zs * hs_prev + (1.0 - zs) * h_prev
                         ~~~~^~~~
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 38, in wrapped
    @functools.wraps(f)
    
Exception

wandb: Agent Starting Run: bmwso7rf with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 3.8245941026979015e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.9
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_001411-bmwso7rf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-139
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/bmwso7rf
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 17.5 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
17.7 K    Trainable params
0         Non-trainable params
17.7 K    Total params
0.071     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading summary, console lines 43-43
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÇ‚ñÅ‚ñÑ‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÉ‚ñÅ‚ñÅ‚ñÜ‚ñà
wandb:               train_loss ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 4
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.01935
wandb: spikes/train_avg_layer_1 0.00136
wandb:               train_loss 0.20376
wandb:      trainer/global_step 34
wandb:                 val_loss 0.20192
wandb: 
wandb: üöÄ View run radiant-sweep-139 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/bmwso7rf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_001411-bmwso7rf/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: 73esevm1 with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 3.508151527727345e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 3
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.9
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_001609-73esevm1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-140
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/73esevm1
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 62.9 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
63.0 K    Trainable params
0         Non-trainable params
63.0 K    Total params
0.252     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                     epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                        lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb:  spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñà‚ñÜ
wandb:  spikes/train_avg_layer_1 ‚ñà‚ñÉ‚ñÜ‚ñÅ
wandb: spikes/train_avg_layer_10 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_11 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_12 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_13 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_14 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_15 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +11 ...
wandb: 
wandb: Run summary:
wandb:                     epoch 3
wandb:                        lr 0.0
wandb:  spikes/train_avg_layer_0 0.01727
wandb:  spikes/train_avg_layer_1 0.0012
wandb: spikes/train_avg_layer_10 0
wandb: spikes/train_avg_layer_11 0
wandb: spikes/train_avg_layer_12 0
wandb: spikes/train_avg_layer_13 0
wandb: spikes/train_avg_layer_14 0
wandb: spikes/train_avg_layer_15 0
wandb:                       +11 ...
wandb: 
wandb: üöÄ View run generous-sweep-140 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/73esevm1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_001609-73esevm1/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: pz89a4mn with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.00010609157812979284
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.9
wandb: setting up run pz89a4mn
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_002409-pz89a4mn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-141
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/pz89a4mn
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 944    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
975       Trainable params
0         Non-trainable params
975       Total params
0.004     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading history steps 41-45, summary, console lines 42-43
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ‚ñà
wandb:   grad_mean/lif_layers.1 ‚ñÅ‚ñà
wandb:   grad_mean/lif_layers.2 ‚ñÅ‚ñà
wandb:   grad_mean/lif_layers.3 ‚ñÅ‚ñà
wandb:   grad_mean/output_layer ‚ñÅ‚ñà
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà
wandb:                       +4 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 21
wandb:   grad_mean/lif_layers.0 0.01028
wandb:   grad_mean/lif_layers.1 0.00359
wandb:   grad_mean/lif_layers.2 0.00247
wandb:   grad_mean/lif_layers.3 0.00264
wandb:   grad_mean/output_layer 0.13324
wandb:                       lr 4e-05
wandb: spikes/train_avg_layer_0 0.02252
wandb: spikes/train_avg_layer_1 0.00322
wandb: spikes/train_avg_layer_2 0.00077
wandb:                       +4 ...
wandb: 
wandb: üöÄ View run eternal-sweep-141 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/pz89a4mn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_002409-pz89a4mn/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 163, in forward
    delta = torch.matmul(sin_t, self.Ws.t())  # (batch, hidden)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: 47h69oso with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 8.18617757834158e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.8
wandb: setting up run 47h69oso
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_002608-47h69oso
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-142
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/47h69oso
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 62.9 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
63.0 K    Trainable params
0         Non-trainable params
63.0 K    Total params
0.252     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading summary
wandb: 
wandb: Run history:
wandb:                     epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                        lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb:  spikes/train_avg_layer_0 ‚ñà‚ñÇ‚ñÅ‚ñà
wandb:  spikes/train_avg_layer_1 ‚ñÑ‚ñÑ‚ñÅ‚ñà
wandb: spikes/train_avg_layer_10 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_11 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_12 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_13 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_14 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_15 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +11 ...
wandb: 
wandb: Run summary:
wandb:                     epoch 3
wandb:                        lr 8e-05
wandb:  spikes/train_avg_layer_0 0.0245
wandb:  spikes/train_avg_layer_1 0.00124
wandb: spikes/train_avg_layer_10 0
wandb: spikes/train_avg_layer_11 0
wandb: spikes/train_avg_layer_12 0
wandb: spikes/train_avg_layer_13 0
wandb: spikes/train_avg_layer_14 0
wandb: spikes/train_avg_layer_15 0
wandb:                       +11 ...
wandb: 
wandb: üöÄ View run pretty-sweep-142 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/47h69oso
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_002608-47h69oso/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: ne318okw with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.0002863291507211986
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.9
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_003311-ne318okw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-143
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/ne318okw
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 248 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
248 K     Trainable params
0         Non-trainable params
248 K     Total params
0.995     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                     epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                        lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb:  spikes/train_avg_layer_0 ‚ñÅ‚ñÉ‚ñÖ‚ñà
wandb:  spikes/train_avg_layer_1 ‚ñÅ‚ñÇ‚ñÑ‚ñà
wandb: spikes/train_avg_layer_10 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_11 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_12 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_13 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_14 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_15 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +11 ...
wandb: 
wandb: Run summary:
wandb:                     epoch 3
wandb:                        lr 0.00028
wandb:  spikes/train_avg_layer_0 0.02012
wandb:  spikes/train_avg_layer_1 0.00247
wandb: spikes/train_avg_layer_10 0
wandb: spikes/train_avg_layer_11 0
wandb: spikes/train_avg_layer_12 0
wandb: spikes/train_avg_layer_13 0
wandb: spikes/train_avg_layer_14 0
wandb: spikes/train_avg_layer_15 0
wandb:                       +11 ...
wandb: 
wandb: üöÄ View run logical-sweep-143 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/ne318okw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_003311-ne318okw/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: yeham3il with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 2.7411437349454618e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 1
wandb: setting up run yeham3il
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_004909-yeham3il
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-144
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/yeham3il
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 944    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
975       Trainable params
0         Non-trainable params
975       Total params
0.004     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:                       lr ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñà‚ñÉ‚ñÇ‚ñÑ‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÑ
wandb: spikes/train_avg_layer_1 ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               train_loss ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 9
wandb:                       lr 2e-05
wandb: spikes/train_avg_layer_0 0.01258
wandb: spikes/train_avg_layer_1 6e-05
wandb: spikes/train_avg_layer_2 0
wandb: spikes/train_avg_layer_3 0
wandb:               train_loss 0.31613
wandb:      trainer/global_step 69
wandb:                 val_loss 0.31326
wandb: 
wandb: üöÄ View run exalted-sweep-144 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/yeham3il
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_004909-yeham3il/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 315, in apply
    return user_fn(self, *args)
           ^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 61, in backward
    grad_input = grad_output.clone()
                 ^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: h5lhz2j8 with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 4.218607014764466e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_005011-h5lhz2j8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-145
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/h5lhz2j8
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 332    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
351       Trainable params
0         Non-trainable params
351       Total params
0.001     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                   epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:  grad_mean/lif_layers.0 ‚ñÅ‚ñÖ‚ñà‚ñà
wandb:  grad_mean/lif_layers.1 ‚ñÅ‚ñÅ‚ñÖ‚ñà
wandb: grad_mean/lif_layers.10 ‚ñÉ‚ñÅ‚ñà‚ñÅ
wandb: grad_mean/lif_layers.11 ‚ñÉ‚ñÅ‚ñà‚ñÇ
wandb: grad_mean/lif_layers.12 ‚ñÑ‚ñÅ‚ñà‚ñÇ
wandb: grad_mean/lif_layers.13 ‚ñÑ‚ñÅ‚ñà‚ñÇ
wandb: grad_mean/lif_layers.14 ‚ñÉ‚ñÅ‚ñà‚ñÇ
wandb: grad_mean/lif_layers.15 ‚ñÅ‚ñà‚ñÅ‚ñÉ
wandb:  grad_mean/lif_layers.2 ‚ñÅ‚ñÅ‚ñà‚ñÉ
wandb:                     +28 ...
wandb: 
wandb: Run summary:
wandb:                   epoch 39
wandb:  grad_mean/lif_layers.0 0.0
wandb:  grad_mean/lif_layers.1 0.0
wandb: grad_mean/lif_layers.10 0.0
wandb: grad_mean/lif_layers.11 1e-05
wandb: grad_mean/lif_layers.12 3e-05
wandb: grad_mean/lif_layers.13 4e-05
wandb: grad_mean/lif_layers.14 3e-05
wandb: grad_mean/lif_layers.15 0.00012
wandb:  grad_mean/lif_layers.2 0.0
wandb:                     +28 ...
wandb: 
wandb: üöÄ View run fresh-sweep-145 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/h5lhz2j8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_005011-h5lhz2j8/logs
wandb: Agent Starting Run: tfig43wk with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 3.333608797641093e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 3
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_005505-tfig43wk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-sweep-146
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/tfig43wk
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 92     | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
111       Trainable params
0         Non-trainable params
111       Total params
0.000     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading history steps 41-51, summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñà‚ñÅ
wandb:   grad_mean/lif_layers.1 ‚ñÅ‚ñà
wandb:   grad_mean/lif_layers.2 ‚ñÅ‚ñà
wandb:   grad_mean/lif_layers.3 ‚ñÅ‚ñà
wandb:   grad_mean/output_layer ‚ñÅ‚ñà
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: spikes/train_avg_layer_1 ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ
wandb: spikes/train_avg_layer_2 ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÉ
wandb:                       +4 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 24
wandb:   grad_mean/lif_layers.0 0.00907
wandb:   grad_mean/lif_layers.1 0.01337
wandb:   grad_mean/lif_layers.2 0.01007
wandb:   grad_mean/lif_layers.3 0.01299
wandb:   grad_mean/output_layer 0.31661
wandb:                       lr 1e-05
wandb: spikes/train_avg_layer_0 0.01488
wandb: spikes/train_avg_layer_1 0.00012
wandb: spikes/train_avg_layer_2 2e-05
wandb:                       +4 ...
wandb: 
wandb: üöÄ View run restful-sweep-146 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/tfig43wk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_005505-tfig43wk/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 185, in forward
    h_candidate = torch.tanh(preact)
                  ^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: tdrgmyxf with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.5083509485248038e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 3
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_005607-tdrgmyxf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-147
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/tdrgmyxf
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 2.0 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
2.1 K     Trainable params
0         Non-trainable params
2.1 K     Total params
0.008     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading history steps 10-11, summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñà‚ñÜ
wandb: spikes/train_avg_layer_2 ‚ñà‚ñá‚ñá‚ñÜ‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 5
wandb:                       lr 1e-05
wandb: spikes/train_avg_layer_0 0.0183
wandb: spikes/train_avg_layer_1 0.00119
wandb: spikes/train_avg_layer_2 9e-05
wandb: spikes/train_avg_layer_3 0
wandb: spikes/train_avg_layer_4 0
wandb: spikes/train_avg_layer_5 0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run gentle-sweep-147 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/tdrgmyxf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_005607-tdrgmyxf/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 189, in forward
    hs = zs * hs_prev + (1.0 - zs) * h_prev
                         ~~~~^~~~
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 38, in wrapped
    @functools.wraps(f)
    
Exception

wandb: Agent Starting Run: bbqmlhxe with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 3.0692338307337816e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 1
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 1
wandb: setting up run bbqmlhxe
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_005709-bbqmlhxe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-148
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/bbqmlhxe
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 400    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
431       Trainable params
0         Non-trainable params
431       Total params
0.002     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ‚ñà
wandb:   grad_mean/lif_layers.1 ‚ñà‚ñÅ
wandb:   grad_mean/output_layer ‚ñà‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_1 ‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÜ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ
wandb:               train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 21
wandb:   grad_mean/lif_layers.0 0.00721
wandb:   grad_mean/lif_layers.1 0.00628
wandb:   grad_mean/output_layer 0.26609
wandb:                       lr 1e-05
wandb: spikes/train_avg_layer_0 0.02205
wandb: spikes/train_avg_layer_1 0.00172
wandb:               train_loss 0.23361
wandb:      trainer/global_step 153
wandb:                 val_loss 0.23139
wandb: 
wandb: üöÄ View run neat-sweep-148 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/bbqmlhxe
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_005709-bbqmlhxe/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 153, in run
    self.on_advance_end(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 398, in on_advance_end
    self.val_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 145, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 437, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 412, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 620, in validation_step
    layer_outputs.append(x_seq)
      ^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 167, in forward
    x = self.rho * torch.tanh(i / self.rho)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: no1uji1n with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.00036520774145915133
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.8
wandb: setting up run no1uji1n
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_005811-no1uji1n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-149
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/no1uji1n
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 17.5 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
17.7 K    Trainable params
0         Non-trainable params
17.7 K    Total params
0.071     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñà
wandb:               train_loss ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 4
wandb:                       lr 0.00035
wandb: spikes/train_avg_layer_0 0.01933
wandb: spikes/train_avg_layer_1 0.00469
wandb:               train_loss 0.20583
wandb:      trainer/global_step 34
wandb:                 val_loss 0.20161
wandb: 
wandb: üöÄ View run dry-sweep-149 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/no1uji1n
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_005811-no1uji1n/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 185, in forward
    h_candidate = torch.tanh(preact)
                  ^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: xptsuxq5 with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.0014902988626554e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_010010-xptsuxq5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-150
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/xptsuxq5
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 52     | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
71        Trainable params
0         Non-trainable params
71        Total params
0.000     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception in thread QueueFeederThread:
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1012, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 291, in _feed
    queue_sem.release()
ValueError: semaphore or lock released too many times
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ‚ñÅ‚ñà
wandb:   grad_mean/lif_layers.1 ‚ñà‚ñÅ‚ñÅ
wandb:   grad_mean/output_layer ‚ñà‚ñÇ‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: spikes/train_avg_layer_1 ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 31
wandb:   grad_mean/lif_layers.0 0.05365
wandb:   grad_mean/lif_layers.1 0.0168
wandb:   grad_mean/output_layer 0.65273
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.01059
wandb: spikes/train_avg_layer_1 0.00102
wandb:               train_loss 0.59371
wandb:      trainer/global_step 223
wandb:                 val_loss 0.5896
wandb: 
wandb: üöÄ View run devoted-sweep-150 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/xptsuxq5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_010010-xptsuxq5/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 171, in forward
    h_prev = h.detach()
             ^^^^^^^^^^
Exception

wandb: Agent Starting Run: 9cm5fzn3 with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.2944980471711538e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 1
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.9
wandb: setting up run 9cm5fzn3
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_010107-9cm5fzn3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-151
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/9cm5fzn3
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 4.2 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
4.2 K     Trainable params
0         Non-trainable params
4.2 K     Total params
0.017     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                   epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:  grad_mean/lif_layers.0 ‚ñÖ‚ñÇ‚ñà‚ñÅ
wandb:  grad_mean/lif_layers.1 ‚ñà‚ñÜ‚ñà‚ñÅ
wandb: grad_mean/lif_layers.10 ‚ñà‚ñÜ‚ñá‚ñÅ
wandb: grad_mean/lif_layers.11 ‚ñà‚ñÜ‚ñá‚ñÅ
wandb: grad_mean/lif_layers.12 ‚ñà‚ñÜ‚ñá‚ñÅ
wandb: grad_mean/lif_layers.13 ‚ñà‚ñÖ‚ñá‚ñÅ
wandb: grad_mean/lif_layers.14 ‚ñà‚ñÜ‚ñá‚ñÅ
wandb: grad_mean/lif_layers.15 ‚ñà‚ñÜ‚ñá‚ñÅ
wandb:  grad_mean/lif_layers.2 ‚ñà‚ñÜ‚ñá‚ñÅ
wandb:                     +28 ...
wandb: 
wandb: Run summary:
wandb:                   epoch 39
wandb:  grad_mean/lif_layers.0 2e-05
wandb:  grad_mean/lif_layers.1 2e-05
wandb: grad_mean/lif_layers.10 0.00017
wandb: grad_mean/lif_layers.11 0.0002
wandb: grad_mean/lif_layers.12 0.00024
wandb: grad_mean/lif_layers.13 0.0003
wandb: grad_mean/lif_layers.14 0.00028
wandb: grad_mean/lif_layers.15 0.00065
wandb:  grad_mean/lif_layers.2 2e-05
wandb:                     +28 ...
wandb: 
wandb: üöÄ View run skilled-sweep-151 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/9cm5fzn3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_010107-9cm5fzn3/logs
wandb: Agent Starting Run: dxwwjgbl with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.00200567821516e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 3
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.9
wandb: setting up run dxwwjgbl
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_011242-dxwwjgbl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-152
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/dxwwjgbl
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 92     | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
111       Trainable params
0         Non-trainable params
111       Total params
0.000     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1618, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/popen_fork.py", line 40, in wait
    if not wait([self.sentinel], timeout):
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 1136, in wait
    ready = selector.select(timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Exception: 
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: uploading console lines 42-62
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ‚ñÇ‚ñà‚ñÉ
wandb:   grad_mean/lif_layers.1 ‚ñÜ‚ñÅ‚ñÜ‚ñà
wandb:   grad_mean/lif_layers.2 ‚ñá‚ñÅ‚ñÜ‚ñà
wandb:   grad_mean/lif_layers.3 ‚ñÜ‚ñÅ‚ñÜ‚ñà
wandb:   grad_mean/output_layer ‚ñÜ‚ñÅ‚ñÜ‚ñà
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá
wandb: spikes/train_avg_layer_2 ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +4 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 39
wandb:   grad_mean/lif_layers.0 0.01365
wandb:   grad_mean/lif_layers.1 0.00386
wandb:   grad_mean/lif_layers.2 0.00322
wandb:   grad_mean/lif_layers.3 0.00623
wandb:   grad_mean/output_layer 0.18903
wandb:                       lr 0
wandb: spikes/train_avg_layer_0 0.01616
wandb: spikes/train_avg_layer_1 0.00121
wandb: spikes/train_avg_layer_2 0
wandb:                       +4 ...
wandb: 
wandb: üöÄ View run silvery-sweep-152 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/dxwwjgbl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_011242-dxwwjgbl/logs
wandb: Agent Starting Run: ohm3555j with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.00012587844352985995
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 1
wandb: setting up run ohm3555j
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_011414-ohm3555j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-153
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/ohm3555j
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 17.5 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
17.7 K    Trainable params
0         Non-trainable params
17.7 K    Total params
0.071     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñà
wandb:               train_loss ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 4
wandb:                       lr 0.00012
wandb: spikes/train_avg_layer_0 0.01805
wandb: spikes/train_avg_layer_1 0.00079
wandb:               train_loss 0.24261
wandb:      trainer/global_step 34
wandb:                 val_loss 0.23941
wandb: 
wandb: üöÄ View run swept-sweep-153 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/ohm3555j
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_011414-ohm3555j/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 185, in forward
    h_candidate = torch.tanh(preact)
                  ^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: esyhkg7l with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 2.619140817541973e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 3
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_011609-esyhkg7l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-154
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/esyhkg7l
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 944    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
975       Trainable params
0         Non-trainable params
975       Total params
0.004     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: uploading history steps 82-83, summary, console lines 42-44
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ‚ñÉ‚ñÜ‚ñà
wandb:   grad_mean/lif_layers.1 ‚ñÉ‚ñÅ‚ñÇ‚ñà
wandb:   grad_mean/lif_layers.2 ‚ñÇ‚ñÅ‚ñÇ‚ñà
wandb:   grad_mean/lif_layers.3 ‚ñÅ‚ñÅ‚ñÇ‚ñà
wandb:   grad_mean/output_layer ‚ñÅ‚ñÇ‚ñÇ‚ñà
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_1 ‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                       +4 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 39
wandb:   grad_mean/lif_layers.0 0.00396
wandb:   grad_mean/lif_layers.1 0.00186
wandb:   grad_mean/lif_layers.2 0.00134
wandb:   grad_mean/lif_layers.3 0.00164
wandb:   grad_mean/output_layer 0.07486
wandb:                       lr 0
wandb: spikes/train_avg_layer_0 0.0243
wandb: spikes/train_avg_layer_1 0.00403
wandb: spikes/train_avg_layer_2 0.0008
wandb:                       +4 ...
wandb: 
wandb: üöÄ View run vibrant-sweep-154 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/esyhkg7l
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_011609-esyhkg7l/logs
wandb: Agent Starting Run: p2ojiiq6 with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.1623271479797577e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 3
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_011920-p2ojiiq6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-155
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/p2ojiiq6
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 50.6 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
50.7 K    Trainable params
0         Non-trainable params
50.7 K    Total params
0.203     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñÅ‚ñÖ‚ñÉ
wandb: spikes/train_avg_layer_1 ‚ñà‚ñà‚ñÅ‚ñÑ
wandb: spikes/train_avg_layer_2 ‚ñà‚ñá‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               train_loss ‚ñà‚ñÜ‚ñÉ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñÜ‚ñÉ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 3
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.02289
wandb: spikes/train_avg_layer_1 0.00189
wandb: spikes/train_avg_layer_2 2e-05
wandb: spikes/train_avg_layer_3 0
wandb:               train_loss 0.27043
wandb:      trainer/global_step 27
wandb:                 val_loss 0.26795
wandb: 
wandb: üöÄ View run vibrant-sweep-155 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/p2ojiiq6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_011920-p2ojiiq6/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 189, in forward
    hs = zs * hs_prev + (1.0 - zs) * h_prev
                         ~~~~^~~~
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 45, in wrapped
    return f(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 1075, in __rsub__
    return _C._VariableFunctions.rsub(self, other)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: e35w3lhd with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.1962954912729917e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.9
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_012306-e35w3lhd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-156
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/e35w3lhd
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 944    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
975       Trainable params
0         Non-trainable params
975       Total params
0.004     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1618, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/popen_fork.py", line 40, in wait
    if not wait([self.sentinel], timeout):
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 1136, in wait
    ready = selector.select(timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Exception: 
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: uploading history steps 82-83, summary, console lines 42-43
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñà‚ñÜ‚ñÜ‚ñÅ
wandb:   grad_mean/lif_layers.1 ‚ñÉ‚ñÖ‚ñÅ‚ñà
wandb:   grad_mean/lif_layers.2 ‚ñá‚ñà‚ñÅ‚ñÜ
wandb:   grad_mean/lif_layers.3 ‚ñà‚ñà‚ñÅ‚ñÜ
wandb:   grad_mean/output_layer ‚ñà‚ñà‚ñÅ‚ñá
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_1 ‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                       +4 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 39
wandb:   grad_mean/lif_layers.0 0.01912
wandb:   grad_mean/lif_layers.1 0.00502
wandb:   grad_mean/lif_layers.2 0.00554
wandb:   grad_mean/lif_layers.3 0.00709
wandb:   grad_mean/output_layer 0.49403
wandb:                       lr 0
wandb: spikes/train_avg_layer_0 0.02102
wandb: spikes/train_avg_layer_1 0.0016
wandb: spikes/train_avg_layer_2 0.0
wandb:                       +4 ...
wandb: 
wandb: üöÄ View run quiet-sweep-156 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/e35w3lhd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_012306-e35w3lhd/logs
wandb: Agent Starting Run: ckpfxf10 with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.00021268385023583017
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.9
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_012613-ckpfxf10
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-157
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/ckpfxf10
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 92     | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
111       Trainable params
0         Non-trainable params
111       Total params
0.000     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: uploading history steps 73-83, summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ‚ñà‚ñÉ‚ñÖ
wandb:   grad_mean/lif_layers.1 ‚ñà‚ñá‚ñÅ‚ñÅ
wandb:   grad_mean/lif_layers.2 ‚ñà‚ñá‚ñÅ‚ñÅ
wandb:   grad_mean/lif_layers.3 ‚ñà‚ñá‚ñÅ‚ñÅ
wandb:   grad_mean/output_layer ‚ñà‚ñá‚ñÅ‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +4 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 39
wandb:   grad_mean/lif_layers.0 0.00488
wandb:   grad_mean/lif_layers.1 0.00214
wandb:   grad_mean/lif_layers.2 0.00187
wandb:   grad_mean/lif_layers.3 0.00115
wandb:   grad_mean/output_layer 0.02525
wandb:                       lr 0
wandb: spikes/train_avg_layer_0 0.00488
wandb: spikes/train_avg_layer_1 6e-05
wandb: spikes/train_avg_layer_2 0
wandb:                       +4 ...
wandb: 
wandb: üöÄ View run swept-sweep-157 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/ckpfxf10
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_012613-ckpfxf10/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 2vpaodzq with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 3.1157601692387334e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.9
wandb: setting up run 2vpaodzq
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_012750-2vpaodzq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-158
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/2vpaodzq
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 17.5 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
17.7 K    Trainable params
0         Non-trainable params
17.7 K    Total params
0.071     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñà
wandb: spikes/train_avg_layer_1 ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÇ‚ñÜ
wandb:               train_loss ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÇ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 5
wandb:                       lr 3e-05
wandb: spikes/train_avg_layer_0 0.01955
wandb: spikes/train_avg_layer_1 0.00136
wandb:               train_loss 0.20001
wandb:      trainer/global_step 41
wandb:                 val_loss 0.19788
wandb: 
wandb: üöÄ View run fragrant-sweep-158 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/2vpaodzq
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_012750-2vpaodzq/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: 2tiqdijv with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.433063905285311e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_013010-2tiqdijv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-159
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/2tiqdijv
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 332    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
351       Trainable params
0         Non-trainable params
351       Total params
0.001     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: uploading history steps 82-83, summary, console lines 42-44
wandb: 
wandb: Run history:
wandb:                   epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:  grad_mean/lif_layers.0 ‚ñà‚ñà‚ñá‚ñÅ
wandb:  grad_mean/lif_layers.1 ‚ñÜ‚ñà‚ñá‚ñÅ
wandb: grad_mean/lif_layers.10 ‚ñá‚ñÜ‚ñà‚ñÅ
wandb: grad_mean/lif_layers.11 ‚ñá‚ñÜ‚ñà‚ñÅ
wandb: grad_mean/lif_layers.12 ‚ñá‚ñÖ‚ñà‚ñÅ
wandb: grad_mean/lif_layers.13 ‚ñá‚ñÖ‚ñà‚ñÅ
wandb: grad_mean/lif_layers.14 ‚ñá‚ñÉ‚ñà‚ñÅ
wandb: grad_mean/lif_layers.15 ‚ñà‚ñÇ‚ñà‚ñÅ
wandb:  grad_mean/lif_layers.2 ‚ñÜ‚ñà‚ñá‚ñÅ
wandb:                     +28 ...
wandb: 
wandb: Run summary:
wandb:                   epoch 39
wandb:  grad_mean/lif_layers.0 2e-05
wandb:  grad_mean/lif_layers.1 1e-05
wandb: grad_mean/lif_layers.10 0.00124
wandb: grad_mean/lif_layers.11 0.00128
wandb: grad_mean/lif_layers.12 0.00096
wandb: grad_mean/lif_layers.13 0.0018
wandb: grad_mean/lif_layers.14 0.00175
wandb: grad_mean/lif_layers.15 0.00239
wandb:  grad_mean/lif_layers.2 1e-05
wandb:                     +28 ...
wandb: 
wandb: üöÄ View run volcanic-sweep-159 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/2tiqdijv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_013010-2tiqdijv/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: udbq5yht with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 4.776718296828e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 3
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.9
wandb: setting up run udbq5yht
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_013513-udbq5yht
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-160
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/udbq5yht
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 172    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
191       Trainable params
0         Non-trainable params
191       Total params
0.001     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                  epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: grad_mean/lif_layers.0 ‚ñÉ‚ñÅ‚ñà
wandb: grad_mean/lif_layers.1 ‚ñÅ‚ñÇ‚ñà
wandb: grad_mean/lif_layers.2 ‚ñÅ‚ñÉ‚ñà
wandb: grad_mean/lif_layers.3 ‚ñÅ‚ñÉ‚ñà
wandb: grad_mean/lif_layers.4 ‚ñÅ‚ñÉ‚ñà
wandb: grad_mean/lif_layers.5 ‚ñÅ‚ñÉ‚ñà
wandb: grad_mean/lif_layers.6 ‚ñÅ‚ñÉ‚ñà
wandb: grad_mean/lif_layers.7 ‚ñÅ‚ñÇ‚ñà
wandb: grad_mean/output_layer ‚ñÅ‚ñÉ‚ñà
wandb:                    +12 ...
wandb: 
wandb: Run summary:
wandb:                  epoch 28
wandb: grad_mean/lif_layers.0 0.00319
wandb: grad_mean/lif_layers.1 0.00171
wandb: grad_mean/lif_layers.2 0.00132
wandb: grad_mean/lif_layers.3 0.00423
wandb: grad_mean/lif_layers.4 0.00429
wandb: grad_mean/lif_layers.5 0.0089
wandb: grad_mean/lif_layers.6 0.00614
wandb: grad_mean/lif_layers.7 0.00403
wandb: grad_mean/output_layer 0.12677
wandb:                    +12 ...
wandb: 
wandb: üöÄ View run deft-sweep-160 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/udbq5yht
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_013513-udbq5yht/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 315, in apply
    return user_fn(self, *args)
           ^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 61, in backward
    grad_input = grad_output.clone()
                 ^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: w2vqo2cs with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.4075483932823091e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.8
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_013713-w2vqo2cs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-161
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/w2vqo2cs
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 400    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
431       Trainable params
0         Non-trainable params
431       Total params
0.002     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÑ‚ñà‚ñÅ‚ñà
wandb:   grad_mean/lif_layers.1 ‚ñá‚ñà‚ñÉ‚ñÅ
wandb:   grad_mean/output_layer ‚ñà‚ñà‚ñÑ‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_1 ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 39
wandb:   grad_mean/lif_layers.0 0.00842
wandb:   grad_mean/lif_layers.1 0.00135
wandb:   grad_mean/output_layer 0.04813
wandb:                       lr 0
wandb: spikes/train_avg_layer_0 0.00825
wandb: spikes/train_avg_layer_1 0.00033
wandb:               train_loss 0.16548
wandb:      trainer/global_step 279
wandb:                 val_loss 0.16435
wandb: 
wandb: üöÄ View run efficient-sweep-161 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/w2vqo2cs
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_013713-w2vqo2cs/logs
wandb: Agent Starting Run: lif9q501 with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 4.993685941039736e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.9
wandb: setting up run lif9q501
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_013857-lif9q501
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-162
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/lif9q501
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 332    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
351       Trainable params
0         Non-trainable params
351       Total params
0.001     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                     epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:                        lr ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÅ
wandb:  spikes/train_avg_layer_0 ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ
wandb:  spikes/train_avg_layer_1 ‚ñà‚ñà‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÅ
wandb: spikes/train_avg_layer_10 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_11 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_12 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_13 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_14 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_15 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +11 ...
wandb: 
wandb: Run summary:
wandb:                     epoch 8
wandb:                        lr 4e-05
wandb:  spikes/train_avg_layer_0 0.03714
wandb:  spikes/train_avg_layer_1 0.01068
wandb: spikes/train_avg_layer_10 0
wandb: spikes/train_avg_layer_11 0
wandb: spikes/train_avg_layer_12 0
wandb: spikes/train_avg_layer_13 0
wandb: spikes/train_avg_layer_14 0
wandb: spikes/train_avg_layer_15 0
wandb:                       +11 ...
wandb: 
wandb: üöÄ View run dry-sweep-162 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/lif9q501
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_013857-lif9q501/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 189, in forward
    hs = zs * hs_prev + (1.0 - zs) * h_prev
                         ~~~~^~~~
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 38, in wrapped
    @functools.wraps(f)
    
Exception

wandb: Agent Starting Run: okr57j7c with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 8.30030458909958e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 3
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_014009-okr57j7c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-163
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/okr57j7c
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 17.5 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
17.7 K    Trainable params
0         Non-trainable params
17.7 K    Total params
0.071     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÉ‚ñÅ‚ñÉ‚ñÜ‚ñà
wandb: spikes/train_avg_layer_1 ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÅ
wandb:               train_loss ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 4
wandb:                       lr 1e-05
wandb: spikes/train_avg_layer_0 0.01723
wandb: spikes/train_avg_layer_1 0.00096
wandb:               train_loss 0.22796
wandb:      trainer/global_step 34
wandb:                 val_loss 0.22579
wandb: 
wandb: üöÄ View run unique-sweep-163 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/okr57j7c
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_014009-okr57j7c/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 185, in forward
    h_candidate = torch.tanh(preact)
                  ^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: 0v27jz7y with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 9.647877510092666e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.9
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_014208-0v27jz7y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-164
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/0v27jz7y
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 52     | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
71        Trainable params
0         Non-trainable params
71        Total params
0.000     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading history steps 54-68, summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ‚ñÜ‚ñà
wandb:   grad_mean/lif_layers.1 ‚ñà‚ñà‚ñÅ
wandb:   grad_mean/output_layer ‚ñÇ‚ñà‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_1 ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:               train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 32
wandb:   grad_mean/lif_layers.0 0.09992
wandb:   grad_mean/lif_layers.1 0.05664
wandb:   grad_mean/output_layer 0.69298
wandb:                       lr 1e-05
wandb: spikes/train_avg_layer_0 0.02226
wandb: spikes/train_avg_layer_1 0.00592
wandb:               train_loss 0.63896
wandb:      trainer/global_step 230
wandb:                 val_loss 0.63454
wandb: 
wandb: üöÄ View run deep-sweep-164 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/0v27jz7y
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_014208-0v27jz7y/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 153, in run
    self.on_advance_end(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 398, in on_advance_end
    self.val_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 145, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 437, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 412, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 620, in validation_step
    layer_outputs.append(x_seq)
      ^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 167, in forward
    x = self.rho * torch.tanh(i / self.rho)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: c8qdyd65 with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 4.910282939334654e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 3
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_014310-c8qdyd65
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serene-sweep-165
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/c8qdyd65
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 116 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
116 K     Trainable params
0         Non-trainable params
116 K     Total params
0.467     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^
^^ ^ ^ ^ ^ ^ ^ ^ ^ 
 AssertionError : ^can only test a child process^
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception in thread QueueFeederThread:
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1012, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 291, in _feed
    queue_sem.release()
ValueError: semaphore or lock released too many times
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñá‚ñà‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÖ‚ñÅ‚ñÅ‚ñà
wandb: spikes/train_avg_layer_2 ‚ñà‚ñÖ‚ñÉ‚ñÅ
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 3
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.02171
wandb: spikes/train_avg_layer_1 0.00101
wandb: spikes/train_avg_layer_2 3e-05
wandb: spikes/train_avg_layer_3 0
wandb: spikes/train_avg_layer_4 0
wandb: spikes/train_avg_layer_5 0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run serene-sweep-165 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/c8qdyd65
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_014310-c8qdyd65/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: s8meah8z with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.0007159857420267245
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 1
wandb: setting up run s8meah8z
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_015150-s8meah8z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serene-sweep-166
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/s8meah8z
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 248 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
248 K     Trainable params
0         Non-trainable params
248 K     Total params
0.995     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                     epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                        lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb:  spikes/train_avg_layer_0 ‚ñÅ‚ñÇ‚ñÖ‚ñà
wandb:  spikes/train_avg_layer_1 ‚ñÅ‚ñÇ‚ñÖ‚ñà
wandb: spikes/train_avg_layer_10 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_11 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_12 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_13 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_14 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_15 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +11 ...
wandb: 
wandb: Run summary:
wandb:                     epoch 3
wandb:                        lr 0.0007
wandb:  spikes/train_avg_layer_0 0.02176
wandb:  spikes/train_avg_layer_1 0.01028
wandb: spikes/train_avg_layer_10 0
wandb: spikes/train_avg_layer_11 0
wandb: spikes/train_avg_layer_12 0
wandb: spikes/train_avg_layer_13 0
wandb: spikes/train_avg_layer_14 0
wandb: spikes/train_avg_layer_15 0
wandb:                       +11 ...
wandb: 
wandb: üöÄ View run serene-sweep-166 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/s8meah8z
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_015150-s8meah8z/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: 98j8ok38 with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 9.052005549071355e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 1
wandb: setting up run 98j8ok38
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_020907-98j8ok38
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-167
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/98j8ok38
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 13.0 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
13.1 K    Trainable params
0         Non-trainable params
13.1 K    Total params
0.052     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                       lr ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÑ‚ñÜ‚ñÖ
wandb: spikes/train_avg_layer_1 ‚ñÉ‚ñá‚ñÜ‚ñà‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_2 ‚ñÖ‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÇ
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               train_loss ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 12
wandb:                       lr 1e-05
wandb: spikes/train_avg_layer_0 0.01803
wandb: spikes/train_avg_layer_1 0.00148
wandb: spikes/train_avg_layer_2 2e-05
wandb: spikes/train_avg_layer_3 0
wandb:               train_loss 0.19745
wandb:      trainer/global_step 90
wandb:                 val_loss 0.19565
wandb: 
wandb: üöÄ View run wandering-sweep-167 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/98j8ok38
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_020907-98j8ok38/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: qb52b841 with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 5.003233163883444e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.9
wandb: setting up run qb52b841
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_021507-qb52b841
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-168
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/qb52b841
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 50.6 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
50.7 K    Trainable params
0         Non-trainable params
50.7 K    Total params
0.203     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading config.yaml
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñÇ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_1 ‚ñÖ‚ñÅ‚ñÇ‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÉ‚ñÖ‚ñà
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               train_loss ‚ñà‚ñÜ‚ñÉ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñÜ‚ñÉ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 3
wandb:                       lr 5e-05
wandb: spikes/train_avg_layer_0 0.01943
wandb: spikes/train_avg_layer_1 0.00134
wandb: spikes/train_avg_layer_2 6e-05
wandb: spikes/train_avg_layer_3 0
wandb:               train_loss 0.24195
wandb:      trainer/global_step 27
wandb:                 val_loss 0.23958
wandb: 
wandb: üöÄ View run kind-sweep-168 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/qb52b841
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_021507-qb52b841/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: yxk9b90c with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 2.9038117914553727e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 3
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_021910-yxk9b90c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-169
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/yxk9b90c
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 2.0 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
2.1 K     Trainable params
0         Non-trainable params
2.1 K     Total params
0.008     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                  epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: grad_mean/lif_layers.0 ‚ñÇ‚ñÖ‚ñà‚ñÅ
wandb: grad_mean/lif_layers.1 ‚ñÉ‚ñà‚ñÜ‚ñÅ
wandb: grad_mean/lif_layers.2 ‚ñÖ‚ñà‚ñÜ‚ñÅ
wandb: grad_mean/lif_layers.3 ‚ñÜ‚ñà‚ñá‚ñÅ
wandb: grad_mean/lif_layers.4 ‚ñÜ‚ñà‚ñá‚ñÅ
wandb: grad_mean/lif_layers.5 ‚ñá‚ñà‚ñà‚ñÅ
wandb: grad_mean/lif_layers.6 ‚ñá‚ñà‚ñà‚ñÅ
wandb: grad_mean/lif_layers.7 ‚ñá‚ñà‚ñà‚ñÅ
wandb: grad_mean/output_layer ‚ñá‚ñá‚ñà‚ñÅ
wandb:                    +12 ...
wandb: 
wandb: Run summary:
wandb:                  epoch 39
wandb: grad_mean/lif_layers.0 0.0015
wandb: grad_mean/lif_layers.1 0.00067
wandb: grad_mean/lif_layers.2 0.00056
wandb: grad_mean/lif_layers.3 0.00057
wandb: grad_mean/lif_layers.4 0.00073
wandb: grad_mean/lif_layers.5 0.00096
wandb: grad_mean/lif_layers.6 0.00097
wandb: grad_mean/lif_layers.7 0.0011
wandb: grad_mean/output_layer 0.0746
wandb:                    +12 ...
wandb: 
wandb: üöÄ View run zany-sweep-169 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/yxk9b90c
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_021910-yxk9b90c/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: vwkmzvty with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.479652200303708e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_022532-vwkmzvty
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-170
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/vwkmzvty
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 4.7 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
4.8 K     Trainable params
0         Non-trainable params
4.8 K     Total params
0.019     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading history steps 33-34, summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ
wandb:   grad_mean/lif_layers.1 ‚ñÅ
wandb:   grad_mean/output_layer ‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb: spikes/train_avg_layer_1 ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà
wandb:               train_loss ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 16
wandb:   grad_mean/lif_layers.0 0.00369
wandb:   grad_mean/lif_layers.1 0.00208
wandb:   grad_mean/output_layer 0.15888
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.01999
wandb: spikes/train_avg_layer_1 0.00114
wandb:               train_loss 0.18668
wandb:      trainer/global_step 118
wandb:                 val_loss 0.18504
wandb: 
wandb: üöÄ View run polished-sweep-170 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/vwkmzvty
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_022532-vwkmzvty/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 153, in run
    self.on_advance_end(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 398, in on_advance_end
    self.val_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 123, in run
    self.reset()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 259, in reset
    iter(data_fetcher)  # creates the iterator inside the fetcher
    ^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fetchers.py", line 105, in __iter__
    super().__iter__()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fetchers.py", line 52, in __iter__
    self.iterator = iter(self.combined_loader)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py", line 351, in __iter__
    iter(iterator)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py", line 155, in __iter__
    self._load_current_iterator()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py", line 173, in _load_current_iterator
    self.iterators = [iter(self.iterables[self._iterator_idx])]
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 494, in __iter__
    return self._get_iterator()
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 427, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1170, in __init__
    w.start()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 120, in start
    _cleanup()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 64, in _cleanup
    if (child_popen := p._popen) and child_popen.poll() is not None:
                                     ^^^^^^^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/popen_fork.py", line 27, in poll
    pid, sts = os.waitpid(self.pid, flag)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
Exception

Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1612, in _shutdown_workers
    if self._persistent_workers or self._workers_status[worker_id]:
                                   ^^^^^^^^^^^^^^^^^^^^
AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'
wandb: Agent Starting Run: vcvjc004 with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.9760467109046156e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_022807-vcvjc004
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-sweep-171
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/vcvjc004
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 400    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
431       Trainable params
0         Non-trainable params
431       Total params
0.002     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading history steps 33-40, summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ
wandb:   grad_mean/lif_layers.1 ‚ñÅ
wandb:   grad_mean/output_layer ‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ
wandb: spikes/train_avg_layer_1 ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 19
wandb:   grad_mean/lif_layers.0 0.01201
wandb:   grad_mean/lif_layers.1 0.00756
wandb:   grad_mean/output_layer 0.37702
wandb:                       lr 1e-05
wandb: spikes/train_avg_layer_0 0.01794
wandb: spikes/train_avg_layer_1 0.00012
wandb:               train_loss 0.30641
wandb:      trainer/global_step 139
wandb:                 val_loss 0.30364
wandb: 
wandb: üöÄ View run grateful-sweep-171 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/vcvjc004
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_022807-vcvjc004/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: j2qh3y5f with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 2.385830136039348e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.8
wandb: setting up run j2qh3y5f
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_022909-j2qh3y5f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-172
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/j2qh3y5f
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 944    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
975       Trainable params
0         Non-trainable params
975       Total params
0.004     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 270, in _feed
    send_bytes(obj)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 427, in _send_bytes
    self._send(header + buf)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 384, in _send
    n = write(self._handle, buf)
        ^^^^^^^^^^^^^^^^^^^^^^^^
OSError: [Errno 9] Bad file descriptor
Exception in thread QueueFeederThread:
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
Exception in thread QueueFeederThread:
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    reader_close()
      File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
self._shutdown_workers()
      File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    reader_close()self._shutdown_workers()    

self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    if w.is_alive():
           ^_close(self._handle)^
^^^OSError^    : ^if w.is_alive():[Errno 9] Bad file descriptor^

^ ^ 
^     ^self._close() During handling of the above exception, another exception occurred:


   File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
 
   File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
^Traceback (most recent call last):
^^  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    _close(self._handle)    
assert self._parent_pid == os.getpid(), 'can only test a child process'    
self.run()OSError
 :    File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1012, in run
[Errno 9] Bad file descriptor     
 assert self._parent_pid == os.getpid(), 'can only test a child process' 

   During handling of the above exception, another exception occurred:
     
    Traceback (most recent call last):
^ ^   File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
^ ^ ^ ^^^^^^^^^^^^^^^    ^^self._target(*self._args, **self._kwargs)^^
^^^^^  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 291, in _feed
^^^^^^^^^^^^^^^^^^^^^^^^^^    ^^self.run()
^
AssertionError^: ^can only test a child process^
^  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1012, in run

AssertionError: can only test a child process
    queue_sem.release()
ValueError: semaphore or lock released too many times
    self._target(*self._args, **self._kwargs)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 291, in _feed
    queue_sem.release()
ValueError: semaphore or lock released too many times
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^    ^if w.is_alive():^
^^ 
   File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
     ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
             assert self._parent_pid == os.getpid(), 'can only test a child process' 
 ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^AssertionError^: ^can only test a child process^
^^^^^^^
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
    self._shutdown_workers()  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers

  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^    ^if w.is_alive():^
^
   File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
      ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'    
assert self._parent_pid == os.getpid(), 'can only test a child process'
                     ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^AssertionError
: AssertionErrorcan only test a child process: 
can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^Traceback (most recent call last):
^^^^^^^^^^^Traceback (most recent call last):
^  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
^^^^^  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
^^^  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
^^  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
^OSError: [Errno 9] Bad file descriptor
^^^^
AssertionError: can only test a child process
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
    if w.is_alive():  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()

  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
    OSError: [Errno 9] Bad file descriptor
   ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1618, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/popen_fork.py", line 40, in wait
    if not wait([self.sentinel], timeout):
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 1136, in wait
    ready = selector.select(timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Exception: 
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: uploading history steps 82-83, summary, console lines 70-72
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÑ‚ñÖ‚ñÅ‚ñà
wandb:   grad_mean/lif_layers.1 ‚ñÅ‚ñÇ‚ñÖ‚ñà
wandb:   grad_mean/lif_layers.2 ‚ñÅ‚ñÅ‚ñÖ‚ñà
wandb:   grad_mean/lif_layers.3 ‚ñÇ‚ñÅ‚ñÜ‚ñà
wandb:   grad_mean/output_layer ‚ñÇ‚ñÅ‚ñÜ‚ñà
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: spikes/train_avg_layer_1 ‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_2 ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:                       +4 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 39
wandb:   grad_mean/lif_layers.0 0.01315
wandb:   grad_mean/lif_layers.1 0.0059
wandb:   grad_mean/lif_layers.2 0.00358
wandb:   grad_mean/lif_layers.3 0.00511
wandb:   grad_mean/output_layer 0.25306
wandb:                       lr 0
wandb: spikes/train_avg_layer_0 0.01655
wandb: spikes/train_avg_layer_1 0.00126
wandb: spikes/train_avg_layer_2 0.0
wandb:                       +4 ...
wandb: 
wandb: üöÄ View run fast-sweep-172 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/j2qh3y5f
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_022909-j2qh3y5f/logs
wandb: Agent Starting Run: 6sa5qkzk with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.915156919682132e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.9
wandb: setting up run 6sa5qkzk
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_023331-6sa5qkzk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-sweep-173
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/6sa5qkzk
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 116 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
116 K     Trainable params
0         Non-trainable params
116 K     Total params
0.467     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading summary, console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÑ‚ñá‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñà‚ñÉ‚ñÇ
wandb: spikes/train_avg_layer_2 ‚ñá‚ñà‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 3
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.0209
wandb: spikes/train_avg_layer_1 0.00157
wandb: spikes/train_avg_layer_2 6e-05
wandb: spikes/train_avg_layer_3 0
wandb: spikes/train_avg_layer_4 0
wandb: spikes/train_avg_layer_5 0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run ruby-sweep-173 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/6sa5qkzk
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_023331-6sa5qkzk/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: 8ft77jdy with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 9.887479465032692e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 3
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.9
wandb: setting up run 8ft77jdy
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_024208-8ft77jdy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-174
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/8ft77jdy
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 116 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
116 K     Trainable params
0         Non-trainable params
116 K     Total params
0.467     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading summary, console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÇ‚ñÖ‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÉ‚ñÖ‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÅ‚ñÑ‚ñà
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 3
wandb:                       lr 0.0001
wandb: spikes/train_avg_layer_0 0.02132
wandb: spikes/train_avg_layer_1 0.00165
wandb: spikes/train_avg_layer_2 0.00012
wandb: spikes/train_avg_layer_3 0
wandb: spikes/train_avg_layer_4 0
wandb: spikes/train_avg_layer_5 0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run treasured-sweep-174 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/8ft77jdy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_024208-8ft77jdy/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: jlwt8r4q with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 5.749044818168924e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 3
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 1
wandb: setting up run jlwt8r4q
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_025007-jlwt8r4q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-175
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/jlwt8r4q
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 13.0 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
13.1 K    Trainable params
0         Non-trainable params
13.1 K    Total params
0.052     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÉ‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÉ‚ñÜ‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñá‚ñÇ‚ñà
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               train_loss ‚ñà‚ñÜ‚ñÉ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñÜ‚ñÉ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 3
wandb:                       lr 6e-05
wandb: spikes/train_avg_layer_0 0.02096
wandb: spikes/train_avg_layer_1 0.00107
wandb: spikes/train_avg_layer_2 0.0
wandb: spikes/train_avg_layer_3 0
wandb:               train_loss 0.27373
wandb:      trainer/global_step 27
wandb:                 val_loss 0.27107
wandb: 
wandb: üöÄ View run peach-sweep-175 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/jlwt8r4q
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_025007-jlwt8r4q/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 167, in forward
    x = self.rho * torch.tanh(i / self.rho)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: 0qu0mgyp with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.00070738636420013
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 1
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_025211-0qu0mgyp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-sweep-176
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/0qu0mgyp
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 4.7 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
4.8 K     Trainable params
0         Non-trainable params
4.8 K     Total params
0.019     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1618, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/popen_fork.py", line 40, in wait
    if not wait([self.sentinel], timeout):
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 1136, in wait
    ready = selector.select(timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Exception: 
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: uploading history steps 80-83, summary, console lines 44-45
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñà‚ñÉ‚ñÅ‚ñÅ
wandb:   grad_mean/lif_layers.1 ‚ñà‚ñÑ‚ñÅ‚ñÅ
wandb:   grad_mean/output_layer ‚ñÉ‚ñà‚ñÅ‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:               train_loss ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 39
wandb:   grad_mean/lif_layers.0 0.00178
wandb:   grad_mean/lif_layers.1 0.0003
wandb:   grad_mean/output_layer 0.13768
wandb:                       lr 0
wandb: spikes/train_avg_layer_0 0.03811
wandb: spikes/train_avg_layer_1 0.02867
wandb:               train_loss 0.1811
wandb:      trainer/global_step 279
wandb:                 val_loss 0.17892
wandb: 
wandb: üöÄ View run ancient-sweep-176 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/0qu0mgyp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_025211-0qu0mgyp/logs
wandb: Agent Starting Run: 34mza6xz with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.0004492073054890762
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_025808-34mza6xz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-177
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/34mza6xz
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 52     | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
71        Trainable params
0         Non-trainable params
71        Total params
0.000     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: uploading history steps 73-83, summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ‚ñÑ‚ñà‚ñà
wandb:   grad_mean/lif_layers.1 ‚ñÅ‚ñÜ‚ñá‚ñà
wandb:   grad_mean/output_layer ‚ñà‚ñÖ‚ñÅ‚ñÉ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:               train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 39
wandb:   grad_mean/lif_layers.0 0.17187
wandb:   grad_mean/lif_layers.1 0.04688
wandb:   grad_mean/output_layer 0.5819
wandb:                       lr 0
wandb: spikes/train_avg_layer_0 0.02383
wandb: spikes/train_avg_layer_1 0.01036
wandb:               train_loss 0.48387
wandb:      trainer/global_step 279
wandb:                 val_loss 0.48
wandb: 
wandb: üöÄ View run glamorous-sweep-177 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/34mza6xz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_025808-34mza6xz/logs
wandb: Agent Starting Run: nsyjxs1d with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 5.964922477637983e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.8
wandb: setting up run nsyjxs1d
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_025904-nsyjxs1d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-178
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/nsyjxs1d
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 400    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
431       Trainable params
0         Non-trainable params
431       Total params
0.002     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading history steps 50-51, summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ‚ñà
wandb:   grad_mean/lif_layers.1 ‚ñÅ‚ñà
wandb:   grad_mean/output_layer ‚ñÅ‚ñà
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:               train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 24
wandb:   grad_mean/lif_layers.0 0.02167
wandb:   grad_mean/lif_layers.1 0.00756
wandb:   grad_mean/output_layer 0.33991
wandb:                       lr 2e-05
wandb: spikes/train_avg_layer_0 0.0215
wandb: spikes/train_avg_layer_1 0.00164
wandb:               train_loss 0.27532
wandb:      trainer/global_step 174
wandb:                 val_loss 0.27273
wandb: 
wandb: üöÄ View run clean-sweep-178 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/nsyjxs1d
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_025904-nsyjxs1d/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 149, in run
    self.on_run_start(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 245, in on_run_start
    iter(data_fetcher)  # creates the iterator inside the fetcher
    ^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fetchers.py", line 105, in __iter__
    super().__iter__()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fetchers.py", line 52, in __iter__
    self.iterator = iter(self.combined_loader)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py", line 351, in __iter__
    iter(iterator)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py", line 92, in __iter__
    super().__iter__()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py", line 43, in __iter__
    self.iterators = [iter(iterable) for iterable in self.iterables]
                      ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 494, in __iter__
    return self._get_iterator()
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 427, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1218, in __init__
    self._reset(loader, first_iter=True)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1260, in _reset
    self._try_put_index()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1513, in _try_put_index
    index = self._next_index()
            ^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 722, in _next_index
    return next(self._sampler_iter)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/sampler.py", line 354, in __iter__
    batch = [*itertools.islice(sampler_iter, self.batch_size)]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/sampler.py", line 195, in __iter__
    yield from torch.randperm(n, generator=generator).tolist()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: gl9a37s3 with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 5.207399275734382e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_030011-gl9a37s3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-179
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/gl9a37s3
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 4.2 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
4.2 K     Trainable params
0         Non-trainable params
4.2 K     Total params
0.017     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading summary, console lines 42-42
wandb: 
wandb: Run history:
wandb:                     epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñà
wandb:                        lr ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÅ
wandb:  spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñà
wandb:  spikes/train_avg_layer_1 ‚ñà‚ñà‚ñÜ‚ñÅ‚ñÅ‚ñÑ
wandb: spikes/train_avg_layer_10 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_11 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_12 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_13 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_14 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_15 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +11 ...
wandb: 
wandb: Run summary:
wandb:                     epoch 5
wandb:                        lr 0.0
wandb:  spikes/train_avg_layer_0 0.02737
wandb:  spikes/train_avg_layer_1 0.00372
wandb: spikes/train_avg_layer_10 0
wandb: spikes/train_avg_layer_11 0
wandb: spikes/train_avg_layer_12 0
wandb: spikes/train_avg_layer_13 0
wandb: spikes/train_avg_layer_14 0
wandb: spikes/train_avg_layer_15 0
wandb:                       +11 ...
wandb: 
wandb: üöÄ View run avid-sweep-179 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/gl9a37s3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_030011-gl9a37s3/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 315, in apply
    return user_fn(self, *args)
           ^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 61, in backward
    grad_input = grad_output.clone()
                 ^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: gsplupky with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.0005453471838908359
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_030210-gsplupky
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-180
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/gsplupky
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 944    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
975       Trainable params
0         Non-trainable params
975       Total params
0.004     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading history steps 46-49, summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñà‚ñÅ
wandb:   grad_mean/lif_layers.1 ‚ñà‚ñÅ
wandb:   grad_mean/lif_layers.2 ‚ñà‚ñÅ
wandb:   grad_mean/lif_layers.3 ‚ñà‚ñÅ
wandb:   grad_mean/output_layer ‚ñà‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                       +4 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 23
wandb:   grad_mean/lif_layers.0 0.01541
wandb:   grad_mean/lif_layers.1 0.0075
wandb:   grad_mean/lif_layers.2 0.00264
wandb:   grad_mean/lif_layers.3 0.00204
wandb:   grad_mean/output_layer 0.09475
wandb:                       lr 0.00019
wandb: spikes/train_avg_layer_0 0.03945
wandb: spikes/train_avg_layer_1 0.0235
wandb: spikes/train_avg_layer_2 0.01159
wandb:                       +4 ...
wandb: 
wandb: üöÄ View run rare-sweep-180 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/gsplupky
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_030210-gsplupky/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 149, in run
    self.on_run_start(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 245, in on_run_start
    iter(data_fetcher)  # creates the iterator inside the fetcher
    ^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fetchers.py", line 105, in __iter__
    super().__iter__()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fetchers.py", line 52, in __iter__
    self.iterator = iter(self.combined_loader)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py", line 351, in __iter__
    iter(iterator)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py", line 92, in __iter__
    super().__iter__()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py", line 43, in __iter__
    self.iterators = [iter(iterable) for iterable in self.iterables]
                      ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 494, in __iter__
    return self._get_iterator()
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 427, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1218, in __init__
    self._reset(loader, first_iter=True)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1260, in _reset
    self._try_put_index()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1513, in _try_put_index
    index = self._next_index()
            ^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 722, in _next_index
    return next(self._sampler_iter)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/sampler.py", line 354, in __iter__
    batch = [*itertools.islice(sampler_iter, self.batch_size)]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/sampler.py", line 176, in __iter__
    seed = int(torch.empty((), dtype=torch.int64).random_().item())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: suwxadj2 with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.210938658469403e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 3
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_030409-suwxadj2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-sweep-181
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/suwxadj2
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 2.0 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
2.1 K     Trainable params
0         Non-trainable params
2.1 K     Total params
0.008     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading history steps 8-9, summary, console lines 43-44
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÇ‚ñÉ‚ñÅ‚ñá‚ñà
wandb: spikes/train_avg_layer_1 ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 4
wandb:                       lr 1e-05
wandb: spikes/train_avg_layer_0 0.01823
wandb: spikes/train_avg_layer_1 0.00097
wandb: spikes/train_avg_layer_2 0
wandb: spikes/train_avg_layer_3 0
wandb: spikes/train_avg_layer_4 0
wandb: spikes/train_avg_layer_5 0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run playful-sweep-181 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/suwxadj2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_030409-suwxadj2/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: edq3rwhl with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.933532005987026e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 3
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 1
wandb: setting up run edq3rwhl
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_030507-edq3rwhl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-182
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/edq3rwhl
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 116 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
116 K     Trainable params
0         Non-trainable params
116 K     Total params
0.467     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÖ‚ñà‚ñà‚ñÅ
wandb: spikes/train_avg_layer_1 ‚ñà‚ñÅ‚ñÑ‚ñÖ
wandb: spikes/train_avg_layer_2 ‚ñÜ‚ñÅ‚ñà‚ñà
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 3
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.01955
wandb: spikes/train_avg_layer_1 0.0016
wandb: spikes/train_avg_layer_2 8e-05
wandb: spikes/train_avg_layer_3 0
wandb: spikes/train_avg_layer_4 0
wandb: spikes/train_avg_layer_5 0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run ethereal-sweep-182 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/edq3rwhl
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_030507-edq3rwhl/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: qn858npf with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.000535161607093257
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.8
wandb: setting up run qn858npf
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_031311-qn858npf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-183
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/qn858npf
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 332    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
351       Trainable params
0         Non-trainable params
351       Total params
0.001     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading history steps 10-11, summary, console lines 43-44
wandb: 
wandb: Run history:
wandb:                     epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñà
wandb:                        lr ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÅ
wandb:  spikes/train_avg_layer_0 ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà
wandb:  spikes/train_avg_layer_1 ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñá‚ñà
wandb: spikes/train_avg_layer_10 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_11 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_12 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_13 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_14 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_15 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +11 ...
wandb: 
wandb: Run summary:
wandb:                     epoch 5
wandb:                        lr 0.00051
wandb:  spikes/train_avg_layer_0 0.01473
wandb:  spikes/train_avg_layer_1 0.0043
wandb: spikes/train_avg_layer_10 0
wandb: spikes/train_avg_layer_11 0
wandb: spikes/train_avg_layer_12 0
wandb: spikes/train_avg_layer_13 0
wandb: spikes/train_avg_layer_14 0
wandb: spikes/train_avg_layer_15 0
wandb:                       +11 ...
wandb: 
wandb: üöÄ View run vital-sweep-183 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/qn858npf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_031311-qn858npf/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: wjk2epwo with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 5.3847967017822725e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 3
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 1
wandb: setting up run wjk2epwo
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_031408-wjk2epwo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-184
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/wjk2epwo
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 332    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
351       Trainable params
0         Non-trainable params
351       Total params
0.001     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading history steps 10-13, summary, console lines 42-43
wandb: 
wandb: Run history:
wandb:                     epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:                        lr ‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÅ
wandb:  spikes/train_avg_layer_0 ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñà‚ñà
wandb:  spikes/train_avg_layer_1 ‚ñÅ‚ñÅ‚ñÖ‚ñÉ‚ñÇ‚ñà‚ñá
wandb: spikes/train_avg_layer_10 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_11 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_12 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_13 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_14 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_15 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +11 ...
wandb: 
wandb: Run summary:
wandb:                     epoch 6
wandb:                        lr 0.0
wandb:  spikes/train_avg_layer_0 0.03504
wandb:  spikes/train_avg_layer_1 0.0
wandb: spikes/train_avg_layer_10 0
wandb: spikes/train_avg_layer_11 0
wandb: spikes/train_avg_layer_12 0
wandb: spikes/train_avg_layer_13 0
wandb: spikes/train_avg_layer_14 0
wandb: spikes/train_avg_layer_15 0
wandb:                       +11 ...
wandb: 
wandb: üöÄ View run happy-sweep-184 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/wjk2epwo
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_031408-wjk2epwo/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 189, in forward
    hs = zs * hs_prev + (1.0 - zs) * h_prev
                         ~~~~^~~~
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 38, in wrapped
    @functools.wraps(f)
    
Exception

wandb: Agent Starting Run: bmtc4031 with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 6.512377651802893e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 1
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.8
wandb: setting up run bmtc4031
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_031510-bmtc4031
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-185
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/bmtc4031
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 4.7 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
4.8 K     Trainable params
0         Non-trainable params
4.8 K     Total params
0.019     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÉ‚ñà‚ñÅ‚ñÖ
wandb: spikes/train_avg_layer_1 ‚ñà‚ñà‚ñÑ‚ñÇ‚ñÅ
wandb:               train_loss ‚ñà‚ñá‚ñÑ‚ñÉ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñÖ‚ñÑ‚ñÇ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 4
wandb:                       lr 1e-05
wandb: spikes/train_avg_layer_0 0.02007
wandb: spikes/train_avg_layer_1 0.00124
wandb:               train_loss 0.2506
wandb:      trainer/global_step 34
wandb:                 val_loss 0.24822
wandb: 
wandb: üöÄ View run swept-sweep-185 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/bmtc4031
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_031510-bmtc4031/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: tq5z0yte with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.0008992986423965628
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_031607-tq5z0yte
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-186
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/tq5z0yte
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 62.9 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
63.0 K    Trainable params
0         Non-trainable params
63.0 K    Total params
0.252     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading summary, console lines 43-43
wandb: 
wandb: Run history:
wandb:                     epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                        lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb:  spikes/train_avg_layer_0 ‚ñÅ‚ñÉ‚ñÖ‚ñà
wandb:  spikes/train_avg_layer_1 ‚ñÅ‚ñÇ‚ñÑ‚ñà
wandb: spikes/train_avg_layer_10 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_11 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_12 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_13 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_14 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_15 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +11 ...
wandb: 
wandb: Run summary:
wandb:                     epoch 3
wandb:                        lr 0.00088
wandb:  spikes/train_avg_layer_0 0.0211
wandb:  spikes/train_avg_layer_1 0.00502
wandb: spikes/train_avg_layer_10 0
wandb: spikes/train_avg_layer_11 0
wandb: spikes/train_avg_layer_12 0
wandb: spikes/train_avg_layer_13 0
wandb: spikes/train_avg_layer_14 0
wandb: spikes/train_avg_layer_15 0
wandb:                       +11 ...
wandb: 
wandb: üöÄ View run ethereal-sweep-186 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/tq5z0yte
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_031607-tq5z0yte/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: qy0xakuy with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 4.274713898087619e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 3
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_032411-qy0xakuy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-187
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/qy0xakuy
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 4.7 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
4.8 K     Trainable params
0         Non-trainable params
4.8 K     Total params
0.019     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1618, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/popen_fork.py", line 40, in wait
    if not wait([self.sentinel], timeout):
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 1136, in wait
    ready = selector.select(timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Exception: 
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: uploading history steps 80-83, summary, console lines 42-43
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÇ‚ñà‚ñÜ‚ñÅ
wandb:   grad_mean/lif_layers.1 ‚ñÅ‚ñà‚ñá‚ñÉ
wandb:   grad_mean/output_layer ‚ñÅ‚ñà‚ñá‚ñÇ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÜ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:               train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 39
wandb:   grad_mean/lif_layers.0 0.00517
wandb:   grad_mean/lif_layers.1 0.00195
wandb:   grad_mean/output_layer 0.19144
wandb:                       lr 0
wandb: spikes/train_avg_layer_0 0.01861
wandb: spikes/train_avg_layer_1 0.00061
wandb:               train_loss 0.20001
wandb:      trainer/global_step 279
wandb:                 val_loss 0.19822
wandb: 
wandb: üöÄ View run lunar-sweep-187 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/qy0xakuy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_032411-qy0xakuy/logs
wandb: Agent Starting Run: nbq3d0nx with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.0005197652813554361
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_033042-nbq3d0nx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-188
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/nbq3d0nx
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 4.2 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
4.2 K     Trainable params
0         Non-trainable params
4.2 K     Total params
0.017     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                     epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                        lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb:  spikes/train_avg_layer_0 ‚ñÅ‚ñÉ‚ñÖ‚ñà
wandb:  spikes/train_avg_layer_1 ‚ñà‚ñÅ‚ñÑ‚ñÜ
wandb: spikes/train_avg_layer_10 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_11 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_12 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_13 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_14 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_15 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +11 ...
wandb: 
wandb: Run summary:
wandb:                     epoch 3
wandb:                        lr 0.00051
wandb:  spikes/train_avg_layer_0 0.02113
wandb:  spikes/train_avg_layer_1 0.00122
wandb: spikes/train_avg_layer_10 0
wandb: spikes/train_avg_layer_11 0
wandb: spikes/train_avg_layer_12 0
wandb: spikes/train_avg_layer_13 0
wandb: spikes/train_avg_layer_14 0
wandb: spikes/train_avg_layer_15 0
wandb:                       +11 ...
wandb: 
wandb: üöÄ View run efficient-sweep-188 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/nbq3d0nx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_033042-nbq3d0nx/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 167, in forward
    x = self.rho * torch.tanh(i / self.rho)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: myljbjuj with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 5.9562159463339685e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 1
wandb: setting up run myljbjuj
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_033206-myljbjuj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-189
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/myljbjuj
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 116 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
116 K     Trainable params
0         Non-trainable params
116 K     Total params
0.467     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading summary, console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÉ‚ñÜ‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÉ‚ñÖ‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÉ‚ñÖ‚ñà
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 3
wandb:                       lr 6e-05
wandb: spikes/train_avg_layer_0 0.02357
wandb: spikes/train_avg_layer_1 0.00235
wandb: spikes/train_avg_layer_2 0.00015
wandb: spikes/train_avg_layer_3 0
wandb: spikes/train_avg_layer_4 0
wandb: spikes/train_avg_layer_5 0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run logical-sweep-189 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/myljbjuj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_033206-myljbjuj/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: cq31a6q8 with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.9793205148680556e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 3
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_034011-cq31a6q8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-190
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/cq31a6q8
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 4.7 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
4.8 K     Trainable params
0         Non-trainable params
4.8 K     Total params
0.019     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading history steps 8-9, summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñà
wandb: spikes/train_avg_layer_1 ‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÖ
wandb:               train_loss ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 4
wandb:                       lr 2e-05
wandb: spikes/train_avg_layer_0 0.01953
wandb: spikes/train_avg_layer_1 0.00153
wandb:               train_loss 0.27099
wandb:      trainer/global_step 34
wandb:                 val_loss 0.26839
wandb: 
wandb: üöÄ View run kind-sweep-190 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/cq31a6q8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_034011-cq31a6q8/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: i6o2jrb2 with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.0004632506529776134
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 1
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_034108-i6o2jrb2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-191
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/i6o2jrb2
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 62.9 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
63.0 K    Trainable params
0         Non-trainable params
63.0 K    Total params
0.252     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading summary, console lines 43-43
wandb: 
wandb: Run history:
wandb:                     epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                        lr ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ
wandb:  spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb:  spikes/train_avg_layer_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà
wandb: spikes/train_avg_layer_10 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñà
wandb: spikes/train_avg_layer_11 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà
wandb: spikes/train_avg_layer_12 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà
wandb: spikes/train_avg_layer_13 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_14 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_15 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +11 ...
wandb: 
wandb: Run summary:
wandb:                     epoch 12
wandb:                        lr 0.00035
wandb:  spikes/train_avg_layer_0 0.03038
wandb:  spikes/train_avg_layer_1 0.02629
wandb: spikes/train_avg_layer_10 0.00284
wandb: spikes/train_avg_layer_11 0.00039
wandb: spikes/train_avg_layer_12 0.0
wandb: spikes/train_avg_layer_13 0
wandb: spikes/train_avg_layer_14 0
wandb: spikes/train_avg_layer_15 0
wandb:                       +11 ...
wandb: 
wandb: üöÄ View run stoic-sweep-191 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/i6o2jrb2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_034108-i6o2jrb2/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: 7xlqcypz with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.0004572573631699404
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 3
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.9
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_040709-7xlqcypz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-192
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/7xlqcypz
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 2.0 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
2.1 K     Trainable params
0         Non-trainable params
2.1 K     Total params
0.008     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: uploading history steps 82-83, summary, console lines 41-41
wandb: 
wandb: Run history:
wandb:                  epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb: grad_mean/lif_layers.0 ‚ñÅ‚ñÅ‚ñÖ‚ñà
wandb: grad_mean/lif_layers.1 ‚ñÅ‚ñÑ‚ñá‚ñà
wandb: grad_mean/lif_layers.2 ‚ñÅ‚ñÖ‚ñÜ‚ñà
wandb: grad_mean/lif_layers.3 ‚ñÅ‚ñÉ‚ñÜ‚ñà
wandb: grad_mean/lif_layers.4 ‚ñÅ‚ñÉ‚ñÜ‚ñà
wandb: grad_mean/lif_layers.5 ‚ñÅ‚ñÖ‚ñá‚ñà
wandb: grad_mean/lif_layers.6 ‚ñÖ‚ñà‚ñÉ‚ñÅ
wandb: grad_mean/lif_layers.7 ‚ñá‚ñà‚ñÉ‚ñÅ
wandb: grad_mean/output_layer ‚ñÜ‚ñà‚ñÇ‚ñÅ
wandb:                    +12 ...
wandb: 
wandb: Run summary:
wandb:                  epoch 39
wandb: grad_mean/lif_layers.0 0.04563
wandb: grad_mean/lif_layers.1 0.01102
wandb: grad_mean/lif_layers.2 0.00398
wandb: grad_mean/lif_layers.3 0.00178
wandb: grad_mean/lif_layers.4 0.00083
wandb: grad_mean/lif_layers.5 0.00045
wandb: grad_mean/lif_layers.6 0.0002
wandb: grad_mean/lif_layers.7 0.00025
wandb: grad_mean/output_layer 0.01284
wandb:                    +12 ...
wandb: 
wandb: üöÄ View run morning-sweep-192 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/7xlqcypz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_040709-7xlqcypz/logs
wandb: Agent Starting Run: m1pfcz45 with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.0009463040253674244
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 1
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.9
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_041331-m1pfcz45
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-193
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/m1pfcz45
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 13.0 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
13.1 K    Trainable params
0         Non-trainable params
13.1 K    Total params
0.052     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: uploading history steps 82-83, summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ‚ñÑ‚ñá‚ñà
wandb:   grad_mean/lif_layers.1 ‚ñÅ‚ñÖ‚ñá‚ñà
wandb:   grad_mean/lif_layers.2 ‚ñÅ‚ñÜ‚ñá‚ñà
wandb:   grad_mean/lif_layers.3 ‚ñÅ‚ñá‚ñá‚ñà
wandb:   grad_mean/output_layer ‚ñà‚ñÉ‚ñÇ‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:                       +4 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 39
wandb:   grad_mean/lif_layers.0 0.12164
wandb:   grad_mean/lif_layers.1 0.01357
wandb:   grad_mean/lif_layers.2 0.00158
wandb:   grad_mean/lif_layers.3 0.00018
wandb:   grad_mean/output_layer 0.05829
wandb:                       lr 0
wandb: spikes/train_avg_layer_0 0.01433
wandb: spikes/train_avg_layer_1 0.0239
wandb: spikes/train_avg_layer_2 0.02036
wandb:                       +4 ...
wandb: 
wandb: üöÄ View run jolly-sweep-193 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/m1pfcz45
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_041331-m1pfcz45/logs
wandb: Agent Starting Run: 1s46jctp with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.712532454214395e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.9
wandb: setting up run 1s46jctp
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_042700-1s46jctp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-194
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/1s46jctp
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 62.9 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
63.0 K    Trainable params
0         Non-trainable params
63.0 K    Total params
0.252     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading summary, console lines 42-42
wandb: 
wandb: Run history:
wandb:                     epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                        lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb:  spikes/train_avg_layer_0 ‚ñà‚ñÜ‚ñÉ‚ñÅ
wandb:  spikes/train_avg_layer_1 ‚ñà‚ñÖ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_10 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_11 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_12 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_13 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_14 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_15 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +11 ...
wandb: 
wandb: Run summary:
wandb:                     epoch 3
wandb:                        lr 2e-05
wandb:  spikes/train_avg_layer_0 0.02228
wandb:  spikes/train_avg_layer_1 0.00125
wandb: spikes/train_avg_layer_10 0
wandb: spikes/train_avg_layer_11 0
wandb: spikes/train_avg_layer_12 0
wandb: spikes/train_avg_layer_13 0
wandb: spikes/train_avg_layer_14 0
wandb: spikes/train_avg_layer_15 0
wandb:                       +11 ...
wandb: 
wandb: üöÄ View run divine-sweep-194 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/1s46jctp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_042700-1s46jctp/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: kjuhuf07 with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.0003864267159508021
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 3
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_043509-kjuhuf07
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-195
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/kjuhuf07
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 332    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
351       Trainable params
0         Non-trainable params
351       Total params
0.001     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                   epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:  grad_mean/lif_layers.0 ‚ñà‚ñÅ
wandb:  grad_mean/lif_layers.1 ‚ñà‚ñÅ
wandb: grad_mean/lif_layers.10 ‚ñà‚ñÅ
wandb: grad_mean/lif_layers.11 ‚ñà‚ñÅ
wandb: grad_mean/lif_layers.12 ‚ñà‚ñÅ
wandb: grad_mean/lif_layers.13 ‚ñà‚ñÅ
wandb: grad_mean/lif_layers.14 ‚ñà‚ñÅ
wandb: grad_mean/lif_layers.15 ‚ñà‚ñÅ
wandb:  grad_mean/lif_layers.2 ‚ñà‚ñÅ
wandb:                     +28 ...
wandb: 
wandb: Run summary:
wandb:                   epoch 21
wandb:  grad_mean/lif_layers.0 2e-05
wandb:  grad_mean/lif_layers.1 2e-05
wandb: grad_mean/lif_layers.10 0.00491
wandb: grad_mean/lif_layers.11 0.00595
wandb: grad_mean/lif_layers.12 0.00704
wandb: grad_mean/lif_layers.13 0.00482
wandb: grad_mean/lif_layers.14 0.00859
wandb: grad_mean/lif_layers.15 0.00988
wandb:  grad_mean/lif_layers.2 2e-05
wandb:                     +28 ...
wandb: 
wandb: üöÄ View run clean-sweep-195 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/kjuhuf07
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_043509-kjuhuf07/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 180, in forward
    H = (h_prev > 0.5).float()
        ^^^^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: huli8g99 with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.89614076552631e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 3
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_043810-huli8g99
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-196
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/huli8g99
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 2.0 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
2.1 K     Trainable params
0         Non-trainable params
2.1 K     Total params
0.008     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading history steps 8-9, summary, console lines 42-43
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñá‚ñÅ‚ñÜ‚ñÖ‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÉ‚ñà‚ñÖ‚ñÜ
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 4
wandb:                       lr 2e-05
wandb: spikes/train_avg_layer_0 0.01181
wandb: spikes/train_avg_layer_1 0.0001
wandb: spikes/train_avg_layer_2 0.0
wandb: spikes/train_avg_layer_3 0
wandb: spikes/train_avg_layer_4 0
wandb: spikes/train_avg_layer_5 0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run skilled-sweep-196 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/huli8g99
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_043810-huli8g99/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 189, in forward
    hs = zs * hs_prev + (1.0 - zs) * h_prev
                         ~~~~^~~~
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 45, in wrapped
    return f(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 1075, in __rsub__
    return _C._VariableFunctions.rsub(self, other)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: nbvvcn08 with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.3811895175188504e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 3
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 1
wandb: setting up run nbvvcn08
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_043907-nbvvcn08
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-197
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/nbvvcn08
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 4.2 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
4.2 K     Trainable params
0         Non-trainable params
4.2 K     Total params
0.017     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading history steps 10-11, summary, console lines 42-43
wandb: 
wandb: Run history:
wandb:                     epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñà
wandb:                        lr ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÅ
wandb:  spikes/train_avg_layer_0 ‚ñÅ‚ñÉ‚ñá‚ñÖ‚ñá‚ñà
wandb:  spikes/train_avg_layer_1 ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñá‚ñà
wandb: spikes/train_avg_layer_10 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_11 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_12 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_13 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_14 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_15 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +11 ...
wandb: 
wandb: Run summary:
wandb:                     epoch 5
wandb:                        lr 1e-05
wandb:  spikes/train_avg_layer_0 0.01624
wandb:  spikes/train_avg_layer_1 0.00038
wandb: spikes/train_avg_layer_10 0
wandb: spikes/train_avg_layer_11 0
wandb: spikes/train_avg_layer_12 0
wandb: spikes/train_avg_layer_13 0
wandb: spikes/train_avg_layer_14 0
wandb: spikes/train_avg_layer_15 0
wandb:                       +11 ...
wandb: 
wandb: üöÄ View run stoic-sweep-197 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/nbvvcn08
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_043907-nbvvcn08/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: 4cgc8adw with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 3.886698211646849e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.9
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_044111-4cgc8adw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-198
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/4cgc8adw
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 2.0 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
2.1 K     Trainable params
0         Non-trainable params
2.1 K     Total params
0.008     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñÖ‚ñÉ‚ñÅ
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñà‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñà‚ñÖ‚ñÜ
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 3
wandb:                       lr 4e-05
wandb: spikes/train_avg_layer_0 0.02267
wandb: spikes/train_avg_layer_1 0.00124
wandb: spikes/train_avg_layer_2 3e-05
wandb: spikes/train_avg_layer_3 0
wandb: spikes/train_avg_layer_4 0
wandb: spikes/train_avg_layer_5 0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run ethereal-sweep-198 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/4cgc8adw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_044111-4cgc8adw/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 153, in run
    self.on_advance_end(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 398, in on_advance_end
    self.val_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 145, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 437, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 412, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 620, in validation_step
    layer_outputs.append(x_seq)
      ^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 167, in forward
    x = self.rho * torch.tanh(i / self.rho)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: e4d03nc4 with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 2.383236851460744e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 3
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.9
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_044208-e4d03nc4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-199
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/e4d03nc4
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 29.6 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
29.7 K    Trainable params
0         Non-trainable params
29.7 K    Total params
0.119     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception in thread QueueFeederThread:
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1012, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 291, in _feed
    queue_sem.release()
ValueError: semaphore or lock released too many times
wandb: updating run metadata
wandb: uploading summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÖ‚ñÉ‚ñÅ‚ñÑ‚ñà
wandb: spikes/train_avg_layer_1 ‚ñà‚ñÇ‚ñÑ‚ñÉ‚ñÅ
wandb: spikes/train_avg_layer_2 ‚ñà‚ñÜ‚ñà‚ñÖ‚ñÅ
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 4
wandb:                       lr 2e-05
wandb: spikes/train_avg_layer_0 0.02153
wandb: spikes/train_avg_layer_1 0.00123
wandb: spikes/train_avg_layer_2 2e-05
wandb: spikes/train_avg_layer_3 0
wandb: spikes/train_avg_layer_4 0
wandb: spikes/train_avg_layer_5 0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run true-sweep-199 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/e4d03nc4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_044208-e4d03nc4/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    # ------------------ RLeaky (per-step) branch ------------------
                               ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 189, in forward
    hs = zs * hs_prev + (1.0 - zs) * h_prev
                         ~~~~^~~~
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 38, in wrapped
    @functools.wraps(f)
    
Exception

wandb: Agent Starting Run: uw28obon with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.0002939982005784754
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 1
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_044610-uw28obon
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-200
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/uw28obon
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 248 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
248 K     Trainable params
0         Non-trainable params
248 K     Total params
0.995     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^    ^if w.is_alive():^
^ ^ ^ 
   File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
   ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
          assert self._parent_pid == os.getpid(), 'can only test a child process' 
       ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^AssertionError^: ^can only test a child process^
^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
<function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>Traceback (most recent call last):

  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
         if w.is_alive(): 
 ^ ^ ^ ^     if w.is_alive():^ 
^ ^  ^ ^^ ^^ ^^ ^^ ^
 ^  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
^^^^^^^^^^^^^
^  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
        assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'

                 assert self._parent_pid == os.getpid(), 'can only test a child process'  
          ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

^AssertionErrorAssertionError^: : ^can only test a child processcan only test a child process^

^^^^
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
wandb: updating run metadata
wandb: uploading summary
wandb: 
wandb: Run history:
wandb:                     epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                        lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb:  spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÉ‚ñà
wandb:  spikes/train_avg_layer_1 ‚ñÅ‚ñÇ‚ñÑ‚ñà
wandb: spikes/train_avg_layer_10 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_11 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_12 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_13 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_14 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_15 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +11 ...
wandb: 
wandb: Run summary:
wandb:                     epoch 3
wandb:                        lr 0.00029
wandb:  spikes/train_avg_layer_0 0.02037
wandb:  spikes/train_avg_layer_1 0.00251
wandb: spikes/train_avg_layer_10 0
wandb: spikes/train_avg_layer_11 0
wandb: spikes/train_avg_layer_12 0
wandb: spikes/train_avg_layer_13 0
wandb: spikes/train_avg_layer_14 0
wandb: spikes/train_avg_layer_15 0
wandb:                       +11 ...
wandb: 
wandb: üöÄ View run ethereal-sweep-200 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/uw28obon
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251125_044610-uw28obon/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    log_model=False,
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

