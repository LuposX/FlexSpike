/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
wandb: Agent Starting Run: 6896yzg4 with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.00018642436829732932
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.8
wandb: Currently logged in as: lupos to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: setting up run 6896yzg4
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_113418-6896yzg4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/6896yzg4
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 4.7 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
4.8 K     Trainable params
0         Non-trainable params
4.8 K     Total params
0.019     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: uploading console lines 42-43
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ‚ñÖ‚ñà‚ñà
wandb:   grad_mean/lif_layers.1 ‚ñà‚ñÑ‚ñÇ‚ñÅ
wandb:   grad_mean/output_layer ‚ñà‚ñÑ‚ñÇ‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:               train_loss ‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 39
wandb:   grad_mean/lif_layers.0 0.00785
wandb:   grad_mean/lif_layers.1 0.00172
wandb:   grad_mean/output_layer 0.16297
wandb:                       lr 0
wandb: spikes/train_avg_layer_0 0.02827
wandb: spikes/train_avg_layer_1 0.01006
wandb:               train_loss 0.1857
wandb:      trainer/global_step 279
wandb:                 val_loss 0.18395
wandb: 
wandb: üöÄ View run copper-sweep-1 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/6896yzg4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_113418-6896yzg4/logs
wandb: Agent Starting Run: 7f7xsvc4 with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 5.148795801676285e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.9
wandb: setting up run 7f7xsvc4
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_114106-7f7xsvc4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lilac-sweep-2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/7f7xsvc4
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 332    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
351       Trainable params
0         Non-trainable params
351       Total params
0.001     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: uploading history steps 82-83, summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                   epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:  grad_mean/lif_layers.0 ‚ñÅ‚ñÅ‚ñÜ‚ñà
wandb:  grad_mean/lif_layers.1 ‚ñá‚ñÅ‚ñà‚ñÖ
wandb: grad_mean/lif_layers.10 ‚ñÑ‚ñÇ‚ñà‚ñÅ
wandb: grad_mean/lif_layers.11 ‚ñÑ‚ñÇ‚ñà‚ñÅ
wandb: grad_mean/lif_layers.12 ‚ñÖ‚ñÉ‚ñà‚ñÅ
wandb: grad_mean/lif_layers.13 ‚ñÖ‚ñÉ‚ñà‚ñÅ
wandb: grad_mean/lif_layers.14 ‚ñÑ‚ñÑ‚ñà‚ñÅ
wandb: grad_mean/lif_layers.15 ‚ñÉ‚ñÉ‚ñà‚ñÅ
wandb:  grad_mean/lif_layers.2 ‚ñÖ‚ñÅ‚ñà‚ñÑ
wandb:                     +28 ...
wandb: 
wandb: Run summary:
wandb:                   epoch 39
wandb:  grad_mean/lif_layers.0 0.00014
wandb:  grad_mean/lif_layers.1 8e-05
wandb: grad_mean/lif_layers.10 0.00126
wandb: grad_mean/lif_layers.11 0.00105
wandb: grad_mean/lif_layers.12 0.00245
wandb: grad_mean/lif_layers.13 0.00345
wandb: grad_mean/lif_layers.14 0.00605
wandb: grad_mean/lif_layers.15 0.0041
wandb:  grad_mean/lif_layers.2 0.00014
wandb:                     +28 ...
wandb: 
wandb: üöÄ View run lilac-sweep-2 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/7f7xsvc4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_114106-7f7xsvc4/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: uuxij427 with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 3.5334968712479883e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.8
wandb: setting up run uuxij427
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_114600-uuxij427
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-sweep-3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/uuxij427
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 13.0 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
13.1 K    Trainable params
0         Non-trainable params
13.1 K    Total params
0.052     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñÅ‚ñÑ‚ñá
wandb: spikes/train_avg_layer_1 ‚ñà‚ñá‚ñá‚ñÅ
wandb: spikes/train_avg_layer_2 ‚ñà‚ñÅ‚ñÉ‚ñÇ
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               train_loss ‚ñà‚ñÜ‚ñÉ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñÜ‚ñÉ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 3
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.0191
wandb: spikes/train_avg_layer_1 0.00088
wandb: spikes/train_avg_layer_2 0.0
wandb: spikes/train_avg_layer_3 0
wandb:               train_loss 0.20695
wandb:      trainer/global_step 27
wandb:                 val_loss 0.20504
wandb: 
wandb: üöÄ View run earnest-sweep-3 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/uuxij427
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_114600-uuxij427/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 153, in run
    self.on_advance_end(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 398, in on_advance_end
    self.val_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 145, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 437, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 412, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 620, in validation_step
    outputs = self(X_batch)
              ^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    lif_out, _states = lif(input_seq)  # lif_out: (T, B, F_hidden)
                       ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 185, in forward
    h_candidate = torch.tanh(preact)
                  ^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: qsc5tsxn with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 7.548890660327252e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.9
wandb: setting up run qsc5tsxn
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_114809-qsc5tsxn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-sweep-4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/qsc5tsxn
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 29.6 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
29.7 K    Trainable params
0         Non-trainable params
29.7 K    Total params
0.119     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception in thread QueueFeederThread:
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1012, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 291, in _feed
    queue_sem.release()
ValueError: semaphore or lock released too many times
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
      Exception ignored in:  ^<function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>^
^Traceback (most recent call last):
^  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    self._shutdown_workers()
    assert self._parent_pid == os.getpid(), 'can only test a child process'
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
           ^^^^^^^^^^^^^^^^^^^^^    ^if w.is_alive():^
^^^ ^ ^ ^ ^ ^ 
 AssertionError^: ^can only test a child process^
^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    Exception ignored in: self._shutdown_workers()
<function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^    ^self._shutdown_workers()^
^^^^  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
^^^^^^^^^^^^^^^    ^^if w.is_alive():^
^
AssertionError :      can only test a child process if w.is_alive():
 
      ^ ^ ^ ^ ^^^^^^^^^^^^^^^^
^  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'^
^^^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^
^AssertionError^: ^can only test a child processException ignored in: ^
^<function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>^
^Traceback (most recent call last):
^  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
^^^^^^^^^^^^^^
AssertionError: can only test a child process
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
    Exception ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620> 
 Traceback (most recent call last):
 ^  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
wandb: updating run metadata
wandb: uploading summary, console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÖ‚ñà‚ñÉ‚ñÅ
wandb: spikes/train_avg_layer_1 ‚ñà‚ñÇ‚ñÅ‚ñÇ
wandb: spikes/train_avg_layer_2 ‚ñá‚ñà‚ñÜ‚ñÅ
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 3
wandb:                       lr 1e-05
wandb: spikes/train_avg_layer_0 0.02057
wandb: spikes/train_avg_layer_1 0.00102
wandb: spikes/train_avg_layer_2 3e-05
wandb: spikes/train_avg_layer_3 0
wandb: spikes/train_avg_layer_4 0
wandb: spikes/train_avg_layer_5 0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run playful-sweep-4 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/qsc5tsxn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_114809-qsc5tsxn/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: 5ekf0127 with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.4170634879496257e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 1
wandb: setting up run 5ekf0127
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_115308-5ekf0127
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/5ekf0127
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 4.7 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
4.8 K     Trainable params
0         Non-trainable params
4.8 K     Total params
0.019     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñá‚ñÉ‚ñÅ‚ñá
wandb: spikes/train_avg_layer_1 ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñà
wandb:               train_loss ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñá‚ñÖ‚ñÇ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 4
wandb:                       lr 1e-05
wandb: spikes/train_avg_layer_0 0.01994
wandb: spikes/train_avg_layer_1 0.00159
wandb:               train_loss 0.30529
wandb:      trainer/global_step 34
wandb:                 val_loss 0.30241
wandb: 
wandb: üöÄ View run kind-sweep-5 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/5ekf0127
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_115308-5ekf0127/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
    outputs = self(X_batch)
              ^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    lif_out, _states = lif(input_seq)  # lif_out: (T, B, F_hidden)
                       ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 167, in forward
    x = self.rho * torch.tanh(i / self.rho)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: nua9eqmj with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 6.382233993479792e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 3
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 1
wandb: setting up run nua9eqmj
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_115411-nua9eqmj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-6
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/nua9eqmj
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 172    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
191       Trainable params
0         Non-trainable params
191       Total params
0.001     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                  epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: grad_mean/lif_layers.0 ‚ñÅ‚ñÜ‚ñà‚ñà
wandb: grad_mean/lif_layers.1 ‚ñà‚ñÅ‚ñÅ‚ñÇ
wandb: grad_mean/lif_layers.2 ‚ñà‚ñÅ‚ñÅ‚ñÇ
wandb: grad_mean/lif_layers.3 ‚ñà‚ñÅ‚ñÅ‚ñÇ
wandb: grad_mean/lif_layers.4 ‚ñà‚ñÇ‚ñÅ‚ñÇ
wandb: grad_mean/lif_layers.5 ‚ñà‚ñÇ‚ñÅ‚ñÇ
wandb: grad_mean/lif_layers.6 ‚ñà‚ñÇ‚ñÅ‚ñÇ
wandb: grad_mean/lif_layers.7 ‚ñà‚ñÇ‚ñÅ‚ñÇ
wandb: grad_mean/output_layer ‚ñà‚ñÇ‚ñÅ‚ñÉ
wandb:                    +12 ...
wandb: 
wandb: Run summary:
wandb:                  epoch 39
wandb: grad_mean/lif_layers.0 0.00237
wandb: grad_mean/lif_layers.1 0.00059
wandb: grad_mean/lif_layers.2 0.00044
wandb: grad_mean/lif_layers.3 0.00063
wandb: grad_mean/lif_layers.4 0.00039
wandb: grad_mean/lif_layers.5 0.00106
wandb: grad_mean/lif_layers.6 0.001
wandb: grad_mean/lif_layers.7 0.00085
wandb: grad_mean/output_layer 0.02616
wandb:                    +12 ...
wandb: 
wandb: üöÄ View run stellar-sweep-6 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/nua9eqmj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_115411-nua9eqmj/logs
wandb: Agent Starting Run: 7ae1lxgc with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.253680762118859e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_115646-7ae1lxgc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-7
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/7ae1lxgc
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 52     | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
71        Trainable params
0         Non-trainable params
71        Total params
0.000     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: uploading console lines 42-43
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ‚ñà‚ñÉ‚ñÅ
wandb:   grad_mean/lif_layers.1 ‚ñÜ‚ñà‚ñÖ‚ñÅ
wandb:   grad_mean/output_layer ‚ñà‚ñà‚ñÉ‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:               train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 39
wandb:   grad_mean/lif_layers.0 0.03858
wandb:   grad_mean/lif_layers.1 0.02738
wandb:   grad_mean/output_layer 0.76337
wandb:                       lr 0
wandb: spikes/train_avg_layer_0 0.0059
wandb: spikes/train_avg_layer_1 9e-05
wandb:               train_loss 0.75394
wandb:      trainer/global_step 279
wandb:                 val_loss 0.74933
wandb: 
wandb: üöÄ View run clear-sweep-7 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/7ae1lxgc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_115646-7ae1lxgc/logs
wandb: Agent Starting Run: afjwmzsy with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 4.463874992693854e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 1
wandb: setting up run afjwmzsy
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_115737-afjwmzsy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-8
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/afjwmzsy
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 4.7 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
4.8 K     Trainable params
0         Non-trainable params
4.8 K     Total params
0.019     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading history steps 18-19, summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:                       lr ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñà
wandb:               train_loss ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 9
wandb:                       lr 4e-05
wandb: spikes/train_avg_layer_0 0.01789
wandb: spikes/train_avg_layer_1 0.0008
wandb:               train_loss 0.21987
wandb:      trainer/global_step 69
wandb:                 val_loss 0.21767
wandb: 
wandb: üöÄ View run flowing-sweep-8 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/afjwmzsy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_115737-afjwmzsy/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: ysmgdt1g with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.984605607322757e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_115911-ysmgdt1g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-9
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/ysmgdt1g
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 944    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
975       Trainable params
0         Non-trainable params
975       Total params
0.004     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                       lr ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ
wandb: spikes/train_avg_layer_1 ‚ñÖ‚ñÑ‚ñá‚ñÜ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÇ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_2 ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà
wandb:               train_loss ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 10
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.02348
wandb: spikes/train_avg_layer_1 0.00189
wandb: spikes/train_avg_layer_2 0.00023
wandb: spikes/train_avg_layer_3 1e-05
wandb:               train_loss 0.42853
wandb:      trainer/global_step 76
wandb:                 val_loss 0.42514
wandb: 
wandb: üöÄ View run chocolate-sweep-9 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/ysmgdt1g
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_115911-ysmgdt1g/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
    outputs = self(X_batch)
              ^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    lif_out, _states = lif(input_seq)  # lif_out: (T, B, F_hidden)
                       ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 171, in forward
    h_prev = h.detach()
             ^^^^^^^^^^
Exception

wandb: Agent Starting Run: r15w2nhx with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.411683053959495e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 3
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.9
wandb: setting up run r15w2nhx
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_120008-r15w2nhx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-10
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/r15w2nhx
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 52     | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
71        Trainable params
0         Non-trainable params
71        Total params
0.000     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: uploading history steps 76-83, summary, console lines 42-45
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ‚ñÅ‚ñÑ‚ñà
wandb:   grad_mean/lif_layers.1 ‚ñÉ‚ñà‚ñÖ‚ñÅ
wandb:   grad_mean/output_layer ‚ñÅ‚ñà‚ñÑ‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:               train_loss ‚ñà‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:                 val_loss ‚ñà‚ñá‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 39
wandb:   grad_mean/lif_layers.0 0.00499
wandb:   grad_mean/lif_layers.1 0.023
wandb:   grad_mean/output_layer 0.54563
wandb:                       lr 0
wandb: spikes/train_avg_layer_0 0.02189
wandb: spikes/train_avg_layer_1 0.01023
wandb:               train_loss 0.45103
wandb:      trainer/global_step 279
wandb:                 val_loss 0.44756
wandb: 
wandb: üöÄ View run lucky-sweep-10 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/r15w2nhx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_120008-r15w2nhx/logs
wandb: Agent Starting Run: ausud55z with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 9.074280975665308e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 1
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.9
wandb: setting up run ausud55z
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_120100-ausud55z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-11
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/ausud55z
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 944    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
975       Trainable params
0         Non-trainable params
975       Total params
0.004     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: uploading history steps 20-25, console lines 40-40; updating run metadata
wandb: uploading summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                       lr ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñÜ
wandb: spikes/train_avg_layer_1 ‚ñÉ‚ñÅ‚ñÉ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñá
wandb: spikes/train_avg_layer_2 ‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñà
wandb: spikes/train_avg_layer_3 ‚ñá‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:               train_loss ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 12
wandb:                       lr 1e-05
wandb: spikes/train_avg_layer_0 0.03814
wandb: spikes/train_avg_layer_1 0.00681
wandb: spikes/train_avg_layer_2 0.001
wandb: spikes/train_avg_layer_3 0.0
wandb:               train_loss 0.37674
wandb:      trainer/global_step 90
wandb:                 val_loss 0.37358
wandb: 
wandb: üöÄ View run dutiful-sweep-11 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/ausud55z
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_120100-ausud55z/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
    outputs = self(X_batch)
              ^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    lif_out, _states = lif(input_seq)  # lif_out: (T, B, F_hidden)
                       ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 167, in forward
    x = self.rho * torch.tanh(i / self.rho)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: 7cm3hrkn with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.6029453903934532e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_120207-7cm3hrkn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-12
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/7cm3hrkn
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 29.6 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
29.7 K    Trainable params
0         Non-trainable params
29.7 K    Total params
0.119     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñà‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_1 ‚ñà‚ñÑ‚ñÜ‚ñÅ
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÅ‚ñà‚ñá
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 3
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.02006
wandb: spikes/train_avg_layer_1 0.00139
wandb: spikes/train_avg_layer_2 4e-05
wandb: spikes/train_avg_layer_3 0
wandb: spikes/train_avg_layer_4 0
wandb: spikes/train_avg_layer_5 0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run laced-sweep-12 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/7cm3hrkn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_120207-7cm3hrkn/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: pun80zd6 with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 6.7931200572818405e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.8
wandb: setting up run pun80zd6
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_120609-pun80zd6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-13
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/pun80zd6
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 248 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
248 K     Trainable params
0         Non-trainable params
248 K     Total params
0.995     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading summary
wandb: 
wandb: Run history:
wandb:                     epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                        lr ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ
wandb:  spikes/train_avg_layer_0 ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñà
wandb:  spikes/train_avg_layer_1 ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà
wandb: spikes/train_avg_layer_10 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_11 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_12 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_13 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_14 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_15 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +11 ...
wandb: 
wandb: Run summary:
wandb:                     epoch 12
wandb:                        lr 1e-05
wandb:  spikes/train_avg_layer_0 0.02069
wandb:  spikes/train_avg_layer_1 0.00116
wandb: spikes/train_avg_layer_10 0
wandb: spikes/train_avg_layer_11 0
wandb: spikes/train_avg_layer_12 0
wandb: spikes/train_avg_layer_13 0
wandb: spikes/train_avg_layer_14 0
wandb: spikes/train_avg_layer_15 0
wandb:                       +11 ...
wandb: 
wandb: üöÄ View run revived-sweep-13 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/pun80zd6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_120609-pun80zd6/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: v9p3u7od with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.7244834381203388e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 1
wandb: setting up run v9p3u7od
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_125908-v9p3u7od
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-14
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/v9p3u7od
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 944    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
975       Trainable params
0         Non-trainable params
975       Total params
0.004     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÉ‚ñÅ‚ñà‚ñÖ
wandb:   grad_mean/lif_layers.1 ‚ñÖ‚ñÅ‚ñà‚ñÑ
wandb:   grad_mean/lif_layers.2 ‚ñÖ‚ñÅ‚ñà‚ñÑ
wandb:   grad_mean/lif_layers.3 ‚ñÖ‚ñÅ‚ñà‚ñÉ
wandb:   grad_mean/output_layer ‚ñÑ‚ñÅ‚ñà‚ñÑ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: spikes/train_avg_layer_1 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: spikes/train_avg_layer_2 ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +4 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 39
wandb:   grad_mean/lif_layers.0 0.00571
wandb:   grad_mean/lif_layers.1 0.00274
wandb:   grad_mean/lif_layers.2 0.00251
wandb:   grad_mean/lif_layers.3 0.00246
wandb:   grad_mean/output_layer 0.15046
wandb:                       lr 0
wandb: spikes/train_avg_layer_0 0.02464
wandb: spikes/train_avg_layer_1 0.00302
wandb: spikes/train_avg_layer_2 0.0003
wandb:                       +4 ...
wandb: 
wandb: üöÄ View run bright-sweep-14 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/v9p3u7od
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_125908-v9p3u7od/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: m665lmnt with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.00022113613859836567
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_130234-m665lmnt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-15
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/m665lmnt
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 2.0 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
2.1 K     Trainable params
0         Non-trainable params
2.1 K     Total params
0.008     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading history steps 16-17, summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:                       lr ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñá‚ñà‚ñÖ‚ñÑ‚ñÑ
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 8
wandb:                       lr 0.00019
wandb: spikes/train_avg_layer_0 0.02415
wandb: spikes/train_avg_layer_1 0.00217
wandb: spikes/train_avg_layer_2 0.00018
wandb: spikes/train_avg_layer_3 0
wandb: spikes/train_avg_layer_4 0
wandb: spikes/train_avg_layer_5 0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run pleasant-sweep-15 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/m665lmnt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_130234-m665lmnt/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 153, in run
    self.on_advance_end(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 398, in on_advance_end
    self.val_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 145, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 437, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 412, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 620, in validation_step
    outputs = self(X_batch)
              ^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    lif_out, _states = lif(input_seq)  # lif_out: (T, B, F_hidden)
                       ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 189, in forward
    hs = zs * hs_prev + (1.0 - zs) * h_prev
                         ~~~~^~~~
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 38, in wrapped
    @functools.wraps(f)
    
Exception

wandb: Agent Starting Run: h7lyntqr with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 3.787085466885639e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.9
wandb: setting up run h7lyntqr
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_130407-h7lyntqr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-16
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/h7lyntqr
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 172    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
191       Trainable params
0         Non-trainable params
191       Total params
0.001     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
<function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
    self._shutdown_workers()  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers

  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    self._shutdown_workers()
    if w.is_alive():  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers

       ^^^^^^    ^^if w.is_alive():^
^^^ 
   File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
     ^^^^^^^^^^^^    
if w.is_alive():  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive

       ^^^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^
^^ ^ ^ ^ ^ 
   File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
     ^^^    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'^
^^^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'^^
^^^^ ^^ ^^ ^^ ^^ 
^ AssertionError^ : ^ can only test a child process^ 
^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^
^AssertionError^: ^can only test a child process^
^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception in thread QueueFeederThreadTraceback (most recent call last):
:
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^    ^self.run()^
^^^^  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1012, in run
^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
    self._target(*self._args, **self._kwargs)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 291, in _feed
    queue_sem.release()
ValueError: semaphore or lock released too many times
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
        if w.is_alive():if w.is_alive():

              ^^^^^^^^^^^^^^^^^^^^    ^^self._shutdown_workers()^^


  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           if w.is_alive():     
 assert self._parent_pid == os.getpid(), 'can only test a child process'  
  ^  ^  ^  ^  ^  ^ ^^ ^^ ^^ ^^ ^^ ^^^^^^^^^^^^^^^^^^^^^
^^  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
^^^^^^^^^^^^^^^^^^^^^^^^Exception ignored in: 
^AssertionError<function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>^: 
^can only test a child processTraceback (most recent call last):
^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
^^^^^^^
AssertionError: can only test a child process
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^    ^self._shutdown_workers()^
^^^^  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
^^^^^^^^
AssertionError: can only test a child process
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
OSError: [Errno 9] Bad file descriptor
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Traceback (most recent call last):
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()

  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
OSError: [Errno 9] Bad file descriptor
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                  epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: grad_mean/lif_layers.0 ‚ñÅ
wandb: grad_mean/lif_layers.1 ‚ñÅ
wandb: grad_mean/lif_layers.2 ‚ñÅ
wandb: grad_mean/lif_layers.3 ‚ñÅ
wandb: grad_mean/lif_layers.4 ‚ñÅ
wandb: grad_mean/lif_layers.5 ‚ñÅ
wandb: grad_mean/lif_layers.6 ‚ñÅ
wandb: grad_mean/lif_layers.7 ‚ñÅ
wandb: grad_mean/output_layer ‚ñÅ
wandb:                    +12 ...
wandb: 
wandb: Run summary:
wandb:                  epoch 18
wandb: grad_mean/lif_layers.0 0.00203
wandb: grad_mean/lif_layers.1 0.0027
wandb: grad_mean/lif_layers.2 0.00317
wandb: grad_mean/lif_layers.3 0.0046
wandb: grad_mean/lif_layers.4 0.00623
wandb: grad_mean/lif_layers.5 0.01138
wandb: grad_mean/lif_layers.6 0.01149
wandb: grad_mean/lif_layers.7 0.00836
wandb: grad_mean/output_layer 0.23066
wandb:                    +12 ...
wandb: 
wandb: üöÄ View run polished-sweep-16 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/h7lyntqr
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_130407-h7lyntqr/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 153, in run
    self.on_advance_end(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 398, in on_advance_end
    self.val_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 145, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 437, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 412, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 620, in validation_step
    outputs = self(X_batch)
              ^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    lif_out, _states = lif(input_seq)  # lif_out: (T, B, F_hidden)
                       ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 167, in forward
    x = self.rho * torch.tanh(i / self.rho)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: z4ov41aw with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 3.10385970233246e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.9
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_130611-z4ov41aw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-17
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/z4ov41aw
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 116 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
116 K     Trainable params
0         Non-trainable params
116 K     Total params
0.467     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Exception in thread QueueFeederThread:
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1012, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 291, in _feed
    queue_sem.release()
ValueError: semaphore or lock released too many times
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÉ‚ñÜ‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÑ‚ñÅ‚ñÑ‚ñà
wandb: spikes/train_avg_layer_2 ‚ñá‚ñà‚ñÜ‚ñÅ
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 3
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.02263
wandb: spikes/train_avg_layer_1 0.00188
wandb: spikes/train_avg_layer_2 5e-05
wandb: spikes/train_avg_layer_3 0
wandb: spikes/train_avg_layer_4 0
wandb: spikes/train_avg_layer_5 0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run desert-sweep-17 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/z4ov41aw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_130611-z4ov41aw/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: 29z6t2wt with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.531818437354374e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.9
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_131410-29z6t2wt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-18
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/29z6t2wt
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 17.5 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
17.7 K    Trainable params
0         Non-trainable params
17.7 K    Total params
0.071     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
<function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>Traceback (most recent call last):

  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^Exception ignored in: ^^^^<function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>^
^^Traceback (most recent call last):
^  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
^^^^^^^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^
^^^ ^ ^ ^ ^ ^ ^ ^ ^ ^ 
 AssertionError^: ^can only test a child process^
^^^^^    ^self._shutdown_workers()^
^^^  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
 Exception ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620> 
 Traceback (most recent call last):
   File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
   ^^^^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^
^^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^    ^^
self._shutdown_workers()^AssertionError
^: ^can only test a child process^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
^^^^^^^^^^^^^^^
AssertionError: can only test a child process
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
wandb: updating run metadata
wandb: uploading console lines 52-52
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ
wandb:   grad_mean/lif_layers.1 ‚ñÅ
wandb:   grad_mean/output_layer ‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñà‚ñà
wandb:               train_loss ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 14
wandb:   grad_mean/lif_layers.0 0.0038
wandb:   grad_mean/lif_layers.1 0.00178
wandb:   grad_mean/output_layer 0.20423
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.02017
wandb: spikes/train_avg_layer_1 0.00137
wandb:               train_loss 0.201
wandb:      trainer/global_step 99
wandb:                 val_loss 0.19913
wandb: 
wandb: üöÄ View run frosty-sweep-18 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/29z6t2wt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_131410-29z6t2wt/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
    outputs = self(X_batch)
              ^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    lif_out, _states = lif(input_seq)  # lif_out: (T, B, F_hidden)
                       ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 171, in forward
    h_prev = h.detach()
             ^^^^^^^^^^
Exception

wandb: Agent Starting Run: 14c0rjzz with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 5.309096352338182e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 3
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_132011-14c0rjzz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-sweep-19
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/14c0rjzz
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 29.6 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
29.7 K    Trainable params
0         Non-trainable params
29.7 K    Total params
0.119     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñÑ‚ñÅ‚ñÜ‚ñÖ
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÇ‚ñÅ‚ñà‚ñá
wandb: spikes/train_avg_layer_2 ‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñà
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 4
wandb:                       lr 5e-05
wandb: spikes/train_avg_layer_0 0.01914
wandb: spikes/train_avg_layer_1 0.00119
wandb: spikes/train_avg_layer_2 1e-05
wandb: spikes/train_avg_layer_3 0
wandb: spikes/train_avg_layer_4 0
wandb: spikes/train_avg_layer_5 0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run charmed-sweep-19 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/14c0rjzz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_132011-14c0rjzz/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: d2go79t1 with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 2.1063948574057957e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.8
wandb: setting up run d2go79t1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_132408-d2go79t1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-20
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/d2go79t1
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 332    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
351       Trainable params
0         Non-trainable params
351       Total params
0.001     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: uploading history steps 82-83, summary, console lines 43-45
wandb: 
wandb: Run history:
wandb:                   epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:  grad_mean/lif_layers.0 ‚ñà‚ñÅ‚ñÑ‚ñÉ
wandb:  grad_mean/lif_layers.1 ‚ñÅ‚ñÖ‚ñÜ‚ñà
wandb: grad_mean/lif_layers.10 ‚ñÅ‚ñá‚ñÜ‚ñà
wandb: grad_mean/lif_layers.11 ‚ñÅ‚ñá‚ñÜ‚ñà
wandb: grad_mean/lif_layers.12 ‚ñÅ‚ñá‚ñÜ‚ñà
wandb: grad_mean/lif_layers.13 ‚ñÅ‚ñá‚ñÜ‚ñà
wandb: grad_mean/lif_layers.14 ‚ñÅ‚ñá‚ñÜ‚ñà
wandb: grad_mean/lif_layers.15 ‚ñÅ‚ñà‚ñÜ‚ñà
wandb:  grad_mean/lif_layers.2 ‚ñÅ‚ñÖ‚ñÜ‚ñà
wandb:                     +28 ...
wandb: 
wandb: Run summary:
wandb:                   epoch 39
wandb:  grad_mean/lif_layers.0 2e-05
wandb:  grad_mean/lif_layers.1 1e-05
wandb: grad_mean/lif_layers.10 0.00154
wandb: grad_mean/lif_layers.11 0.00248
wandb: grad_mean/lif_layers.12 0.00371
wandb: grad_mean/lif_layers.13 0.00291
wandb: grad_mean/lif_layers.14 0.00311
wandb: grad_mean/lif_layers.15 0.00311
wandb:  grad_mean/lif_layers.2 1e-05
wandb:                     +28 ...
wandb: 
wandb: üöÄ View run drawn-sweep-20 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/d2go79t1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_132408-d2go79t1/logs
wandb: Agent Starting Run: 51k9gtkp with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 2.856973614391325e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 1
wandb: setting up run 51k9gtkp
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_132903-51k9gtkp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-21
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/51k9gtkp
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 52     | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
71        Trainable params
0         Non-trainable params
71        Total params
0.000     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: uploading history steps 82-83, summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñá‚ñÜ‚ñÅ‚ñà
wandb:   grad_mean/lif_layers.1 ‚ñà‚ñÜ‚ñÅ‚ñÑ
wandb:   grad_mean/output_layer ‚ñà‚ñÅ‚ñá‚ñÉ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÜ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb: spikes/train_avg_layer_1 ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:               train_loss ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 39
wandb:   grad_mean/lif_layers.0 0.0217
wandb:   grad_mean/lif_layers.1 0.01868
wandb:   grad_mean/output_layer 0.74235
wandb:                       lr 0
wandb: spikes/train_avg_layer_0 0.00824
wandb: spikes/train_avg_layer_1 0.00388
wandb:               train_loss 0.71132
wandb:      trainer/global_step 279
wandb:                 val_loss 0.70686
wandb: 
wandb: üöÄ View run still-sweep-21 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/51k9gtkp
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_132903-51k9gtkp/logs
wandb: Agent Starting Run: 8makozzh with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.1207619391436483e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_132954-8makozzh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-22
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/8makozzh
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 29.6 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
29.7 K    Trainable params
0         Non-trainable params
29.7 K    Total params
0.119     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                       lr ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñá‚ñà‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñá‚ñà‚ñá‚ñÇ‚ñÅ‚ñÇ
wandb: spikes/train_avg_layer_1 ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñá‚ñà‚ñà‚ñÜ‚ñá‚ñà‚ñà
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 12
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.01791
wandb: spikes/train_avg_layer_1 0.00151
wandb: spikes/train_avg_layer_2 4e-05
wandb: spikes/train_avg_layer_3 0
wandb: spikes/train_avg_layer_4 0
wandb: spikes/train_avg_layer_5 0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run glorious-sweep-22 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/8makozzh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_132954-8makozzh/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: jjk63jeh with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 8.504383935848153e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 3
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_133911-jjk63jeh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-23
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/jjk63jeh
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 4.7 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
4.8 K     Trainable params
0         Non-trainable params
4.8 K     Total params
0.019     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÅ
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñà
wandb:               train_loss ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 4
wandb:                       lr 1e-05
wandb: spikes/train_avg_layer_0 0.01982
wandb: spikes/train_avg_layer_1 0.00096
wandb:               train_loss 0.3007
wandb:      trainer/global_step 34
wandb:                 val_loss 0.29794
wandb: 
wandb: üöÄ View run summer-sweep-23 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/jjk63jeh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_133911-jjk63jeh/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 315, in apply
    return user_fn(self, *args)
           ^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 61, in backward
    grad_input = grad_output.clone()
                 ^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: vjnrziuh with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.7223290429565332e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 0.8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_134008-vjnrziuh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-24
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/vjnrziuh
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 13.0 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
13.1 K    Trainable params
0         Non-trainable params
13.1 K    Total params
0.052     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading history steps 8-9, summary, console lines 43-44
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÜ‚ñá‚ñà‚ñà
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               train_loss ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 4
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.0211
wandb: spikes/train_avg_layer_1 0.00153
wandb: spikes/train_avg_layer_2 4e-05
wandb: spikes/train_avg_layer_3 0
wandb:               train_loss 0.30324
wandb:      trainer/global_step 34
wandb:                 val_loss 0.30053
wandb: 
wandb: üöÄ View run worldly-sweep-24 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/vjnrziuh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_134008-vjnrziuh/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
    outputs = self(X_batch)
              ^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    lif_out, _states = lif(input_seq)  # lif_out: (T, B, F_hidden)
                       ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 192, in forward
    sout_t = self._relu(h)
             ^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 565, in apply
    @classmethod
    
Exception

wandb: Agent Starting Run: ghkzu6ht with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 5.965415708716437e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 3
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 1
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_134207-ghkzu6ht
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-25
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/ghkzu6ht
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 116 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
116 K     Trainable params
0         Non-trainable params
116 K     Total params
0.467     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÑ‚ñÅ‚ñÇ‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÉ‚ñÜ‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÇ‚ñÑ‚ñà
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 3
wandb:                       lr 1e-05
wandb: spikes/train_avg_layer_0 0.0194
wandb: spikes/train_avg_layer_1 0.00176
wandb: spikes/train_avg_layer_2 6e-05
wandb: spikes/train_avg_layer_3 0
wandb: spikes/train_avg_layer_4 0
wandb: spikes/train_avg_layer_5 0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run sleek-sweep-25 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/ghkzu6ht
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_134207-ghkzu6ht/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
    outputs = self(X_batch)
              ^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    lif_out, _states = lif(input_seq)  # lif_out: (T, B, F_hidden)
                       ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 163, in forward
    delta = torch.matmul(sin_t, self.Ws.t())  # (batch, hidden)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: ed1r6v04 with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.0001139428731626579
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 1
wandb: setting up run ed1r6v04
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_135012-ed1r6v04
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-26
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/ed1r6v04
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 92     | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
111       Trainable params
0         Non-trainable params
111       Total params
0.000     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-44
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ
wandb:   grad_mean/lif_layers.1 ‚ñÅ
wandb:   grad_mean/lif_layers.2 ‚ñÅ
wandb:   grad_mean/lif_layers.3 ‚ñÅ
wandb:   grad_mean/output_layer ‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +4 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 18
wandb:   grad_mean/lif_layers.0 0.00971
wandb:   grad_mean/lif_layers.1 0.00941
wandb:   grad_mean/lif_layers.2 0.00808
wandb:   grad_mean/lif_layers.3 0.00981
wandb:   grad_mean/output_layer 0.19686
wandb:                       lr 6e-05
wandb: spikes/train_avg_layer_0 0.01526
wandb: spikes/train_avg_layer_1 0.0051
wandb: spikes/train_avg_layer_2 0
wandb:                       +4 ...
wandb: 
wandb: üöÄ View run sweepy-sweep-26 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/ed1r6v04
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_135012-ed1r6v04/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 131, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 319, in _training_step
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 391, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 567, in training_step
    outputs = self(X_batch)
              ^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    lif_out, _states = lif(input_seq)  # lif_out: (T, B, F_hidden)
                       ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 189, in forward
    hs = zs * hs_prev + (1.0 - zs) * h_prev
                         ~~~~^~~~
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 45, in wrapped
    return f(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 1075, in __rsub__
    return _C._VariableFunctions.rsub(self, other)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: gw05rx5y with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 2.2612752707444608e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 3
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.9
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_135110-gw05rx5y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-sweep-27
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/gw05rx5y
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 400    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
431       Trainable params
0         Non-trainable params
431       Total params
0.002     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1618, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/popen_fork.py", line 40, in wait
    if not wait([self.sentinel], timeout):
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 1136, in wait
    ready = selector.select(timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Exception: 
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: uploading console lines 42-62
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÖ‚ñÅ‚ñà‚ñÇ
wandb:   grad_mean/lif_layers.1 ‚ñÜ‚ñÑ‚ñà‚ñÅ
wandb:   grad_mean/output_layer ‚ñÜ‚ñÖ‚ñà‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: spikes/train_avg_layer_1 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 39
wandb:   grad_mean/lif_layers.0 0.02021
wandb:   grad_mean/lif_layers.1 0.00775
wandb:   grad_mean/output_layer 0.35237
wandb:                       lr 0
wandb: spikes/train_avg_layer_0 0.01756
wandb: spikes/train_avg_layer_1 0.0009
wandb:               train_loss 0.29137
wandb:      trainer/global_step 279
wandb:                 val_loss 0.28875
wandb: 
wandb: üöÄ View run wise-sweep-27 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/gw05rx5y
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_135110-gw05rx5y/logs
wandb: Agent Starting Run: db3bhatm with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.675936357322927e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: True
wandb: 	rho: 1
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.8
wandb: setting up run db3bhatm
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_135251-db3bhatm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-28
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/db3bhatm
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 400    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
431       Trainable params
0         Non-trainable params
431       Total params
0.002     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading history steps 52-62, summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ‚ñà‚ñá
wandb:   grad_mean/lif_layers.1 ‚ñÅ‚ñÜ‚ñà
wandb:   grad_mean/output_layer ‚ñÅ‚ñÖ‚ñà
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb: spikes/train_avg_layer_1 ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ
wandb:               train_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 29
wandb:   grad_mean/lif_layers.0 0.01089
wandb:   grad_mean/lif_layers.1 0.0099
wandb:   grad_mean/output_layer 0.35366
wandb:                       lr 0.0
wandb: spikes/train_avg_layer_0 0.02822
wandb: spikes/train_avg_layer_1 0.00248
wandb:               train_loss 0.28358
wandb:      trainer/global_step 209
wandb:                 val_loss 0.28099
wandb: 
wandb: üöÄ View run pleasant-sweep-28 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/db3bhatm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_135251-db3bhatm/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 315, in apply
    return user_fn(self, *args)
           ^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 61, in backward
    grad_input = grad_output.clone()
                 ^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: hjsthmre with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 2.6981889194336622e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_135411-hjsthmre
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-29
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/hjsthmre
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 52     | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
71        Trainable params
0         Non-trainable params
71        Total params
0.000     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: uploading history steps 76-83, summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÑ‚ñà‚ñÅ‚ñà
wandb:   grad_mean/lif_layers.1 ‚ñÅ‚ñÉ‚ñÑ‚ñà
wandb:   grad_mean/output_layer ‚ñÇ‚ñÅ‚ñÖ‚ñà
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: spikes/train_avg_layer_1 ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ
wandb:               train_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 39
wandb:   grad_mean/lif_layers.0 0.02904
wandb:   grad_mean/lif_layers.1 0.02924
wandb:   grad_mean/output_layer 0.75682
wandb:                       lr 0
wandb: spikes/train_avg_layer_0 0.03
wandb: spikes/train_avg_layer_1 0.00288
wandb:               train_loss 0.7295
wandb:      trainer/global_step 279
wandb:                 val_loss 0.72496
wandb: 
wandb: üöÄ View run lucky-sweep-29 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/hjsthmre
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_135411-hjsthmre/logs
wandb: Agent Starting Run: bjq2xjnh with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 1.939277197184247e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 3
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.1
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_135508-bjq2xjnh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run driven-sweep-30
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/bjq2xjnh
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 248 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
248 K     Trainable params
0         Non-trainable params
248 K     Total params
0.995     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                     epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                        lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb:  spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÖ‚ñà
wandb:  spikes/train_avg_layer_1 ‚ñÜ‚ñá‚ñà‚ñÅ
wandb: spikes/train_avg_layer_10 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_11 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_12 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_13 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_14 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_15 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +11 ...
wandb: 
wandb: Run summary:
wandb:                     epoch 3
wandb:                        lr 0.0
wandb:  spikes/train_avg_layer_0 0.01999
wandb:  spikes/train_avg_layer_1 0.00162
wandb: spikes/train_avg_layer_10 0
wandb: spikes/train_avg_layer_11 0
wandb: spikes/train_avg_layer_12 0
wandb: spikes/train_avg_layer_13 0
wandb: spikes/train_avg_layer_14 0
wandb: spikes/train_avg_layer_15 0
wandb:                       +11 ...
wandb: 
wandb: üöÄ View run driven-sweep-30 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/bjq2xjnh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_135508-bjq2xjnh/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: qrbdcj35 with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 4.474401741012071e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 4
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 3
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.8
wandb: setting up run qrbdcj35
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_141209-qrbdcj35
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-31
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/qrbdcj35
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 944    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
975       Trainable params
0         Non-trainable params
975       Total params
0.004     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÇ‚ñÅ‚ñà‚ñà
wandb:   grad_mean/lif_layers.1 ‚ñÅ‚ñÉ‚ñà‚ñÜ
wandb:   grad_mean/lif_layers.2 ‚ñÅ‚ñÉ‚ñà‚ñÖ
wandb:   grad_mean/lif_layers.3 ‚ñÅ‚ñÇ‚ñà‚ñÖ
wandb:   grad_mean/output_layer ‚ñÅ‚ñÉ‚ñà‚ñÖ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÇ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà
wandb: spikes/train_avg_layer_1 ‚ñà‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_2 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +4 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 39
wandb:   grad_mean/lif_layers.0 0.00503
wandb:   grad_mean/lif_layers.1 0.00122
wandb:   grad_mean/lif_layers.2 0.00072
wandb:   grad_mean/lif_layers.3 0.0012
wandb:   grad_mean/output_layer 0.05421
wandb:                       lr 0
wandb: spikes/train_avg_layer_0 0.02035
wandb: spikes/train_avg_layer_1 0.00056
wandb: spikes/train_avg_layer_2 0.0
wandb:                       +4 ...
wandb: 
wandb: üöÄ View run upbeat-sweep-31 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/qrbdcj35
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_141209-qrbdcj35/logs
wandb: Agent Starting Run: qe85q1pm with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.00022769145095116795
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 16
wandb: 	num_hidden_layers: 2
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.8
wandb: setting up run qe85q1pm
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_141530-qe85q1pm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-32
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/qe85q1pm
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 400    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 17     | train
--------------------------------------------------------
431       Trainable params
0         Non-trainable params
431       Total params
0.002     Total estimated model params size (MB)
12        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading console lines 42-42
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:   grad_mean/lif_layers.0 ‚ñÅ
wandb:   grad_mean/lif_layers.1 ‚ñÅ
wandb:   grad_mean/output_layer ‚ñÅ
wandb:                       lr ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà
wandb:               train_loss ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb:      trainer/global_step ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                 val_loss ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                    epoch 14
wandb:   grad_mean/lif_layers.0 0.0221
wandb:   grad_mean/lif_layers.1 0.00949
wandb:   grad_mean/output_layer 0.37295
wandb:                       lr 0.00017
wandb: spikes/train_avg_layer_0 0.02196
wandb: spikes/train_avg_layer_1 0.00189
wandb:               train_loss 0.30108
wandb:      trainer/global_step 99
wandb:                 val_loss 0.29753
wandb: 
wandb: üöÄ View run stilted-sweep-32 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/qe85q1pm
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_141530-qe85q1pm/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 153, in run
    self.on_advance_end(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 398, in on_advance_end
    self.val_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 145, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 437, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 412, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 620, in validation_step
    outputs = self(X_batch)
              ^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/RSNN.py", line 507, in forward
    lif_out, _states = lif(input_seq)  # lif_out: (T, B, F_hidden)
                       ^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/utils/src_cell.py", line 163, in forward
    delta = torch.matmul(sin_t, self.Ws.t())  # (batch, hidden)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Exception

wandb: Agent Starting Run: rzwhw5w2 with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 5.641032030208905e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 4
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -5
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0.2
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.9
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_141611-rzwhw5w2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-sweep-33
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/rzwhw5w2
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 332    | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 5      | train
--------------------------------------------------------
351       Trainable params
0         Non-trainable params
351       Total params
0.001     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
Exception ignored in:         <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>self._shutdown_workers()if w.is_alive():


Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
     ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
          assert self._parent_pid == os.getpid(), 'can only test a child process' 
^^ ^ ^ ^ ^ ^ ^ ^     ^if w.is_alive(): ^
 ^  
^   File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^
^  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
^^^^^^^^^^^
AssertionError:     can only test a child processassert self._parent_pid == os.getpid(), 'can only test a child process'

             assert self._parent_pid == os.getpid(), 'can only test a child process' 
 ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
^AssertionError^: ^can only test a child process^
^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
Exception in thread QueueFeederThread:
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
Traceback (most recent call last):
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/threading.py", line 1012, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 291, in _feed
    Traceback (most recent call last):
queue_sem.release()
ValueError: semaphore or lock released too many times
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
Exception ignored in:   File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
<function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>    
self._shutdown_workers()Traceback (most recent call last):

  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^    ^^self._shutdown_workers()^Exception ignored in: 
^<function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>^
    ^Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
if w.is_alive():^  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__

^^ 
   File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
     ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    if w.is_alive():
       ^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^
^^ ^     ^assert self._parent_pid == os.getpid(), 'can only test a child process' ^    
 ^self._shutdown_workers() ^ 
 ^  ^  
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
     ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    ^^    assert self._parent_pid == os.getpid(), 'can only test a child process'^^if w.is_alive():
^^
^^ ^ ^ ^ ^ ^ ^ ^ 
 ^ AssertionError ^ :  ^ can only test a child process ^^
 
^ AssertionError^ : ^^can only test a child process^^
^^^^^^^^^^^^^^
^  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
OSError: [Errno 9] Bad file descriptor
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x14c1dd409620>
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1654, in __del__
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    self._shutdown_workers()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1637, in _shutdown_workers
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    if w.is_alive():
       ^^^^^^^^^^^^
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/process.py", line 160, in is_alive
    assert self._parent_pid == os.getpid(), 'can only test a child process'
           ^^^^^^^^^^^^^^^^^^^^^^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^
^^^ ^ ^ ^ 
 AssertionError :  can only test a child process 
   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: can only test a child process
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
Traceback (most recent call last):
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/queues.py", line 259, in _feed
    reader_close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 178, in close
    self._close()
  File "/opt/bwhpc/common/devel/miniforge/25.3.1-py3.12/lib/python3.12/multiprocessing/connection.py", line 377, in _close
    _close(self._handle)
OSError: [Errno 9] Bad file descriptor
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: uploading console lines 52-52
wandb: 
wandb: Run history:
wandb:                   epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:  grad_mean/lif_layers.0 ‚ñà‚ñÜ‚ñÅ‚ñÉ
wandb:  grad_mean/lif_layers.1 ‚ñà‚ñÜ‚ñÅ‚ñÖ
wandb: grad_mean/lif_layers.10 ‚ñÅ‚ñÅ‚ñÖ‚ñà
wandb: grad_mean/lif_layers.11 ‚ñÇ‚ñÅ‚ñÜ‚ñà
wandb: grad_mean/lif_layers.12 ‚ñÉ‚ñÅ‚ñÜ‚ñà
wandb: grad_mean/lif_layers.13 ‚ñÑ‚ñÅ‚ñá‚ñà
wandb: grad_mean/lif_layers.14 ‚ñÑ‚ñÅ‚ñá‚ñà
wandb: grad_mean/lif_layers.15 ‚ñÑ‚ñÅ‚ñá‚ñà
wandb:  grad_mean/lif_layers.2 ‚ñà‚ñÑ‚ñÅ‚ñà
wandb:                     +28 ...
wandb: 
wandb: Run summary:
wandb:                   epoch 39
wandb:  grad_mean/lif_layers.0 0.0004
wandb:  grad_mean/lif_layers.1 0.00012
wandb: grad_mean/lif_layers.10 0.00157
wandb: grad_mean/lif_layers.11 0.00111
wandb: grad_mean/lif_layers.12 0.0027
wandb: grad_mean/lif_layers.13 0.0027
wandb: grad_mean/lif_layers.14 0.00211
wandb: grad_mean/lif_layers.15 0.00275
wandb:  grad_mean/lif_layers.2 0.00014
wandb:                     +28 ...
wandb: 
wandb: üöÄ View run worthy-sweep-33 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/rzwhw5w2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_141611-rzwhw5w2/logs
wandb: Agent Starting Run: psa6tyfb with config:
wandb: 	alpha: 0.85
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: True
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 3.218982456974211e-05
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 64
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 3
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.1
wandb: 	zhyp_s: 0.8
wandb: setting up run psa6tyfb
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_142136-psa6tyfb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-34
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/psa6tyfb
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 29.6 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
29.7 K    Trainable params
0         Non-trainable params
29.7 K    Total params
0.119     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
wandb: updating run metadata
wandb: uploading summary, console lines 40-40
wandb: 
wandb: Run history:
wandb:                    epoch ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:                       lr ‚ñà‚ñá‚ñÑ‚ñÅ
wandb: spikes/train_avg_layer_0 ‚ñÅ‚ñà‚ñÑ‚ñÉ
wandb: spikes/train_avg_layer_1 ‚ñÅ‚ñÑ‚ñÜ‚ñà
wandb: spikes/train_avg_layer_2 ‚ñÅ‚ñÅ‚ñà‚ñá
wandb: spikes/train_avg_layer_3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_4 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_6 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: spikes/train_avg_layer_7 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       +3 ...
wandb: 
wandb: Run summary:
wandb:                    epoch 3
wandb:                       lr 3e-05
wandb: spikes/train_avg_layer_0 0.01954
wandb: spikes/train_avg_layer_1 0.0013
wandb: spikes/train_avg_layer_2 1e-05
wandb: spikes/train_avg_layer_3 0
wandb: spikes/train_avg_layer_4 0
wandb: spikes/train_avg_layer_5 0
wandb: spikes/train_avg_layer_6 0
wandb: spikes/train_avg_layer_7 0
wandb:                       +3 ...
wandb: 
wandb: üöÄ View run icy-sweep-34 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/psa6tyfb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_142136-psa6tyfb/logs
Traceback (most recent call last):
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
  File "/pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/3_hyperparameter_search_rsnn.py", line 301, in training_run
    trainer.fit(model)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1055, in _run_stage
    self.fit_loop.run()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 216, in run
    self.advance()
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py", line 458, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 152, in run
    self.advance(data_fetcher)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 348, in advance
    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 192, in run
    self._optimizer_step(batch_idx, closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 270, in _optimizer_step
    call._call_lightning_module_hook(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 177, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1366, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 154, in step
    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 239, in optimizer_step
    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 123, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/optim/adam.py", line 226, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 109, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 146, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 140, in closure
    self._backward_fn(step_output.closure_loss)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py", line 241, in backward_fn
    call._call_strategy_hook(self.trainer, "backward", loss, optimizer)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 329, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 213, in backward
    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/precision.py", line 73, in backward
    model.backward(tensor, *args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/core/module.py", line 1135, in backward
    loss.backward(*args, **kwargs)
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/_tensor.py", line 625, in backward
    torch.autograd.backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/graph.py", line 841, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/torch/autograd/function.py", line 300, in apply
    def apply(self, *args):
    
Exception

wandb: Agent Starting Run: jfy5z4r8 with config:
wandb: 	alpha: 0.95
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -6
wandb: 	bh_max: -3
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 0.0007430485916480315
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 8
wandb: 	optimizer_class: AdamW
wandb: 	r: 4
wandb: 	relu_bypass: False
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0.2
wandb: 	zhyp_s: 1
wandb: setting up run jfy5z4r8
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_142508-jfy5z4r8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-35
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/jfy5z4r8
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 116 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
116 K     Trainable params
0         Non-trainable params
116 K     Total params
0.467     Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
`Trainer.fit` stopped: `max_epochs=40` reached.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                  epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: grad_mean/lif_layers.0 ‚ñÅ‚ñÉ‚ñá‚ñà
wandb: grad_mean/lif_layers.1 ‚ñÅ‚ñÉ‚ñÜ‚ñà
wandb: grad_mean/lif_layers.2 ‚ñÅ‚ñÉ‚ñá‚ñà
wandb: grad_mean/lif_layers.3 ‚ñÅ‚ñÉ‚ñá‚ñà
wandb: grad_mean/lif_layers.4 ‚ñÅ‚ñÑ‚ñá‚ñà
wandb: grad_mean/lif_layers.5 ‚ñÅ‚ñÖ‚ñà‚ñà
wandb: grad_mean/lif_layers.6 ‚ñÅ‚ñÜ‚ñà‚ñà
wandb: grad_mean/lif_layers.7 ‚ñà‚ñÇ‚ñÅ‚ñÅ
wandb: grad_mean/output_layer ‚ñà‚ñÑ‚ñÇ‚ñÅ
wandb:                    +12 ...
wandb: 
wandb: Run summary:
wandb:                  epoch 39
wandb: grad_mean/lif_layers.0 2342.53638
wandb: grad_mean/lif_layers.1 216.85454
wandb: grad_mean/lif_layers.2 18.97678
wandb: grad_mean/lif_layers.3 1.29413
wandb: grad_mean/lif_layers.4 0.09267
wandb: grad_mean/lif_layers.5 0.00802
wandb: grad_mean/lif_layers.6 0.00073
wandb: grad_mean/lif_layers.7 6e-05
wandb: grad_mean/output_layer 0.10988
wandb:                    +12 ...
wandb: 
wandb: üöÄ View run dry-sweep-35 at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/jfy5z4r8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_142508-jfy5z4r8/logs
wandb: Agent Starting Run: 1qx79j7y with config:
wandb: 	alpha: 0.9
wandb: 	batch_size: 2048
wandb: 	beta: 0
wandb: 	bh_init: -5
wandb: 	bh_max: -4
wandb: 	bntt_time_steps: 100
wandb: 	data_path: ./data/small_dataset.ds
wandb: 	detach_rec: False
wandb: 	dropout: 0
wandb: 	epochs: 40
wandb: 	layer_skip: 0
wandb: 	lr: 6.246187068903071e-06
wandb: 	neuron_type: SRC
wandb: 	num_hidden: 128
wandb: 	num_hidden_layers: 16
wandb: 	optimizer_class: AdamW
wandb: 	r: 2
wandb: 	relu_bypass: True
wandb: 	rho: 2
wandb: 	rs: -3
wandb: 	scheduler_class: cosine
wandb: 	scheduler_kwargs: 
wandb: 	surrogate_gradient: atan
wandb: 	temporal_skip: -1
wandb: 	use_bntt: False
wandb: 	use_layernorm: False
wandb: 	z: 0
wandb: 	zdep_s: 0
wandb: 	zhyp_s: 0.9
wandb: setting up run 1qx79j7y
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251124_154118-1qx79j7y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-36
wandb: ‚≠êÔ∏è View project at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep
wandb: üßπ View sweep at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/sweeps/kxbgxnd8
wandb: üöÄ View run at https://wandb.ai/lupos/SpikeSynth-Surrogate-Sweep/runs/1qx79j7y
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 248 K  | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 0      | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 129    | train
--------------------------------------------------------
248 K     Trainable params
0         Non-trainable params
248 K     Total params
0.995     Total estimated model params size (MB)
40        Modules in train mode
0         Modules in eval mode
wandb: WARNING Config item 'num_hidden_layers' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'num_hidden' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'beta' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'optimizer_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'lr' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'batch_size' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'dropout' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'temporal_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'layer_skip' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_bntt' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_class' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'use_layernorm' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'neuron_type' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'scheduler_kwargs' was locked by 'sweep' (ignored update).
wandb: WARNING Config item 'bntt_time_steps' was locked by 'sweep' (ignored update).
SLURM auto-requeueing enabled. Setting signal handlers.
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
