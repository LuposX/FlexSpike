/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
2025-11-13 14:26:03,254 INFO: Loading dataset from ./data/dataset.ds
2025-11-13 14:26:03,428 INFO: Using accelerator=cpu
2025-11-13 14:26:03,428 INFO: === Starting run 1/4 with seed 42 ===
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
wandb: Currently logged in as: lupos to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: setting up run zi8bqvsh
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251113_142603-zi8bqvsh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run RSNN_wHypOpt_Skip3_run1
wandb: â­ï¸ View project at https://wandb.ai/lupos/surrogate-confidence
wandb: ğŸš€ View run at https://wandb.ai/lupos/surrogate-confidence/runs/zi8bqvsh
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:751: Checkpoint directory /pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/models/SRNN exists and is not empty.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 29.6 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 4.2 K  | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
17.5 K    Trainable params
16.4 K    Non-trainable params
33.9 K    Total params
0.135     Total estimated model params size (MB)
21        Modules in train mode
0         Modules in eval mode
SLURM auto-requeueing enabled. Setting signal handlers.
Metric val_loss improved. New best score: 0.127
Metric val_loss improved by 0.022 >= min_delta = 0.0001. New best score: 0.105
Metric val_loss improved by 0.010 >= min_delta = 0.0001. New best score: 0.095
Metric val_loss improved by 0.004 >= min_delta = 0.0001. New best score: 0.091
Metric val_loss improved by 0.003 >= min_delta = 0.0001. New best score: 0.087
Metric val_loss improved by 0.002 >= min_delta = 0.0001. New best score: 0.085
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.085
Metric val_loss improved by 0.001 >= min_delta = 0.0001. New best score: 0.084
Metric val_loss improved by 0.001 >= min_delta = 0.0001. New best score: 0.084
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.083
Metric val_loss improved by 0.002 >= min_delta = 0.0001. New best score: 0.081
Metric val_loss improved by 0.001 >= min_delta = 0.0001. New best score: 0.080
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.080
Metric val_loss improved by 0.001 >= min_delta = 0.0001. New best score: 0.079
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.079
Metric val_loss improved by 0.001 >= min_delta = 0.0001. New best score: 0.079
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.078
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.078
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.078
Metric val_loss improved by 0.001 >= min_delta = 0.0001. New best score: 0.077
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.077
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.077
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.076
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.076
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.076
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.076
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.076
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.076
`Trainer.fit` stopped: `max_epochs=80` reached.
wandb: uploading artifact model-zi8bqvsh
wandb: uploading history steps 277-279, summary, console lines 20-21
wandb: 
wandb: Run history:
wandb:                        epoch â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ
wandb: grad_mean/layer_skip_projs.3 â–‡â–†â–ƒâ–…â–„â–„â–‚â–‚â–ˆâ–â–‚â–‚â–‡â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–â–‚â–ƒâ–â–â–‚â–â–â–â–‚â–â–â–â–
wandb:       grad_mean/lif_layers.0 â–…â–‡â–…â–‚â–‚â–…â–‚â–‚â–ˆâ–ƒâ–†â–‚â–‚â–â–„â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–â–‚â–â–‚â–â–â–
wandb:       grad_mean/lif_layers.1 â–‡â–ˆâ–ƒâ–‚â–„â–‚â–ƒâ–‚â–„â–‚â–‚â–ƒâ–ƒâ–…â–‡â–‚â–‚â–ƒâ–‚â–â–â–ƒâ–â–â–‚â–‚â–â–â–ƒâ–â–‚â–â–‚â–â–â–â–â–â–â–
wandb:       grad_mean/lif_layers.2 â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–‚â–‚â–ƒâ–‚â–„â–…â–‚â–ƒâ–‚â–…â–„â–…â–ƒâ–ˆâ–ƒâ–„â–â–ƒâ–‚â–‚â–â–â–â–ƒâ–â–‚â–ƒâ–â–â–â–â–â–
wandb:       grad_mean/lif_layers.3 â–‡â–ƒâ–ƒâ–ƒâ–ƒâ–…â–‚â–‚â–…â–ˆâ–‚â–â–‚â–„â–‚â–…â–â–‚â–ˆâ–‚â–‚â–â–â–‚â–â–‚â–‚â–‚â–ƒâ–â–â–â–â–â–â–â–â–â–â–
wandb:       grad_mean/output_layer â–…â–ˆâ–â–„â–„â–â–„â–ƒâ–‚â–‚â–â–ƒâ–‚â–‚â–‚â–„â–†â–‡â–‚â–â–â–‚â–‚â–â–‚â–ƒâ–â–‚â–‚â–â–‚â–‚â–â–â–â–â–â–â–â–
wandb:                           lr â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–
wandb:     spikes/train_avg_layer_0 â–ˆâ–‡â–‡â–†â–…â–„â–ƒâ–ƒâ–‚â–‚â–â–â–â–â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:     spikes/train_avg_layer_1 â–â–…â–…â–†â–ˆâ–†â–…â–…â–†â–…â–„â–…â–„â–„â–„â–…â–„â–…â–…â–„â–„â–„â–„â–„â–ƒâ–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:                           +5 ...
wandb: 
wandb: Run summary:
wandb:                        epoch 79
wandb: grad_mean/layer_skip_projs.3 4e-05
wandb:       grad_mean/lif_layers.0 0.00014
wandb:       grad_mean/lif_layers.1 6e-05
wandb:       grad_mean/lif_layers.2 5e-05
wandb:       grad_mean/lif_layers.3 5e-05
wandb:       grad_mean/output_layer 0.00042
wandb:                           lr 0
wandb:     spikes/train_avg_layer_0 0.16797
wandb:     spikes/train_avg_layer_1 0.44258
wandb:                           +5 ...
wandb: 
wandb: ğŸš€ View run RSNN_wHypOpt_Skip3_run1 at: https://wandb.ai/lupos/surrogate-confidence/runs/zi8bqvsh
wandb: â­ï¸ View project at: https://wandb.ai/lupos/surrogate-confidence
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251113_142603-zi8bqvsh/logs
2025-11-13 14:46:32,727 INFO: Run 1 finished. Best checkpoint: /pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/models/SRNN/RSNN_wHypOpt_Skip3-runrun_idx=0-epoch=75-val_loss=0.08.ckpt
2025-11-13 14:46:32,727 INFO: === Starting run 2/4 with seed 43 ===
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
wandb: setting up run a6668dpg
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251113_144632-a6668dpg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run RSNN_wHypOpt_Skip3_run2
wandb: â­ï¸ View project at https://wandb.ai/lupos/surrogate-confidence
wandb: ğŸš€ View run at https://wandb.ai/lupos/surrogate-confidence/runs/a6668dpg
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:751: Checkpoint directory /pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/models/SRNN exists and is not empty.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 29.6 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 4.2 K  | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
17.5 K    Trainable params
16.4 K    Non-trainable params
33.9 K    Total params
0.135     Total estimated model params size (MB)
21        Modules in train mode
0         Modules in eval mode
SLURM auto-requeueing enabled. Setting signal handlers.
Metric val_loss improved. New best score: 0.121
Metric val_loss improved by 0.018 >= min_delta = 0.0001. New best score: 0.103
Metric val_loss improved by 0.007 >= min_delta = 0.0001. New best score: 0.095
Metric val_loss improved by 0.007 >= min_delta = 0.0001. New best score: 0.088
Metric val_loss improved by 0.002 >= min_delta = 0.0001. New best score: 0.087
Metric val_loss improved by 0.003 >= min_delta = 0.0001. New best score: 0.084
Metric val_loss improved by 0.001 >= min_delta = 0.0001. New best score: 0.083
Metric val_loss improved by 0.001 >= min_delta = 0.0001. New best score: 0.082
Metric val_loss improved by 0.001 >= min_delta = 0.0001. New best score: 0.081
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.081
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.081
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.080
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.080
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.080
Metric val_loss improved by 0.001 >= min_delta = 0.0001. New best score: 0.079
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.079
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.079
Metric val_loss improved by 0.001 >= min_delta = 0.0001. New best score: 0.078
Metric val_loss improved by 0.001 >= min_delta = 0.0001. New best score: 0.078
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.077
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.077
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.077
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.077
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.076
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.076
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.076
`Trainer.fit` stopped: `max_epochs=80` reached.
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                        epoch â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: grad_mean/layer_skip_projs.3 â–†â–…â–‚â–‚â–ƒâ–„â–…â–ˆâ–‚â–‚â–‚â–ƒâ–…â–â–ƒâ–„â–ƒâ–‚â–„â–â–…â–â–„â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–â–‚â–‚â–â–‚â–â–â–â–â–â–
wandb:       grad_mean/lif_layers.0 â–…â–‚â–…â–†â–‚â–ƒâ–ˆâ–ƒâ–‚â–„â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–â–‚â–ƒâ–‚â–ƒâ–â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–
wandb:       grad_mean/lif_layers.1 â–„â–ƒâ–‚â–‚â–ƒâ–ƒâ–‡â–ƒâ–ƒâ–ˆâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–â–‚â–‚â–ƒâ–â–‚â–‚â–â–â–â–‚â–â–â–â–â–
wandb:       grad_mean/lif_layers.2 â–…â–ƒâ–ƒâ–…â–…â–ˆâ–ƒâ–„â–…â–†â–ƒâ–ƒâ–‚â–†â–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–â–ƒâ–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–‚
wandb:       grad_mean/lif_layers.3 â–…â–…â–ƒâ–ƒâ–ƒâ–‚â–„â–ˆâ–‚â–„â–‚â–…â–„â–ƒâ–‚â–„â–ƒâ–„â–ƒâ–ƒâ–â–‚â–ƒâ–â–‚â–ƒâ–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–â–â–â–â–
wandb:       grad_mean/output_layer â–ƒâ–ˆâ–†â–â–â–…â–â–„â–‚â–â–ƒâ–‡â–‚â–…â–‚â–â–…â–‚â–ƒâ–â–‚â–â–ƒâ–ƒâ–„â–‚â–‚â–‚â–â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–â–â–‚â–â–
wandb:                           lr â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–
wandb:     spikes/train_avg_layer_0 â–†â–ˆâ–‡â–‡â–†â–â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–„â–„â–ƒâ–…â–„â–„â–„â–„â–„â–„â–„â–„â–…â–„â–„â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†
wandb:     spikes/train_avg_layer_1 â–†â–†â–ˆâ–ˆâ–†â–†â–…â–…â–…â–…â–ƒâ–„â–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚
wandb:                           +5 ...
wandb: 
wandb: Run summary:
wandb:                        epoch 79
wandb: grad_mean/layer_skip_projs.3 6e-05
wandb:       grad_mean/lif_layers.0 0.00016
wandb:       grad_mean/lif_layers.1 5e-05
wandb:       grad_mean/lif_layers.2 7e-05
wandb:       grad_mean/lif_layers.3 6e-05
wandb:       grad_mean/output_layer 0.00183
wandb:                           lr 0
wandb:     spikes/train_avg_layer_0 0.21791
wandb:     spikes/train_avg_layer_1 0.29173
wandb:                           +5 ...
wandb: 
wandb: ğŸš€ View run RSNN_wHypOpt_Skip3_run2 at: https://wandb.ai/lupos/surrogate-confidence/runs/a6668dpg
wandb: â­ï¸ View project at: https://wandb.ai/lupos/surrogate-confidence
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251113_144632-a6668dpg/logs
2025-11-13 15:07:27,429 INFO: Run 2 finished. Best checkpoint: /pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/models/SRNN/RSNN_wHypOpt_Skip3-runrun_idx=0-epoch=75-val_loss=0.08.ckpt
2025-11-13 15:07:27,429 INFO: === Starting run 3/4 with seed 44 ===
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
wandb: setting up run jchceg18
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251113_150727-jchceg18
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run RSNN_wHypOpt_Skip3_run3
wandb: â­ï¸ View project at https://wandb.ai/lupos/surrogate-confidence
wandb: ğŸš€ View run at https://wandb.ai/lupos/surrogate-confidence/runs/jchceg18
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:751: Checkpoint directory /pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/models/SRNN exists and is not empty.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 29.6 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 4.2 K  | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
17.5 K    Trainable params
16.4 K    Non-trainable params
33.9 K    Total params
0.135     Total estimated model params size (MB)
21        Modules in train mode
0         Modules in eval mode
SLURM auto-requeueing enabled. Setting signal handlers.
Metric val_loss improved. New best score: 0.138
Metric val_loss improved by 0.020 >= min_delta = 0.0001. New best score: 0.118
Metric val_loss improved by 0.019 >= min_delta = 0.0001. New best score: 0.100
Metric val_loss improved by 0.010 >= min_delta = 0.0001. New best score: 0.089
Metric val_loss improved by 0.002 >= min_delta = 0.0001. New best score: 0.087
Metric val_loss improved by 0.002 >= min_delta = 0.0001. New best score: 0.085
Metric val_loss improved by 0.001 >= min_delta = 0.0001. New best score: 0.083
Metric val_loss improved by 0.001 >= min_delta = 0.0001. New best score: 0.082
Metric val_loss improved by 0.001 >= min_delta = 0.0001. New best score: 0.081
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.081
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.081
Metric val_loss improved by 0.001 >= min_delta = 0.0001. New best score: 0.080
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.080
Metric val_loss improved by 0.001 >= min_delta = 0.0001. New best score: 0.079
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.078
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.078
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.077
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.077
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.077
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.077
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.076
Monitored metric val_loss did not improve in the last 20 records. Best score: 0.076. Signaling Trainer to stop.
wandb: updating run metadata
wandb: uploading history steps 266-268, summary, console lines 20-21
wandb: 
wandb: Run history:
wandb:                        epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: grad_mean/layer_skip_projs.3 â–„â–‚â–ƒâ–‚â–‚â–„â–ƒâ–ˆâ–‚â–‚â–ƒâ–‚â–ƒâ–…â–â–‚â–ƒâ–‚â–‚â–â–â–‚â–‚â–„â–â–â–ƒâ–‚â–â–‚â–â–â–‚â–â–â–‚â–‚â–â–â–
wandb:       grad_mean/lif_layers.0 â–†â–„â–„â–ƒâ–ƒâ–â–…â–‚â–ƒâ–ƒâ–ƒâ–‡â–†â–ƒâ–ˆâ–„â–‚â–‚â–‚â–â–‚â–â–ƒâ–â–â–â–ƒâ–â–â–â–‚â–â–â–â–â–‚â–â–â–â–
wandb:       grad_mean/lif_layers.1 â–ˆâ–‡â–„â–ƒâ–ƒâ–‚â–‚â–‚â–â–„â–„â–‡â–ƒâ–â–â–‚â–‚â–ƒâ–‚â–â–ƒâ–â–‚â–â–â–‚â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–â–
wandb:       grad_mean/lif_layers.2 â–ƒâ–…â–ƒâ–„â–„â–‡â–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–ˆâ–ƒâ–‚â–„â–‚â–‚â–‚â–‚â–â–‚â–â–â–‚â–â–â–‚â–â–â–‚â–â–‚â–‚â–â–â–
wandb:       grad_mean/lif_layers.3 â–‚â–ƒâ–‚â–„â–ƒâ–‚â–ƒâ–‚â–„â–ƒâ–ˆâ–â–ƒâ–‚â–…â–‚â–…â–†â–â–‡â–‚â–‚â–â–‚â–â–‚â–‚â–â–â–‚â–â–â–â–â–‚â–â–‚â–â–‚â–
wandb:       grad_mean/output_layer â–ˆâ–‚â–ƒâ–â–‚â–ƒâ–â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–â–â–â–‚â–â–‚â–â–â–â–‚â–â–â–â–â–â–â–â–‚â–â–â–â–â–
wandb:                           lr â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–
wandb:     spikes/train_avg_layer_0 â–ˆâ–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:     spikes/train_avg_layer_1 â–‚â–â–…â–…â–…â–…â–…â–…â–…â–„â–„â–„â–…â–…â–…â–†â–†â–†â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:                           +5 ...
wandb: 
wandb: Run summary:
wandb:                        epoch 76
wandb: grad_mean/layer_skip_projs.3 0.0001
wandb:       grad_mean/lif_layers.0 0.00029
wandb:       grad_mean/lif_layers.1 6e-05
wandb:       grad_mean/lif_layers.2 7e-05
wandb:       grad_mean/lif_layers.3 0.00011
wandb:       grad_mean/output_layer 0.00179
wandb:                           lr 2e-05
wandb:     spikes/train_avg_layer_0 0.17868
wandb:     spikes/train_avg_layer_1 0.31024
wandb:                           +5 ...
wandb: 
wandb: ğŸš€ View run RSNN_wHypOpt_Skip3_run3 at: https://wandb.ai/lupos/surrogate-confidence/runs/jchceg18
wandb: â­ï¸ View project at: https://wandb.ai/lupos/surrogate-confidence
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251113_150727-jchceg18/logs
2025-11-13 15:27:01,144 INFO: Run 3 finished. Best checkpoint: /pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/models/SRNN/RSNN_wHypOpt_Skip3-runrun_idx=0-epoch=75-val_loss=0.08.ckpt
2025-11-13 15:27:01,144 INFO: === Starting run 4/4 with seed 45 ===
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
wandb: setting up run mtamghtg
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /scratch/ka_rh5993/wandb_logs/wandb/run-20251113_152701-mtamghtg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run RSNN_wHypOpt_Skip3_run4
wandb: â­ï¸ View project at https://wandb.ai/lupos/surrogate-confidence
wandb: ğŸš€ View run at https://wandb.ai/lupos/surrogate-confidence/runs/mtamghtg
/home/ka/ka_itec/ka_rh5993/.local/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:751: Checkpoint directory /pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/models/SRNN exists and is not empty.

  | Name             | Type       | Params | Mode 
--------------------------------------------------------
0 | norm             | LayerNorm  | 14     | train
1 | lif_layers       | ModuleList | 29.6 K | train
2 | leaky_linears    | ModuleList | 0      | train
3 | temp_skip_projs  | ModuleList | 0      | train
4 | layer_skip_projs | ModuleList | 4.2 K  | train
5 | layer_bntt       | ModuleList | 0      | train
6 | layer_norms      | ModuleList | 0      | train
7 | output_layer     | Linear     | 65     | train
--------------------------------------------------------
17.5 K    Trainable params
16.4 K    Non-trainable params
33.9 K    Total params
0.135     Total estimated model params size (MB)
21        Modules in train mode
0         Modules in eval mode
SLURM auto-requeueing enabled. Setting signal handlers.
Metric val_loss improved. New best score: 0.117
Metric val_loss improved by 0.020 >= min_delta = 0.0001. New best score: 0.098
Metric val_loss improved by 0.008 >= min_delta = 0.0001. New best score: 0.090
Metric val_loss improved by 0.005 >= min_delta = 0.0001. New best score: 0.085
Metric val_loss improved by 0.001 >= min_delta = 0.0001. New best score: 0.084
Metric val_loss improved by 0.001 >= min_delta = 0.0001. New best score: 0.083
Metric val_loss improved by 0.001 >= min_delta = 0.0001. New best score: 0.082
Metric val_loss improved by 0.001 >= min_delta = 0.0001. New best score: 0.082
Metric val_loss improved by 0.001 >= min_delta = 0.0001. New best score: 0.081
Metric val_loss improved by 0.001 >= min_delta = 0.0001. New best score: 0.080
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.080
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.080
Metric val_loss improved by 0.001 >= min_delta = 0.0001. New best score: 0.079
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.079
Metric val_loss improved by 0.001 >= min_delta = 0.0001. New best score: 0.078
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.077
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.077
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.077
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.077
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.076
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.076
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.076
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.076
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.076
Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.076
`Trainer.fit` stopped: `max_epochs=80` reached.
wandb: updating run metadata
wandb: uploading console lines 23-47
wandb: 
wandb: Run history:
wandb:                        epoch â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: grad_mean/layer_skip_projs.3 â–ˆâ–‚â–„â–„â–‚â–†â–ƒâ–‚â–‚â–ƒâ–„â–„â–‚â–ƒâ–‚â–†â–ƒâ–‚â–â–â–‚â–‚â–â–‚â–â–‚â–â–‚â–â–‚â–‚â–â–â–â–‚â–‚â–‚â–â–â–
wandb:       grad_mean/lif_layers.0 â–†â–„â–„â–‚â–„â–‚â–†â–ƒâ–‚â–ƒâ–ƒâ–†â–‚â–ˆâ–ƒâ–ƒâ–‚â–…â–‚â–‚â–ƒâ–â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–â–â–â–
wandb:       grad_mean/lif_layers.1 â–ˆâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–â–â–„â–„â–‚â–â–…â–ƒâ–â–â–â–‚â–‚â–‚â–â–â–â–â–â–‚â–â–‚â–â–‚â–â–â–â–â–â–â–â–
wandb:       grad_mean/lif_layers.2 â–…â–ƒâ–†â–ˆâ–†â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–‚â–‚â–â–â–‚â–â–â–â–
wandb:       grad_mean/lif_layers.3 â–„â–ƒâ–ƒâ–…â–‚â–ƒâ–‚â–‚â–ƒâ–„â–„â–ˆâ–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–â–ƒâ–‚â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–â–â–‚â–‚â–â–â–
wandb:       grad_mean/output_layer â–ˆâ–‚â–â–…â–‚â–†â–‚â–‚â–…â–‚â–„â–‚â–ˆâ–ƒâ–ƒâ–„â–…â–â–†â–‚â–â–â–‚â–‚â–ƒâ–â–‚â–ƒâ–‚â–‚â–â–â–‚â–‚â–‚â–‚â–â–â–â–
wandb:                           lr â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–…â–…â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–
wandb:     spikes/train_avg_layer_0 â–ˆâ–‡â–…â–„â–…â–â–„â–ˆâ–†â–ˆâ–ƒâ–ƒâ–…â–†â–„â–…â–ƒâ–‚â–ƒâ–‚â–„â–†â–ƒâ–„â–„â–…â–„â–„â–†â–„â–†â–†â–†â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡
wandb:     spikes/train_avg_layer_1 â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–†â–…â–…â–…â–„â–„â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:                           +5 ...
wandb: 
wandb: Run summary:
wandb:                        epoch 79
wandb: grad_mean/layer_skip_projs.3 4e-05
wandb:       grad_mean/lif_layers.0 0.00011
wandb:       grad_mean/lif_layers.1 4e-05
wandb:       grad_mean/lif_layers.2 5e-05
wandb:       grad_mean/lif_layers.3 4e-05
wandb:       grad_mean/output_layer 0.00052
wandb:                           lr 0
wandb:     spikes/train_avg_layer_0 0.18124
wandb:     spikes/train_avg_layer_1 0.31019
wandb:                           +5 ...
wandb: 
wandb: ğŸš€ View run RSNN_wHypOpt_Skip3_run4 at: https://wandb.ai/lupos/surrogate-confidence/runs/mtamghtg
wandb: â­ï¸ View project at: https://wandb.ai/lupos/surrogate-confidence
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: /scratch/ka_rh5993/wandb_logs/wandb/run-20251113_152701-mtamghtg/logs
2025-11-13 15:47:34,226 INFO: Run 4 finished. Best checkpoint: /pfs/data6/home/ka/ka_itec/ka_rh5993/SpikeSynth/surrogate/models/SRNN/RSNN_wHypOpt_Skip3-runrun_idx=0-epoch=75-val_loss=0.08.ckpt
